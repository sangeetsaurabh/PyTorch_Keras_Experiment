{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TextNumber_prediction_multiple_steps_keras_pytorch",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMQL8cow55qa7CYSlv9Rgf5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sangeetsaurabh/PyTorch_Keras_Experiment/blob/master/Text_Number_Prediction/TextNumber_prediction_multiple_steps_keras_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adSK6gSGz36x",
        "colab_type": "text"
      },
      "source": [
        "### Predict the next number in the sequence\n",
        "\n",
        "Given a set of numbers, goal of the model is to predict next number in the sequence. \n",
        "\n",
        "For example, model can be given input like - eight thousand one , eight thousand two , eight thousand three , eight thousand four , eight thousand five , eight thousand six , eight thousand seven , eight thousand eight , eight thousand nine , eight thousand ten , eight thousand eleven , eight thousand twelve....\n",
        "\n",
        "Model will predict next number given the one input. Model in this notebook predicts next word given any of the words like above (multi steps prediciton). So if 20 numbers are given to the model, it will predict 20 numbers (i.e. a number after each number).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "149iYfEnjyLR",
        "colab_type": "code",
        "outputId": "6e9fbeb9-f91a-4910-da34-671e5c431e24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "source": [
        "#### Make sure that the right version of Torch is there\n",
        "!pip install torchtext==0.6.0\n",
        "import torchtext\n",
        "print(torchtext.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torchtext==0.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f2/17/e7c588245aece7aa93f360894179374830daf60d7ed0bbb59332de3b3b61/torchtext-0.6.0-py3-none-any.whl (64kB)\n",
            "\r\u001b[K     |█████                           | 10kB 21.0MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 30kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 40kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 51kB 2.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 61kB 2.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 2.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6.0) (1.5.0+cu101)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6.0) (1.12.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6.0) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6.0) (4.41.1)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 8.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6.0) (1.18.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->torchtext==0.6.0) (0.16.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.6.0) (2020.4.5.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.6.0) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.6.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.6.0) (1.24.3)\n",
            "Installing collected packages: sentencepiece, torchtext\n",
            "  Found existing installation: torchtext 0.3.1\n",
            "    Uninstalling torchtext-0.3.1:\n",
            "      Successfully uninstalled torchtext-0.3.1\n",
            "Successfully installed sentencepiece-0.1.91 torchtext-0.6.0\n",
            "0.6.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RR4eRGbbjJHU",
        "colab_type": "code",
        "outputId": "8eb54a5b-bf16-4a3c-c60f-8ce845e9442d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYx3rbtw0NBL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#drive.flush_and_unmount"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBaVXPQZuWLV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#### Setting up the right seed to make Keras result more consistent\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import random as python_random\n",
        "\n",
        "# The below is necessary for starting Numpy generated random numbers\n",
        "# in a well-defined initial state.\n",
        "np.random.seed(123)\n",
        "\n",
        "# The below is necessary for starting core Python generated random numbers\n",
        "# in a well-defined state.\n",
        "python_random.seed(123)\n",
        "\n",
        "# The below set_seed() will make random number generation\n",
        "# in the TensorFlow backend have a well-defined initial state.\n",
        "# For further details, see:\n",
        "# https://www.tensorflow.org/api_docs/python/tf/random/set_seed\n",
        "tf.random.set_seed(1234)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRJv3gWMi6g-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#### Setting up path to import important data preparation Python module\n",
        "import sys\n",
        "import os\n",
        "sys.path.append('/content/drive/My Drive/Colab Notebooks/torch_pipe/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItOt_tGZi6hJ",
        "colab_type": "code",
        "outputId": "0e0572fd-fa71-435e-c570-ae0896ba757e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "os.getcwd()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bt_V_qOIi6hR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#### Using torch utilities to prepare the features. Importing all the important files\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from Util.human_language_modeling import *\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "import time\n",
        "import logging"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7iRyHrqii6hY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#### Enabling logging\n",
        "import logging\n",
        "logger = logging.getLogger()\n",
        "fhandler = logging.FileHandler(filename='mylog.log', mode='a')\n",
        "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
        "fhandler.setFormatter(formatter)\n",
        "logger.addHandler(fhandler)\n",
        "logger.setLevel(logging.DEBUG)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4Gzgd_Ei6hf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#### Setting up the batch size and length of the sequence\n",
        "BATCH_SIZE = 64 ## defining the batch size\n",
        "bptt = 20 ## back propogration through LSTM\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srAakqVfi6hy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### A simplie python function to show text given an array of vectors\n",
        "def show_text(input_vector):\n",
        "    separator = ' '\n",
        "    txt = separator.join([vocab.itos[i] for i in input_vector])\n",
        "    return txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9pubLZDi6h4",
        "colab_type": "text"
      },
      "source": [
        "#### Download the train and validation data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-MF6hGBi6iB",
        "colab_type": "code",
        "outputId": "2ac274d2-c3b7-48b1-99f2-d9c0f5fb7d58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "tokenizer = get_tokenizer(\"spacy\")\n",
        "train_dataset, valid_dataset = HumanNumbers(root='data',bptt=bptt,batch_size=BATCH_SIZE,data_select=('train', 'valid'))\n",
        "vocab = train_dataset.get_vocab()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0lines [00:00, ?lines/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "<function tokenizer at 0x7efd7de9a158>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8001lines [00:00, 18674.64lines/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "51200\n",
            "51200\n",
            "torch.Size([51200, 20])\n",
            "torch.Size([51200, 20])\n",
            "14080\n",
            "14080\n",
            "torch.Size([14080, 20])\n",
            "torch.Size([14080, 20])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4iNmEGzoEFN",
        "colab_type": "text"
      },
      "source": [
        "#### Extract the features for Keras/Tensor Flow implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9I5fFdykqMqd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional, GRU, SimpleRNN\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import initializers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRAfySwzmVl1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#### Building input features and lables for machine learning models\n",
        "train_x = train_dataset.input_data.numpy()\n",
        "train_label = train_dataset.label_data.numpy().astype(int)\n",
        "train_y = tf.keras.utils.to_categorical(train_label, num_classes=len(vocab.itos))\n",
        "\n",
        "valid_x = valid_dataset.input_data.numpy()\n",
        "valid_label = valid_dataset.label_data.numpy()\n",
        "valid_y = tf.keras.utils.to_categorical(valid_label, num_classes=len(vocab.itos))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "342a1nWPni1X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "05c7d4c6-17b4-4777-cc3f-3fefde8a4aa4"
      },
      "source": [
        "print(train_x.shape)\n",
        "print (train_y.shape)\n",
        "print(valid_x.shape)\n",
        "print(valid_y.shape)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(51200, 20)\n",
            "(51200, 20, 34)\n",
            "(14080, 20)\n",
            "(14080, 20, 34)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMkXv7X6fiYs",
        "colab_type": "text"
      },
      "source": [
        "##### Create the batch data for Train and Validation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLX-gWBXft86",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#### Setting up Keras dataset to feed into machine learning models\n",
        "BUFFER_SIZE = train_x.shape[0] ## Shuffling the data across entire dataset before building the batch\n",
        "\n",
        "train_batch = tf.data.Dataset.from_tensor_slices((train_x, train_y))\n",
        "train_batch = train_batch.shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "\n",
        "val_batch = tf.data.Dataset.from_tensor_slices((valid_x, valid_y))\n",
        "val_batch = val_batch.batch(BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Lp26TcaYZ8U",
        "colab_type": "text"
      },
      "source": [
        "#### Simple DNN to do the prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ha0bqpSRvbuR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "b382599c-6a4a-47b3-9df7-05ab19687348"
      },
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "model = keras.Sequential(\n",
        "    [\n",
        "        keras.layers.Embedding(len(vocab.itos), 100, input_length=train_x.shape[1]),\n",
        "        keras.layers.Dense(64, activation=\"relu\"),\n",
        "        keras.layers.BatchNormalization(),\n",
        "        keras.layers.Dense(len(vocab.itos), activation=\"softmax\"),\n",
        "        #keras.layers.Lambda(lambda x: x[:,-1])\n",
        "    ]\n",
        ")\n",
        "model.summary()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, 20, 100)           3400      \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 20, 64)            6464      \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 20, 64)            256       \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 20, 34)            2210      \n",
            "=================================================================\n",
            "Total params: 12,330\n",
            "Trainable params: 12,202\n",
            "Non-trainable params: 128\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sQO8QaIcYxmY",
        "colab": {}
      },
      "source": [
        "adam = Adam(lr=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['categorical_accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GWTf-V8aYxmc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "outputId": "d7d7ff21-f216-42ea-8be9-bf037357054f"
      },
      "source": [
        "#history = model.fit(train_x, train_y, epochs=10, batch_size=64, verbose=1,validation_data=(valid_x,valid_y))\n",
        "history = model.fit(train_batch, epochs=10, verbose=1,validation_data=val_batch)\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "800/800 [==============================] - 4s 5ms/step - loss: 1.8196 - categorical_accuracy: 0.2470 - val_loss: 3.7993 - val_categorical_accuracy: 0.0842\n",
            "Epoch 3/10\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 1.8171 - categorical_accuracy: 0.2489 - val_loss: 3.5049 - val_categorical_accuracy: 0.0906\n",
            "Epoch 4/10\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 1.8153 - categorical_accuracy: 0.2492 - val_loss: 3.6378 - val_categorical_accuracy: 0.0845\n",
            "Epoch 5/10\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 1.8258 - categorical_accuracy: 0.2500 - val_loss: 3.4867 - val_categorical_accuracy: 0.0836\n",
            "Epoch 6/10\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 1.8142 - categorical_accuracy: 0.2509 - val_loss: 3.5073 - val_categorical_accuracy: 0.0906\n",
            "Epoch 7/10\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 1.8140 - categorical_accuracy: 0.2516 - val_loss: 3.7385 - val_categorical_accuracy: 0.0845\n",
            "Epoch 8/10\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 1.8131 - categorical_accuracy: 0.2527 - val_loss: 3.5133 - val_categorical_accuracy: 0.0845\n",
            "Epoch 9/10\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 1.8129 - categorical_accuracy: 0.2522 - val_loss: 3.5055 - val_categorical_accuracy: 0.0842\n",
            "Epoch 10/10\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 1.8128 - categorical_accuracy: 0.2524 - val_loss: 3.5485 - val_categorical_accuracy: 0.0838\n",
            "Epoch 1/10\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 1.8124 - categorical_accuracy: 0.2525 - val_loss: 3.4227 - val_categorical_accuracy: 0.0838\n",
            "Epoch 2/10\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 1.8120 - categorical_accuracy: 0.2528 - val_loss: 3.5448 - val_categorical_accuracy: 0.0845\n",
            "Epoch 3/10\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 1.8119 - categorical_accuracy: 0.2531 - val_loss: 3.4002 - val_categorical_accuracy: 0.0845\n",
            "Epoch 4/10\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 1.8115 - categorical_accuracy: 0.2535 - val_loss: 3.4772 - val_categorical_accuracy: 0.0840\n",
            "Epoch 5/10\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 1.8121 - categorical_accuracy: 0.2524 - val_loss: 3.4188 - val_categorical_accuracy: 0.0843\n",
            "Epoch 6/10\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 1.8115 - categorical_accuracy: 0.2525 - val_loss: 3.5467 - val_categorical_accuracy: 0.0845\n",
            "Epoch 7/10\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 1.8114 - categorical_accuracy: 0.2538 - val_loss: 3.4725 - val_categorical_accuracy: 0.0906\n",
            "Epoch 8/10\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 1.8116 - categorical_accuracy: 0.2522 - val_loss: 3.5548 - val_categorical_accuracy: 0.1256\n",
            "Epoch 9/10\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 1.8114 - categorical_accuracy: 0.2525 - val_loss: 3.5657 - val_categorical_accuracy: 0.0838\n",
            "Epoch 10/10\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 1.8111 - categorical_accuracy: 0.2536 - val_loss: 3.5419 - val_categorical_accuracy: 0.0845\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xj6pkWZUY8Oz",
        "colab_type": "text"
      },
      "source": [
        "This sequential layer network didn't produce a good result. This was expected as simple DNN is not the right way to predict 1 through 21st word given 20 words sequence. Let's customize DNN to take the sequence of 20 words."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxbR7WxpQqIE",
        "colab_type": "text"
      },
      "source": [
        "#### DNN to do the prediction\n",
        "\n",
        "Customizing DNN to process one word at a time in a sequence. This is more like a custom RNN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0dAiDoZvRwI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d4cd7911-b76c-40fb-fe5f-794d33b6ceeb"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow import keras\n",
        "\n",
        "nh = BATCH_SIZE\n",
        "\n",
        "# Define a Functional model to do a softmax on final dense layer\n",
        "inputs = keras.Input((bptt, nh))\n",
        "outputs = layers.Dense(len(vocab.itos), activation=\"softmax\")(inputs)\n",
        "model = keras.Model(inputs, outputs)\n",
        "\n",
        "class CustomRNN(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(CustomRNN, self).__init__()\n",
        "        self.embedding1 = layers.Embedding(len(vocab.itos), nh, input_length=train_x.shape[1])\n",
        "        self.projection_1 = layers.Dense(units=64, activation=\"relu\")\n",
        "        self.batchnormal = layers.BatchNormalization()\n",
        "        # Our previously-defined Functional model\n",
        "        self.classifier = model\n",
        "\n",
        "    def call(self, inputs):\n",
        "        ### Initialize the weights\n",
        "        outputs = []\n",
        "        if inputs.shape[0] == None:\n",
        "          bs = BATCH_SIZE\n",
        "        else:\n",
        "          bs = inputs.shape[0]\n",
        "        h = tf.zeros(shape=(bs, nh))\n",
        "        ### going in the loop to pick one word at a time\n",
        "        for t in range(inputs.shape[1]):\n",
        "            x = inputs[:, t]\n",
        "            h = h + self.embedding1(x)\n",
        "            h = self.batchnormal(self.projection_1(h))\n",
        "            outputs.append(h)\n",
        "        features = tf.stack(outputs, axis=1)\n",
        "        #print(features.shape)\n",
        "        return self.classifier(features)\n",
        "\n",
        "rnn_model = CustomRNN()\n",
        "rnn_model.predict(valid_x).shape\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14080, 20, 34)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b42I7AM5vyjq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "adam = Adam(lr=0.01)\n",
        "rnn_model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['categorical_accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6hnaBBjv33c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "outputId": "55fa2d42-0dec-4109-8ee3-1093c98ec9ca"
      },
      "source": [
        "#### Train the model\n",
        "#history = rnn_model.fit(train_x, train_y, epochs=20, batch_size=64, verbose=1,validation_data=(valid_x,valid_y))\n",
        "history = rnn_model.fit(train_batch, epochs=20, verbose=1,validation_data=val_batch)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "800/800 [==============================] - 10s 12ms/step - loss: 1.3417 - categorical_accuracy: 0.5376 - val_loss: 1.8904 - val_categorical_accuracy: 0.4899\n",
            "Epoch 2/20\n",
            "800/800 [==============================] - 9s 12ms/step - loss: 0.8487 - categorical_accuracy: 0.7082 - val_loss: 1.9911 - val_categorical_accuracy: 0.5495\n",
            "Epoch 3/20\n",
            "800/800 [==============================] - 9s 11ms/step - loss: 0.6899 - categorical_accuracy: 0.7765 - val_loss: 1.8530 - val_categorical_accuracy: 0.5662\n",
            "Epoch 4/20\n",
            "800/800 [==============================] - 9s 11ms/step - loss: 0.6122 - categorical_accuracy: 0.8043 - val_loss: 2.0488 - val_categorical_accuracy: 0.5873\n",
            "Epoch 5/20\n",
            "800/800 [==============================] - 9s 11ms/step - loss: 0.5742 - categorical_accuracy: 0.8149 - val_loss: 1.9046 - val_categorical_accuracy: 0.6059\n",
            "Epoch 6/20\n",
            "800/800 [==============================] - 9s 12ms/step - loss: 0.5540 - categorical_accuracy: 0.8201 - val_loss: 1.9618 - val_categorical_accuracy: 0.6103\n",
            "Epoch 7/20\n",
            "800/800 [==============================] - 9s 11ms/step - loss: 0.5404 - categorical_accuracy: 0.8234 - val_loss: 1.9110 - val_categorical_accuracy: 0.6414\n",
            "Epoch 8/20\n",
            "800/800 [==============================] - 9s 12ms/step - loss: 0.5286 - categorical_accuracy: 0.8267 - val_loss: 1.9589 - val_categorical_accuracy: 0.6195\n",
            "Epoch 9/20\n",
            "800/800 [==============================] - 9s 11ms/step - loss: 0.5218 - categorical_accuracy: 0.8284 - val_loss: 1.8955 - val_categorical_accuracy: 0.6313\n",
            "Epoch 10/20\n",
            "800/800 [==============================] - 9s 12ms/step - loss: 0.5154 - categorical_accuracy: 0.8300 - val_loss: 1.9167 - val_categorical_accuracy: 0.6294\n",
            "Epoch 11/20\n",
            "800/800 [==============================] - 9s 12ms/step - loss: 0.5095 - categorical_accuracy: 0.8310 - val_loss: 2.0439 - val_categorical_accuracy: 0.6296\n",
            "Epoch 12/20\n",
            "800/800 [==============================] - 9s 11ms/step - loss: 0.5052 - categorical_accuracy: 0.8320 - val_loss: 1.9791 - val_categorical_accuracy: 0.6321\n",
            "Epoch 13/20\n",
            "800/800 [==============================] - 9s 11ms/step - loss: 0.5014 - categorical_accuracy: 0.8329 - val_loss: 1.8705 - val_categorical_accuracy: 0.6403\n",
            "Epoch 14/20\n",
            "800/800 [==============================] - 9s 11ms/step - loss: 0.5000 - categorical_accuracy: 0.8331 - val_loss: 1.9713 - val_categorical_accuracy: 0.6373\n",
            "Epoch 15/20\n",
            "800/800 [==============================] - 9s 11ms/step - loss: 0.4962 - categorical_accuracy: 0.8336 - val_loss: 1.8567 - val_categorical_accuracy: 0.6433\n",
            "Epoch 16/20\n",
            "800/800 [==============================] - 9s 11ms/step - loss: 0.4942 - categorical_accuracy: 0.8343 - val_loss: 1.8638 - val_categorical_accuracy: 0.6512\n",
            "Epoch 17/20\n",
            "800/800 [==============================] - 9s 11ms/step - loss: 0.4909 - categorical_accuracy: 0.8345 - val_loss: 1.7877 - val_categorical_accuracy: 0.6556\n",
            "Epoch 18/20\n",
            "800/800 [==============================] - 9s 11ms/step - loss: 0.4896 - categorical_accuracy: 0.8349 - val_loss: 1.7825 - val_categorical_accuracy: 0.6352\n",
            "Epoch 19/20\n",
            "800/800 [==============================] - 9s 11ms/step - loss: 0.4882 - categorical_accuracy: 0.8351 - val_loss: 1.8495 - val_categorical_accuracy: 0.6395\n",
            "Epoch 20/20\n",
            "800/800 [==============================] - 9s 11ms/step - loss: 0.4855 - categorical_accuracy: 0.8354 - val_loss: 1.7416 - val_categorical_accuracy: 0.6482\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "H2gO_n5ygUik"
      },
      "source": [
        "#### See the results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aD4bfd2xgUim",
        "colab": {}
      },
      "source": [
        "validation_results = rnn_model.predict(val_batch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fLhZ2UDcgUir",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "d81f66dd-3491-4821-af90-7ad87f6794d0"
      },
      "source": [
        "validation_results[0].shape"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20, 34)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RfEdPXr1gUit",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "0232e87a-3654-4735-baa1-bb15e65c21ce"
      },
      "source": [
        "show_text(np.argmax(validation_results[20],axis=1))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'thousand nine hundred six hundred six thousand eight \\n eight thousand eight \\n eight thousand eight \\n eight thousand ten'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEuasDlNg4n6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "28da7886-154a-4a62-d298-ff898ab8331b"
      },
      "source": [
        "#### Comparing the label and predictions\n",
        "for i,word_idx in  enumerate(np.argmax(validation_results[20],axis=1)):\n",
        "  print (f'Label: {repr(tokenizer(show_text(valid_label[20]))[i])} ---> Prediction: {repr(vocab.itos[word_idx])} ')"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label: '\\n ' ---> Prediction: 'thousand' \n",
            "Label: 'eight' ---> Prediction: 'nine' \n",
            "Label: 'thousand' ---> Prediction: 'hundred' \n",
            "Label: 'six' ---> Prediction: 'six' \n",
            "Label: '\\n ' ---> Prediction: 'hundred' \n",
            "Label: 'eight' ---> Prediction: 'six' \n",
            "Label: 'thousand' ---> Prediction: 'thousand' \n",
            "Label: 'seven' ---> Prediction: 'eight' \n",
            "Label: '\\n ' ---> Prediction: '\\n' \n",
            "Label: 'eight' ---> Prediction: 'eight' \n",
            "Label: 'thousand' ---> Prediction: 'thousand' \n",
            "Label: 'eight' ---> Prediction: 'eight' \n",
            "Label: '\\n ' ---> Prediction: '\\n' \n",
            "Label: 'eight' ---> Prediction: 'eight' \n",
            "Label: 'thousand' ---> Prediction: 'thousand' \n",
            "Label: 'nine' ---> Prediction: 'eight' \n",
            "Label: '\\n ' ---> Prediction: '\\n' \n",
            "Label: 'eight' ---> Prediction: 'eight' \n",
            "Label: 'thousand' ---> Prediction: 'thousand' \n",
            "Label: 'ten' ---> Prediction: 'ten' \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ymn5-7eegUiw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "6743e9e8-53b6-411b-f5b2-a0cb5c02e2aa"
      },
      "source": [
        "show_text(valid_label[0])"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n eight thousand one \\n eight thousand two \\n eight thousand three \\n eight thousand four \\n eight thousand five'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1hJcZd4TbprQ",
        "colab_type": "text"
      },
      "source": [
        "As can be seen, performance improved quite a bit with the implmentation of custom RNN model. Let's try real RNN, GRU and LSTM models to see what happens."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHsguJfA0IDL",
        "colab_type": "text"
      },
      "source": [
        "#### Simple RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Thwq-UlMeSJi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "9b87ee7d-d5d1-42a9-db99-3872f76082d8"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(len(vocab.itos), 64, input_length=(train_x.shape[1])))\n",
        "model.add(Bidirectional(SimpleRNN(150,return_sequences=True)))\n",
        "model.add(Dense(len(vocab.itos), activation='softmax'))\n",
        "\n",
        "### Compile the model\n",
        "adam = Adam(lr=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['categorical_accuracy'])\n",
        "\n",
        "#earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=0, mode='auto')\n",
        "#history = model.fit(train_x, train_y, epochs=10, batch_size=64, verbose=1,validation_data=(valid_x,valid_y))\n",
        "history = model.fit(train_batch, epochs=10, verbose=1,validation_data=val_batch)\n",
        "#print model.summary()\n",
        "print(model.summary())\n",
        "\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "800/800 [==============================] - 20s 25ms/step - loss: 0.1054 - categorical_accuracy: 0.9668 - val_loss: 0.1257 - val_categorical_accuracy: 0.9695\n",
            "Epoch 2/10\n",
            "800/800 [==============================] - 21s 26ms/step - loss: 0.0854 - categorical_accuracy: 0.9736 - val_loss: 0.1289 - val_categorical_accuracy: 0.9656\n",
            "Epoch 3/10\n",
            "800/800 [==============================] - 20s 25ms/step - loss: 0.0831 - categorical_accuracy: 0.9739 - val_loss: 0.1202 - val_categorical_accuracy: 0.9669\n",
            "Epoch 4/10\n",
            "800/800 [==============================] - 19s 24ms/step - loss: 0.0800 - categorical_accuracy: 0.9746 - val_loss: 0.1360 - val_categorical_accuracy: 0.9663\n",
            "Epoch 5/10\n",
            "800/800 [==============================] - 20s 25ms/step - loss: 0.0787 - categorical_accuracy: 0.9748 - val_loss: 0.1113 - val_categorical_accuracy: 0.9671\n",
            "Epoch 6/10\n",
            "800/800 [==============================] - 20s 25ms/step - loss: 0.1022 - categorical_accuracy: 0.9687 - val_loss: 0.5597 - val_categorical_accuracy: 0.8502\n",
            "Epoch 7/10\n",
            "800/800 [==============================] - 20s 25ms/step - loss: 0.1815 - categorical_accuracy: 0.9454 - val_loss: 0.4554 - val_categorical_accuracy: 0.8699\n",
            "Epoch 8/10\n",
            "800/800 [==============================] - 20s 25ms/step - loss: 0.1028 - categorical_accuracy: 0.9680 - val_loss: 0.3934 - val_categorical_accuracy: 0.8900\n",
            "Epoch 9/10\n",
            "800/800 [==============================] - 20s 25ms/step - loss: 0.0967 - categorical_accuracy: 0.9701 - val_loss: 0.4896 - val_categorical_accuracy: 0.8852\n",
            "Epoch 10/10\n",
            "800/800 [==============================] - 19s 24ms/step - loss: 0.0998 - categorical_accuracy: 0.9696 - val_loss: 0.4212 - val_categorical_accuracy: 0.8967\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_5 (Embedding)      (None, 20, 64)            2176      \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 20, 300)           64500     \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 20, 34)            10234     \n",
            "=================================================================\n",
            "Total params: 76,910\n",
            "Trainable params: 76,910\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "raCzCC_4pwn3"
      },
      "source": [
        "#### See the results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IjjaF_CZpwn5",
        "colab": {}
      },
      "source": [
        "validation_results = model.predict(val_batch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aR9N6bEtpwn8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "1cda414f-eb03-4c5b-83b1-93ec6ea535a0"
      },
      "source": [
        "validation_results[0].shape"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20, 34)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "glzBYhxLpwn_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "50be7d1e-c3f9-41ca-d4fc-a9d76ef1d191"
      },
      "source": [
        "show_text(np.argmax(validation_results[20],axis=1))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n eight hundred six \\n eight thousand seven \\n eight hundred eight \\n eight hundred nine \\n one thousand seven'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_bnV3nFvpwoF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "1f9072c1-f387-4e41-c82f-8ba36769467e"
      },
      "source": [
        "#### Comparing the label and predictions\n",
        "for i,word_idx in  enumerate(np.argmax(validation_results[20],axis=1)):\n",
        "  print (f'Label: {repr(tokenizer(show_text(valid_label[20]))[i])} ---> Prediction: {repr(vocab.itos[word_idx])} ')"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label: '\\n ' ---> Prediction: '\\n' \n",
            "Label: 'eight' ---> Prediction: 'eight' \n",
            "Label: 'thousand' ---> Prediction: 'hundred' \n",
            "Label: 'six' ---> Prediction: 'six' \n",
            "Label: '\\n ' ---> Prediction: '\\n' \n",
            "Label: 'eight' ---> Prediction: 'eight' \n",
            "Label: 'thousand' ---> Prediction: 'thousand' \n",
            "Label: 'seven' ---> Prediction: 'seven' \n",
            "Label: '\\n ' ---> Prediction: '\\n' \n",
            "Label: 'eight' ---> Prediction: 'eight' \n",
            "Label: 'thousand' ---> Prediction: 'hundred' \n",
            "Label: 'eight' ---> Prediction: 'eight' \n",
            "Label: '\\n ' ---> Prediction: '\\n' \n",
            "Label: 'eight' ---> Prediction: 'eight' \n",
            "Label: 'thousand' ---> Prediction: 'hundred' \n",
            "Label: 'nine' ---> Prediction: 'nine' \n",
            "Label: '\\n ' ---> Prediction: '\\n' \n",
            "Label: 'eight' ---> Prediction: 'one' \n",
            "Label: 'thousand' ---> Prediction: 'thousand' \n",
            "Label: 'ten' ---> Prediction: 'seven' \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "b77IIbJqpwoI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "e88648bd-bb83-4489-b6bf-d13498578fe6"
      },
      "source": [
        "show_text(valid_label[0])"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n eight thousand one \\n eight thousand two \\n eight thousand three \\n eight thousand four \\n eight thousand five'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4QGIUrBepwoK"
      },
      "source": [
        "As expected, performance is so much better with bi-directional RNN."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfIZI6mQt3qo",
        "colab_type": "text"
      },
      "source": [
        "#### GRU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1kR0HdWSt-fX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "348d87d0-3983-4ba0-c7c9-53585502dbab"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(len(vocab.itos), output_dim=64, input_length=train_x.shape[1]))\n",
        "model.add( Bidirectional(GRU(units=150,return_sequences=True)))\n",
        "model.add(Dense(len(vocab.itos), activation='softmax'))\n",
        "\n",
        "### Compile the model\n",
        "adam = Adam(lr=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['categorical_accuracy'])\n",
        "\n",
        "#earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=0, mode='auto')\n",
        "#history = model.fit(train_x, train_y, epochs=10, batch_size=64, verbose=1,validation_data=(valid_x,valid_y))\n",
        "history = model.fit(train_batch, epochs=5, verbose=1,validation_data=val_batch)\n",
        "print (model.summary())\n",
        "\n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "800/800 [==============================] - 8s 10ms/step - loss: 0.1075 - categorical_accuracy: 0.9702 - val_loss: 0.0882 - val_categorical_accuracy: 0.9771\n",
            "Epoch 2/5\n",
            "800/800 [==============================] - 7s 9ms/step - loss: 0.0035 - categorical_accuracy: 0.9991 - val_loss: 0.0917 - val_categorical_accuracy: 0.9820\n",
            "Epoch 3/5\n",
            "800/800 [==============================] - 7s 9ms/step - loss: 0.0464 - categorical_accuracy: 0.9870 - val_loss: 0.1257 - val_categorical_accuracy: 0.9704\n",
            "Epoch 4/5\n",
            "800/800 [==============================] - 7s 9ms/step - loss: 0.0366 - categorical_accuracy: 0.9882 - val_loss: 0.1160 - val_categorical_accuracy: 0.9793\n",
            "Epoch 5/5\n",
            "800/800 [==============================] - 7s 9ms/step - loss: 0.0242 - categorical_accuracy: 0.9924 - val_loss: 0.1204 - val_categorical_accuracy: 0.9776\n",
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_6 (Embedding)      (None, 20, 64)            2176      \n",
            "_________________________________________________________________\n",
            "bidirectional_2 (Bidirection (None, 20, 300)           194400    \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 20, 34)            10234     \n",
            "=================================================================\n",
            "Total params: 206,810\n",
            "Trainable params: 206,810\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "j_HaLoqIrB9A"
      },
      "source": [
        "#### See the results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zN-FQNI0rB9C",
        "colab": {}
      },
      "source": [
        "validation_results = model.predict(val_batch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "icz6d5PkrB9G",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "01efc87c-c1db-427d-8199-3faa89e0b125"
      },
      "source": [
        "validation_results[0].shape"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20, 34)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aI27badPrB9K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c2c1f975-c845-4ce9-b262-9ff76e22b1c2"
      },
      "source": [
        "show_text(np.argmax(validation_results[20],axis=1))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n eight thousand six \\n eight thousand seven \\n eight thousand eight \\n eight thousand nine \\n eight thousand nine'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WIz_jzvirB9M",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "6c86ad06-d4b5-4bc9-8151-c3fb369ddb93"
      },
      "source": [
        "#### Comparing the label and predictions\n",
        "for i,word_idx in  enumerate(np.argmax(validation_results[20],axis=1)):\n",
        "  print (f'Label: {repr(tokenizer(show_text(valid_label[20]))[i])} ---> Prediction: {repr(vocab.itos[word_idx])} ')"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label: '\\n ' ---> Prediction: '\\n' \n",
            "Label: 'eight' ---> Prediction: 'eight' \n",
            "Label: 'thousand' ---> Prediction: 'thousand' \n",
            "Label: 'six' ---> Prediction: 'six' \n",
            "Label: '\\n ' ---> Prediction: '\\n' \n",
            "Label: 'eight' ---> Prediction: 'eight' \n",
            "Label: 'thousand' ---> Prediction: 'thousand' \n",
            "Label: 'seven' ---> Prediction: 'seven' \n",
            "Label: '\\n ' ---> Prediction: '\\n' \n",
            "Label: 'eight' ---> Prediction: 'eight' \n",
            "Label: 'thousand' ---> Prediction: 'thousand' \n",
            "Label: 'eight' ---> Prediction: 'eight' \n",
            "Label: '\\n ' ---> Prediction: '\\n' \n",
            "Label: 'eight' ---> Prediction: 'eight' \n",
            "Label: 'thousand' ---> Prediction: 'thousand' \n",
            "Label: 'nine' ---> Prediction: 'nine' \n",
            "Label: '\\n ' ---> Prediction: '\\n' \n",
            "Label: 'eight' ---> Prediction: 'eight' \n",
            "Label: 'thousand' ---> Prediction: 'thousand' \n",
            "Label: 'ten' ---> Prediction: 'nine' \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "apax64ForB9O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e5548420-e315-4d40-ffce-e7f0fdfd65c8"
      },
      "source": [
        "show_text(valid_label[0])"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n eight thousand one \\n eight thousand two \\n eight thousand three \\n eight thousand four \\n eight thousand five'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NE3_V8oVrB9Q"
      },
      "source": [
        "Wow, bidirectional is the solution for it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dDXpMarkugP0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "8c5923b2-9323-4f34-e916-3a0c3cf87e98"
      },
      "source": [
        "#### Let's try the stateful\n",
        "model = Sequential()\n",
        "model.add(Embedding(len(vocab.itos), 64, input_length=train_x.shape[1],batch_input_shape=(BATCH_SIZE,train_x.shape[1])))\n",
        "model.add(Bidirectional(GRU(150,stateful=True,return_sequences=True)))\n",
        "model.add(Dense(len(vocab.itos), activation='softmax'))\n",
        "\n",
        "### Compile the model\n",
        "adam = Adam(lr=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['categorical_accuracy'])\n",
        "\n",
        "#earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=0, mode='auto')\n",
        "#history = model.fit(train_x, train_y, epochs=10, batch_size=64, verbose=1,validation_data=(valid_x,valid_y))\n",
        "history = model.fit(train_batch, epochs=5, verbose=1,validation_data=val_batch)\n",
        "print (model.summary())\n"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "800/800 [==============================] - 7s 9ms/step - loss: 0.1909 - categorical_accuracy: 0.9520 - val_loss: 0.2399 - val_categorical_accuracy: 0.9257\n",
            "Epoch 2/5\n",
            "800/800 [==============================] - 7s 8ms/step - loss: 0.0616 - categorical_accuracy: 0.9807 - val_loss: 0.3558 - val_categorical_accuracy: 0.9021\n",
            "Epoch 3/5\n",
            "800/800 [==============================] - 7s 8ms/step - loss: 0.0513 - categorical_accuracy: 0.9839 - val_loss: 0.2515 - val_categorical_accuracy: 0.9261\n",
            "Epoch 4/5\n",
            "800/800 [==============================] - 7s 8ms/step - loss: 0.0737 - categorical_accuracy: 0.9796 - val_loss: 0.3342 - val_categorical_accuracy: 0.9041\n",
            "Epoch 5/5\n",
            "800/800 [==============================] - 7s 8ms/step - loss: 0.0961 - categorical_accuracy: 0.9747 - val_loss: 0.4231 - val_categorical_accuracy: 0.8696\n",
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_7 (Embedding)      (64, 20, 64)              2176      \n",
            "_________________________________________________________________\n",
            "bidirectional_3 (Bidirection (64, 20, 300)             194400    \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (64, 20, 34)              10234     \n",
            "=================================================================\n",
            "Total params: 206,810\n",
            "Trainable params: 206,810\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zR9xN7PyW6I",
        "colab_type": "text"
      },
      "source": [
        "#### LSTM\n",
        "\n",
        "Let's do one more experiment. Try both uni directional and bi-directional network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mruLse_dMdxP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        },
        "outputId": "9e52c774-55eb-4bb9-a6a2-f3d4c9043b59"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(len(vocab.itos), output_dim=64, input_length=train_x.shape[1]))\n",
        "model.add(LSTM(units=64, return_sequences=True))\n",
        "model.add(Dense(len(vocab.itos), activation='softmax'))\n",
        "\n",
        "### Compile the model\n",
        "adam = Adam(lr=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['categorical_accuracy'])\n",
        "\n",
        "#earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=0, mode='auto')\n",
        "#history = model.fit(train_x, train_y, epochs=10, batch_size=64, verbose=1,validation_data=(valid_x,valid_y))\n",
        "history = model.fit(train_batch, epochs=10, verbose=1,validation_data=val_batch)\n",
        "print (model.summary())"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "800/800 [==============================] - 5s 6ms/step - loss: 1.1652 - categorical_accuracy: 0.5699 - val_loss: 2.1468 - val_categorical_accuracy: 0.5440\n",
            "Epoch 2/10\n",
            "800/800 [==============================] - 5s 6ms/step - loss: 0.4510 - categorical_accuracy: 0.8394 - val_loss: 2.1747 - val_categorical_accuracy: 0.5711\n",
            "Epoch 3/10\n",
            "800/800 [==============================] - 5s 6ms/step - loss: 0.4216 - categorical_accuracy: 0.8430 - val_loss: 2.4084 - val_categorical_accuracy: 0.5803\n",
            "Epoch 4/10\n",
            "800/800 [==============================] - 5s 6ms/step - loss: 0.4173 - categorical_accuracy: 0.8433 - val_loss: 2.3837 - val_categorical_accuracy: 0.5732\n",
            "Epoch 5/10\n",
            "800/800 [==============================] - 5s 6ms/step - loss: 0.4154 - categorical_accuracy: 0.8434 - val_loss: 2.4107 - val_categorical_accuracy: 0.5687\n",
            "Epoch 6/10\n",
            "800/800 [==============================] - 5s 6ms/step - loss: 0.4130 - categorical_accuracy: 0.8436 - val_loss: 2.3281 - val_categorical_accuracy: 0.5779\n",
            "Epoch 7/10\n",
            "800/800 [==============================] - 5s 6ms/step - loss: 0.4126 - categorical_accuracy: 0.8437 - val_loss: 2.3251 - val_categorical_accuracy: 0.5900\n",
            "Epoch 8/10\n",
            "800/800 [==============================] - 5s 6ms/step - loss: 0.4130 - categorical_accuracy: 0.8437 - val_loss: 2.2123 - val_categorical_accuracy: 0.6155\n",
            "Epoch 9/10\n",
            "800/800 [==============================] - 5s 6ms/step - loss: 0.4103 - categorical_accuracy: 0.8439 - val_loss: 2.2958 - val_categorical_accuracy: 0.5955\n",
            "Epoch 10/10\n",
            "800/800 [==============================] - 5s 6ms/step - loss: 0.4109 - categorical_accuracy: 0.8439 - val_loss: 2.3111 - val_categorical_accuracy: 0.5889\n",
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_8 (Embedding)      (None, 20, 64)            2176      \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 20, 64)            33024     \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 20, 34)            2210      \n",
            "=================================================================\n",
            "Total params: 37,410\n",
            "Trainable params: 37,410\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8dbNaJ2KMlyD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "05fb69df-5514-4b6d-a973-69344ece640b"
      },
      "source": [
        "#### Let's try the stateful\n",
        "model = Sequential()\n",
        "model.add(Embedding(len(vocab.itos), 64, input_length=train_x.shape[1],batch_input_shape=(BATCH_SIZE,train_x.shape[1])))\n",
        "model.add(Bidirectional( LSTM(units=64, return_sequences=True)))\n",
        "model.add(Dense(len(vocab.itos), activation='softmax'))\n",
        "\n",
        "### Compile the model\n",
        "adam = Adam(lr=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['categorical_accuracy'])\n",
        "\n",
        "#earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=0, mode='auto')\n",
        "#history = model.fit(train_x, train_y, epochs=10, batch_size=64, verbose=1,validation_data=(valid_x,valid_y))\n",
        "history = model.fit(train_batch, epochs=5, verbose=1,validation_data=val_batch)\n",
        "print (model.summary())"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "800/800 [==============================] - 6s 8ms/step - loss: 0.1617 - categorical_accuracy: 0.9543 - val_loss: 0.1269 - val_categorical_accuracy: 0.9618\n",
            "Epoch 2/5\n",
            "800/800 [==============================] - 6s 7ms/step - loss: 0.0075 - categorical_accuracy: 0.9984 - val_loss: 0.0817 - val_categorical_accuracy: 0.9780\n",
            "Epoch 3/5\n",
            "800/800 [==============================] - 5s 7ms/step - loss: 0.0026 - categorical_accuracy: 0.9995 - val_loss: 0.0832 - val_categorical_accuracy: 0.9803\n",
            "Epoch 4/5\n",
            "800/800 [==============================] - 5s 7ms/step - loss: 0.0022 - categorical_accuracy: 0.9995 - val_loss: 0.0652 - val_categorical_accuracy: 0.9852\n",
            "Epoch 5/5\n",
            "800/800 [==============================] - 5s 7ms/step - loss: 0.0022 - categorical_accuracy: 0.9995 - val_loss: 0.0927 - val_categorical_accuracy: 0.9793\n",
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_9 (Embedding)      (64, 20, 64)              2176      \n",
            "_________________________________________________________________\n",
            "bidirectional_4 (Bidirection (64, 20, 128)             66048     \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (64, 20, 34)              4386      \n",
            "=================================================================\n",
            "Total params: 72,610\n",
            "Trainable params: 72,610\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-7d2FgsBstql"
      },
      "source": [
        "#### See the results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "I-sSsvaFstqm",
        "colab": {}
      },
      "source": [
        "validation_results = model.predict(val_batch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oTKKoV-Jstqo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5966c7fb-7ca3-4b9d-cba0-55107d224043"
      },
      "source": [
        "validation_results[0].shape"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20, 34)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xMImdW0Dstqq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a49cef40-e2a0-4d88-c57e-3a5875999ece"
      },
      "source": [
        "show_text(np.argmax(validation_results[20],axis=1))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n eight thousand six \\n eight thousand seven \\n eight thousand eight \\n eight thousand nine \\n eight thousand nine'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8lUdz-43stqs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "8cdf6b3b-06d3-4b54-df95-e573f8ad4a3a"
      },
      "source": [
        "#### Comparing the label and predictions\n",
        "for i,word_idx in  enumerate(np.argmax(validation_results[20],axis=1)):\n",
        "  print (f'Label: {repr(tokenizer(show_text(valid_label[20]))[i])} ---> Prediction: {repr(vocab.itos[word_idx])} ')"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label: '\\n ' ---> Prediction: '\\n' \n",
            "Label: 'eight' ---> Prediction: 'eight' \n",
            "Label: 'thousand' ---> Prediction: 'thousand' \n",
            "Label: 'six' ---> Prediction: 'six' \n",
            "Label: '\\n ' ---> Prediction: '\\n' \n",
            "Label: 'eight' ---> Prediction: 'eight' \n",
            "Label: 'thousand' ---> Prediction: 'thousand' \n",
            "Label: 'seven' ---> Prediction: 'seven' \n",
            "Label: '\\n ' ---> Prediction: '\\n' \n",
            "Label: 'eight' ---> Prediction: 'eight' \n",
            "Label: 'thousand' ---> Prediction: 'thousand' \n",
            "Label: 'eight' ---> Prediction: 'eight' \n",
            "Label: '\\n ' ---> Prediction: '\\n' \n",
            "Label: 'eight' ---> Prediction: 'eight' \n",
            "Label: 'thousand' ---> Prediction: 'thousand' \n",
            "Label: 'nine' ---> Prediction: 'nine' \n",
            "Label: '\\n ' ---> Prediction: '\\n' \n",
            "Label: 'eight' ---> Prediction: 'eight' \n",
            "Label: 'thousand' ---> Prediction: 'thousand' \n",
            "Label: 'ten' ---> Prediction: 'nine' \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "R0CzUkQestqu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4c764a42-60e3-4fe6-acd1-4b084b123319"
      },
      "source": [
        "show_text(valid_label[0])"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n eight thousand one \\n eight thousand two \\n eight thousand three \\n eight thousand four \\n eight thousand five'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OjVGQCxvstqy"
      },
      "source": [
        "Wow, bidirectional is the solution for it. Unidirectional is not optimum."
      ]
    }
  ]
}