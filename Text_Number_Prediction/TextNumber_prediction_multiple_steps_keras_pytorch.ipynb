{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TextNumber_prediction_multiple_steps_keras_pytorch",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMEiywNm64N0EWQE4ow8258"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adSK6gSGz36x",
        "colab_type": "text"
      },
      "source": [
        "### Predict the next number in the sequence\n",
        "\n",
        "Given a set of numbers, goal of the model is to predict next number in the sequence. \n",
        "\n",
        "For example, model can be given input like - eight thousand one , eight thousand two , eight thousand three , eight thousand four , eight thousand five , eight thousand six , eight thousand seven , eight thousand eight , eight thousand nine , eight thousand ten , eight thousand eleven , eight thousand twelve....\n",
        "\n",
        "Model will predict next number given the one input. Model in this notebook predicts next word given any of the words like above (multi steps prediciton). So if 20 numbers are given to the model, it will predict 20 numbers (i.e. a number after each number).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "149iYfEnjyLR",
        "colab_type": "code",
        "outputId": "dfd6af0c-dc4d-4716-e102-463cebd93af0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "#### Make sure that the right version of Torch is there\n",
        "!pip install torchtext==0.6.0\n",
        "import torchtext\n",
        "print(torchtext.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchtext==0.6.0 in /usr/local/lib/python3.6/dist-packages (0.6.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6.0) (1.18.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6.0) (1.5.0+cu101)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6.0) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6.0) (4.41.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6.0) (1.12.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6.0) (0.1.90)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->torchtext==0.6.0) (0.16.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.6.0) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.6.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.6.0) (2020.4.5.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.6.0) (1.24.3)\n",
            "0.6.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RR4eRGbbjJHU",
        "colab_type": "code",
        "outputId": "ac5d60bf-117c-4f25-9a44-4aa87cb9c9e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYx3rbtw0NBL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#drive.flush_and_unmount"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBaVXPQZuWLV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#### Setting up the right seed to make Keras result more consistent\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import random as python_random\n",
        "\n",
        "# The below is necessary for starting Numpy generated random numbers\n",
        "# in a well-defined initial state.\n",
        "np.random.seed(123)\n",
        "\n",
        "# The below is necessary for starting core Python generated random numbers\n",
        "# in a well-defined state.\n",
        "python_random.seed(123)\n",
        "\n",
        "# The below set_seed() will make random number generation\n",
        "# in the TensorFlow backend have a well-defined initial state.\n",
        "# For further details, see:\n",
        "# https://www.tensorflow.org/api_docs/python/tf/random/set_seed\n",
        "tf.random.set_seed(1234)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRJv3gWMi6g-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#### Setting up path to import important data preparation Python module\n",
        "import sys\n",
        "import os\n",
        "sys.path.append('/content/drive/My Drive/Colab Notebooks/torch_pipe/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItOt_tGZi6hJ",
        "colab_type": "code",
        "outputId": "801fc85e-25d0-465d-d85d-2d6632541c2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "os.getcwd()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Lp26TcaYZ8U",
        "colab_type": "text"
      },
      "source": [
        "#### Simple DNN to do the prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ha0bqpSRvbuR",
        "colab_type": "code",
        "outputId": "d8711256-643d-4f52-f140-f1df9101f067",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "model = keras.Sequential(\n",
        "    [\n",
        "        keras.layers.Embedding(len(vocab.itos), 100, input_length=train_x.shape[1]),\n",
        "        keras.layers.Dense(64, activation=\"relu\"),\n",
        "        keras.layers.BatchNormalization(),\n",
        "        keras.layers.Dense(len(vocab.itos), activation=\"softmax\"),\n",
        "        #keras.layers.Lambda(lambda x: x[:,-1])\n",
        "    ]\n",
        ")\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 20, 100)           3400      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 20, 64)            6464      \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 20, 64)            256       \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 20, 34)            2210      \n",
            "=================================================================\n",
            "Total params: 12,330\n",
            "Trainable params: 12,202\n",
            "Non-trainable params: 128\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sQO8QaIcYxmY",
        "colab": {}
      },
      "source": [
        "adam = Adam(lr=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['categorical_accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "2303c592-8589-4e70-9de2-5bd083698c5d",
        "id": "GWTf-V8aYxmc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "#history = model.fit(train_x, train_y, epochs=10, batch_size=64, verbose=1,validation_data=(valid_x,valid_y))\n",
        "history = model.fit(train_batch, epochs=10, verbose=1,validation_data=val_batch)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "800/800 [==============================] - 8s 10ms/step - loss: 1.8360 - categorical_accuracy: 0.2424 - val_loss: 3.1931 - val_categorical_accuracy: 0.0987\n",
            "Epoch 2/10\n",
            "800/800 [==============================] - 8s 10ms/step - loss: 1.8199 - categorical_accuracy: 0.2456 - val_loss: 3.4481 - val_categorical_accuracy: 0.0833\n",
            "Epoch 3/10\n",
            "800/800 [==============================] - 8s 10ms/step - loss: 1.8183 - categorical_accuracy: 0.2459 - val_loss: 3.4153 - val_categorical_accuracy: 0.0840\n",
            "Epoch 4/10\n",
            "800/800 [==============================] - 8s 10ms/step - loss: 1.8164 - categorical_accuracy: 0.2470 - val_loss: 3.5714 - val_categorical_accuracy: 0.0840\n",
            "Epoch 5/10\n",
            "800/800 [==============================] - 8s 10ms/step - loss: 1.8166 - categorical_accuracy: 0.2479 - val_loss: 3.4026 - val_categorical_accuracy: 0.0840\n",
            "Epoch 6/10\n",
            "800/800 [==============================] - 8s 10ms/step - loss: 1.8144 - categorical_accuracy: 0.2485 - val_loss: 3.4764 - val_categorical_accuracy: 0.0845\n",
            "Epoch 7/10\n",
            "800/800 [==============================] - 9s 11ms/step - loss: 1.8140 - categorical_accuracy: 0.2481 - val_loss: 3.3974 - val_categorical_accuracy: 0.1761\n",
            "Epoch 8/10\n",
            "800/800 [==============================] - 8s 10ms/step - loss: 1.8135 - categorical_accuracy: 0.2483 - val_loss: 3.4587 - val_categorical_accuracy: 0.0840\n",
            "Epoch 9/10\n",
            "800/800 [==============================] - 8s 10ms/step - loss: 1.8130 - categorical_accuracy: 0.2493 - val_loss: 3.5228 - val_categorical_accuracy: 0.0838\n",
            "Epoch 10/10\n",
            "800/800 [==============================] - 8s 10ms/step - loss: 1.8128 - categorical_accuracy: 0.2490 - val_loss: 3.4722 - val_categorical_accuracy: 0.0843\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xj6pkWZUY8Oz",
        "colab_type": "text"
      },
      "source": [
        "This sequential layer network didn't produce a good result. This was expected as simple DNN is not the right way to predict 1 through 21st word given 20 words sequence. Let's customize DNN to take the sequence of 20 words."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxbR7WxpQqIE",
        "colab_type": "text"
      },
      "source": [
        "#### DNN to do the prediction\n",
        "\n",
        "Customizing DNN to process one word at a time in a sequence. This is more like a custom RNN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0dAiDoZvRwI",
        "colab_type": "code",
        "outputId": "800db7bf-f5ce-4162-e781-19a0185654df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow import keras\n",
        "\n",
        "nh = BATCH_SIZE\n",
        "\n",
        "# Define a Functional model to do a softmax on final dense layer\n",
        "inputs = keras.Input((bptt, nh))\n",
        "outputs = layers.Dense(len(vocab.itos), activation=\"softmax\")(inputs)\n",
        "model = keras.Model(inputs, outputs)\n",
        "\n",
        "class CustomRNN(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(CustomRNN, self).__init__()\n",
        "        self.embedding1 = layers.Embedding(len(vocab.itos), nh, input_length=train_x.shape[1])\n",
        "        self.projection_1 = layers.Dense(units=64, activation=\"relu\")\n",
        "        self.batchnormal = layers.BatchNormalization()\n",
        "        # Our previously-defined Functional model\n",
        "        self.classifier = model\n",
        "\n",
        "    def call(self, inputs):\n",
        "        ### Initialize the weights\n",
        "        outputs = []\n",
        "        if inputs.shape[0] == None:\n",
        "          bs = BATCH_SIZE\n",
        "        else:\n",
        "          bs = inputs.shape[0]\n",
        "        h = tf.zeros(shape=(bs, nh))\n",
        "        ### going in the loop to pick one word at a time\n",
        "        for t in range(inputs.shape[1]):\n",
        "            x = inputs[:, t]\n",
        "            h = h + self.embedding1(x)\n",
        "            h = self.batchnormal(self.projection_1(h))\n",
        "            outputs.append(h)\n",
        "        features = tf.stack(outputs, axis=1)\n",
        "        #print(features.shape)\n",
        "        return self.classifier(features)\n",
        "\n",
        "rnn_model = CustomRNN()\n",
        "rnn_model.predict(valid_x).shape\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14080, 20, 34)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b42I7AM5vyjq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "adam = Adam(lr=0.01)\n",
        "rnn_model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['categorical_accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6hnaBBjv33c",
        "colab_type": "code",
        "outputId": "7da1bd15-2332-415c-b635-eeae09792408",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        }
      },
      "source": [
        "#### Train the model\n",
        "#history = rnn_model.fit(train_x, train_y, epochs=20, batch_size=64, verbose=1,validation_data=(valid_x,valid_y))\n",
        "history = rnn_model.fit(train_batch, epochs=20, verbose=1,validation_data=val_batch)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "800/800 [==============================] - 11s 13ms/step - loss: 1.3549 - categorical_accuracy: 0.5353 - val_loss: 1.9967 - val_categorical_accuracy: 0.4734\n",
            "Epoch 2/20\n",
            "800/800 [==============================] - 11s 13ms/step - loss: 0.7791 - categorical_accuracy: 0.7445 - val_loss: 1.8018 - val_categorical_accuracy: 0.5480\n",
            "Epoch 3/20\n",
            "800/800 [==============================] - 11s 13ms/step - loss: 0.6247 - categorical_accuracy: 0.8004 - val_loss: 1.6496 - val_categorical_accuracy: 0.6168\n",
            "Epoch 4/20\n",
            "800/800 [==============================] - 10s 12ms/step - loss: 0.5743 - categorical_accuracy: 0.8144 - val_loss: 1.5811 - val_categorical_accuracy: 0.6411\n",
            "Epoch 5/20\n",
            "800/800 [==============================] - 10s 12ms/step - loss: 0.5485 - categorical_accuracy: 0.8219 - val_loss: 1.6607 - val_categorical_accuracy: 0.6452\n",
            "Epoch 6/20\n",
            "800/800 [==============================] - 10s 13ms/step - loss: 0.5349 - categorical_accuracy: 0.8254 - val_loss: 1.6201 - val_categorical_accuracy: 0.6465\n",
            "Epoch 7/20\n",
            "800/800 [==============================] - 11s 14ms/step - loss: 0.5240 - categorical_accuracy: 0.8280 - val_loss: 1.6057 - val_categorical_accuracy: 0.6514\n",
            "Epoch 8/20\n",
            "800/800 [==============================] - 10s 13ms/step - loss: 0.5178 - categorical_accuracy: 0.8291 - val_loss: 1.7271 - val_categorical_accuracy: 0.6473\n",
            "Epoch 9/20\n",
            "800/800 [==============================] - 10s 12ms/step - loss: 0.5104 - categorical_accuracy: 0.8308 - val_loss: 1.5816 - val_categorical_accuracy: 0.6431\n",
            "Epoch 10/20\n",
            "800/800 [==============================] - 10s 12ms/step - loss: 0.5043 - categorical_accuracy: 0.8322 - val_loss: 1.6554 - val_categorical_accuracy: 0.6506\n",
            "Epoch 11/20\n",
            "800/800 [==============================] - 10s 13ms/step - loss: 0.5004 - categorical_accuracy: 0.8328 - val_loss: 1.5117 - val_categorical_accuracy: 0.6640\n",
            "Epoch 12/20\n",
            "800/800 [==============================] - 10s 12ms/step - loss: 0.4963 - categorical_accuracy: 0.8340 - val_loss: 1.4952 - val_categorical_accuracy: 0.6719\n",
            "Epoch 13/20\n",
            "800/800 [==============================] - 10s 12ms/step - loss: 0.4925 - categorical_accuracy: 0.8342 - val_loss: 1.5575 - val_categorical_accuracy: 0.6591\n",
            "Epoch 14/20\n",
            "800/800 [==============================] - 10s 12ms/step - loss: 0.4900 - categorical_accuracy: 0.8348 - val_loss: 1.5032 - val_categorical_accuracy: 0.6857\n",
            "Epoch 15/20\n",
            "800/800 [==============================] - 10s 12ms/step - loss: 0.4861 - categorical_accuracy: 0.8357 - val_loss: 1.4866 - val_categorical_accuracy: 0.6760\n",
            "Epoch 16/20\n",
            "800/800 [==============================] - 10s 12ms/step - loss: 0.4856 - categorical_accuracy: 0.8357 - val_loss: 1.4301 - val_categorical_accuracy: 0.6921\n",
            "Epoch 17/20\n",
            "800/800 [==============================] - 10s 12ms/step - loss: 0.4828 - categorical_accuracy: 0.8363 - val_loss: 1.5265 - val_categorical_accuracy: 0.6741\n",
            "Epoch 18/20\n",
            "800/800 [==============================] - 10s 13ms/step - loss: 0.4811 - categorical_accuracy: 0.8364 - val_loss: 1.4300 - val_categorical_accuracy: 0.6882\n",
            "Epoch 19/20\n",
            "800/800 [==============================] - 10s 12ms/step - loss: 0.4782 - categorical_accuracy: 0.8370 - val_loss: 1.4517 - val_categorical_accuracy: 0.6699\n",
            "Epoch 20/20\n",
            "800/800 [==============================] - 10s 12ms/step - loss: 0.4775 - categorical_accuracy: 0.8370 - val_loss: 1.3789 - val_categorical_accuracy: 0.6913\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "H2gO_n5ygUik"
      },
      "source": [
        "#### See the results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aD4bfd2xgUim",
        "colab": {}
      },
      "source": [
        "validation_results = rnn_model.predict(val_batch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fLhZ2UDcgUir",
        "outputId": "aedbfc3f-0ce0-41ae-876e-70a551482c10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "validation_results[0].shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20, 34)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RfEdPXr1gUit",
        "outputId": "0b6f0c2b-35b3-4380-ad03-3c0db0c64f8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "show_text(np.argmax(validation_results[20],axis=1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'thousand one hundred two hundred five thousand seven \\n eight thousand eight \\n five \\n nine \\n five thousand ten'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEuasDlNg4n6",
        "colab_type": "code",
        "outputId": "070e29d1-a88c-40aa-e28b-61a8f77c1ccf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "#### Comparing the label and predictions\n",
        "for i,word_idx in  enumerate(np.argmax(validation_results[20],axis=1)):\n",
        "  print (f'Label: {repr(tokenizer(show_text(valid_label[20]))[i])} ---> Prediction: {repr(vocab.itos[word_idx])} ')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label: '\\n ' ---> Prediction: 'thousand' \n",
            "Label: 'eight' ---> Prediction: 'one' \n",
            "Label: 'thousand' ---> Prediction: 'hundred' \n",
            "Label: 'six' ---> Prediction: 'two' \n",
            "Label: '\\n ' ---> Prediction: 'hundred' \n",
            "Label: 'eight' ---> Prediction: 'five' \n",
            "Label: 'thousand' ---> Prediction: 'thousand' \n",
            "Label: 'seven' ---> Prediction: 'seven' \n",
            "Label: '\\n ' ---> Prediction: '\\n' \n",
            "Label: 'eight' ---> Prediction: 'eight' \n",
            "Label: 'thousand' ---> Prediction: 'thousand' \n",
            "Label: 'eight' ---> Prediction: 'eight' \n",
            "Label: '\\n ' ---> Prediction: '\\n' \n",
            "Label: 'eight' ---> Prediction: 'five' \n",
            "Label: 'thousand' ---> Prediction: '\\n' \n",
            "Label: 'nine' ---> Prediction: 'nine' \n",
            "Label: '\\n ' ---> Prediction: '\\n' \n",
            "Label: 'eight' ---> Prediction: 'five' \n",
            "Label: 'thousand' ---> Prediction: 'thousand' \n",
            "Label: 'ten' ---> Prediction: 'ten' \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ymn5-7eegUiw",
        "outputId": "356272cc-0c22-4d18-9edb-0f2bf990f3eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "show_text(valid_label[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n eight thousand one \\n eight thousand two \\n eight thousand three \\n eight thousand four \\n eight thousand five'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1hJcZd4TbprQ",
        "colab_type": "text"
      },
      "source": [
        "As can be seen, performance improved quite a bit with the implmentation of custom RNN model. Let's try real RNN, GRU and LSTM models to see what happens."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHsguJfA0IDL",
        "colab_type": "text"
      },
      "source": [
        "#### Simple RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Thwq-UlMeSJi",
        "colab_type": "code",
        "outputId": "0be6fe77-63b2-45db-f3ee-962a3c9385c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(len(vocab.itos), 64, input_length=(train_x.shape[1])))\n",
        "model.add(Bidirectional(SimpleRNN(150,return_sequences=True)))\n",
        "model.add(Dense(len(vocab.itos), activation='softmax'))\n",
        "\n",
        "### Compile the model\n",
        "adam = Adam(lr=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['categorical_accuracy'])\n",
        "\n",
        "#earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=0, mode='auto')\n",
        "#history = model.fit(train_x, train_y, epochs=10, batch_size=64, verbose=1,validation_data=(valid_x,valid_y))\n",
        "history = model.fit(train_batch, epochs=10, verbose=1,validation_data=val_batch)\n",
        "#print model.summary()\n",
        "print(model.summary())\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "800/800 [==============================] - 22s 28ms/step - loss: 0.1194 - categorical_accuracy: 0.9618 - val_loss: 0.1008 - val_categorical_accuracy: 0.9714\n",
            "Epoch 2/10\n",
            "800/800 [==============================] - 22s 27ms/step - loss: 0.0802 - categorical_accuracy: 0.9747 - val_loss: 0.1458 - val_categorical_accuracy: 0.9654\n",
            "Epoch 3/10\n",
            "800/800 [==============================] - 22s 27ms/step - loss: 0.0866 - categorical_accuracy: 0.9736 - val_loss: 0.1566 - val_categorical_accuracy: 0.9642\n",
            "Epoch 4/10\n",
            "800/800 [==============================] - 22s 27ms/step - loss: 0.0844 - categorical_accuracy: 0.9738 - val_loss: 0.1365 - val_categorical_accuracy: 0.9639\n",
            "Epoch 5/10\n",
            "800/800 [==============================] - 22s 28ms/step - loss: 0.0877 - categorical_accuracy: 0.9732 - val_loss: 0.1419 - val_categorical_accuracy: 0.9653\n",
            "Epoch 6/10\n",
            "800/800 [==============================] - 23s 29ms/step - loss: 0.0878 - categorical_accuracy: 0.9730 - val_loss: 0.1274 - val_categorical_accuracy: 0.9655\n",
            "Epoch 7/10\n",
            "800/800 [==============================] - 23s 28ms/step - loss: 0.0898 - categorical_accuracy: 0.9727 - val_loss: 0.1680 - val_categorical_accuracy: 0.9641\n",
            "Epoch 8/10\n",
            "800/800 [==============================] - 23s 29ms/step - loss: 0.0892 - categorical_accuracy: 0.9727 - val_loss: 0.1308 - val_categorical_accuracy: 0.9652\n",
            "Epoch 9/10\n",
            "800/800 [==============================] - 23s 28ms/step - loss: 0.0888 - categorical_accuracy: 0.9727 - val_loss: 0.1483 - val_categorical_accuracy: 0.9649\n",
            "Epoch 10/10\n",
            "800/800 [==============================] - 23s 28ms/step - loss: 0.1130 - categorical_accuracy: 0.9664 - val_loss: 0.6182 - val_categorical_accuracy: 0.8340\n",
            "Model: \"sequential_19\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_23 (Embedding)     (None, 20, 64)            2176      \n",
            "_________________________________________________________________\n",
            "bidirectional_5 (Bidirection (None, 20, 300)           64500     \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 20, 34)            10234     \n",
            "=================================================================\n",
            "Total params: 76,910\n",
            "Trainable params: 76,910\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14080, 20, 34)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "raCzCC_4pwn3"
      },
      "source": [
        "#### See the results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IjjaF_CZpwn5",
        "colab": {}
      },
      "source": [
        "validation_results = model.predict(val_batch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "ee288d67-c136-4a46-b87a-8b892d5d8f69",
        "id": "aR9N6bEtpwn8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "validation_results[0].shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20, 34)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "e4d5e9f7-0a6b-4495-90f4-91a5f07290ca",
        "id": "glzBYhxLpwn_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "show_text(np.argmax(validation_results[20],axis=1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n eight hundred three \\n four hundred seven \\n four hundred eight \\n eight hundred nine \\n four thousand three'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "11f3d092-6c44-410e-8dad-1f9db5691920",
        "id": "_bnV3nFvpwoF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "#### Comparing the label and predictions\n",
        "for i,word_idx in  enumerate(np.argmax(validation_results[20],axis=1)):\n",
        "  print (f'Label: {repr(tokenizer(show_text(valid_label[20]))[i])} ---> Prediction: {repr(vocab.itos[word_idx])} ')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label: '\\n ' ---> Prediction: '\\n' \n",
            "Label: 'eight' ---> Prediction: 'eight' \n",
            "Label: 'thousand' ---> Prediction: 'hundred' \n",
            "Label: 'six' ---> Prediction: 'three' \n",
            "Label: '\\n ' ---> Prediction: '\\n' \n",
            "Label: 'eight' ---> Prediction: 'four' \n",
            "Label: 'thousand' ---> Prediction: 'hundred' \n",
            "Label: 'seven' ---> Prediction: 'seven' \n",
            "Label: '\\n ' ---> Prediction: '\\n' \n",
            "Label: 'eight' ---> Prediction: 'four' \n",
            "Label: 'thousand' ---> Prediction: 'hundred' \n",
            "Label: 'eight' ---> Prediction: 'eight' \n",
            "Label: '\\n ' ---> Prediction: '\\n' \n",
            "Label: 'eight' ---> Prediction: 'eight' \n",
            "Label: 'thousand' ---> Prediction: 'hundred' \n",
            "Label: 'nine' ---> Prediction: 'nine' \n",
            "Label: '\\n ' ---> Prediction: '\\n' \n",
            "Label: 'eight' ---> Prediction: 'four' \n",
            "Label: 'thousand' ---> Prediction: 'thousand' \n",
            "Label: 'ten' ---> Prediction: 'three' \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "24632458-3bac-4db3-f136-b1fc6c83e7f8",
        "id": "b77IIbJqpwoI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "show_text(valid_label[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n eight thousand one \\n eight thousand two \\n eight thousand three \\n eight thousand four \\n eight thousand five'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4QGIUrBepwoK"
      },
      "source": [
        "As expected, performance is so much better with bi-directional RNN."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfIZI6mQt3qo",
        "colab_type": "text"
      },
      "source": [
        "#### GRU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "f023ae8b-b9c0-4bb7-a99d-20bbdeebb8f7",
        "id": "1kR0HdWSt-fX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(len(vocab.itos), output_dim=64, input_length=train_x.shape[1]))\n",
        "model.add( Bidirectional(GRU(units=150,return_sequences=True)))\n",
        "model.add(Dense(len(vocab.itos), activation='softmax'))\n",
        "\n",
        "### Compile the model\n",
        "adam = Adam(lr=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['categorical_accuracy'])\n",
        "\n",
        "#earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=0, mode='auto')\n",
        "#history = model.fit(train_x, train_y, epochs=10, batch_size=64, verbose=1,validation_data=(valid_x,valid_y))\n",
        "history = model.fit(train_batch, epochs=5, verbose=1,validation_data=val_batch)\n",
        "print (model.summary())\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "800/800 [==============================] - 26s 33ms/step - loss: 0.1153 - categorical_accuracy: 0.9690 - val_loss: 0.0999 - val_categorical_accuracy: 0.9685\n",
            "Epoch 2/5\n",
            "800/800 [==============================] - 25s 32ms/step - loss: 0.0031 - categorical_accuracy: 0.9993 - val_loss: 0.1242 - val_categorical_accuracy: 0.9633\n",
            "Epoch 3/5\n",
            "800/800 [==============================] - 25s 32ms/step - loss: 0.0424 - categorical_accuracy: 0.9876 - val_loss: 0.1048 - val_categorical_accuracy: 0.9744\n",
            "Epoch 4/5\n",
            "800/800 [==============================] - 26s 32ms/step - loss: 0.0187 - categorical_accuracy: 0.9942 - val_loss: 0.1692 - val_categorical_accuracy: 0.9683\n",
            "Epoch 5/5\n",
            "800/800 [==============================] - 26s 32ms/step - loss: 0.0266 - categorical_accuracy: 0.9919 - val_loss: 0.1102 - val_categorical_accuracy: 0.9791\n",
            "Model: \"sequential_21\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_25 (Embedding)     (None, 20, 64)            2176      \n",
            "_________________________________________________________________\n",
            "bidirectional_7 (Bidirection (None, 20, 300)           194400    \n",
            "_________________________________________________________________\n",
            "dense_23 (Dense)             (None, 20, 34)            10234     \n",
            "=================================================================\n",
            "Total params: 206,810\n",
            "Trainable params: 206,810\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "j_HaLoqIrB9A"
      },
      "source": [
        "#### See the results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zN-FQNI0rB9C",
        "colab": {}
      },
      "source": [
        "validation_results = model.predict(val_batch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "d50c4171-04ba-451a-b146-04adbd8389d6",
        "id": "icz6d5PkrB9G",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "validation_results[0].shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20, 34)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "5c671883-e19f-43c4-8236-5ab2fe461b7e",
        "id": "aI27badPrB9K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "show_text(np.argmax(validation_results[20],axis=1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n eight thousand six \\n eight thousand seven \\n eight thousand eight \\n eight thousand nine \\n eight \\n nine'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "c16bc062-6a46-4f87-f1cc-6e4228573b75",
        "id": "WIz_jzvirB9M",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "#### Comparing the label and predictions\n",
        "for i,word_idx in  enumerate(np.argmax(validation_results[20],axis=1)):\n",
        "  print (f'Label: {repr(tokenizer(show_text(valid_label[20]))[i])} ---> Prediction: {repr(vocab.itos[word_idx])} ')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label: '\\n ' ---> Prediction: '\\n' \n",
            "Label: 'eight' ---> Prediction: 'eight' \n",
            "Label: 'thousand' ---> Prediction: 'thousand' \n",
            "Label: 'six' ---> Prediction: 'six' \n",
            "Label: '\\n ' ---> Prediction: '\\n' \n",
            "Label: 'eight' ---> Prediction: 'eight' \n",
            "Label: 'thousand' ---> Prediction: 'thousand' \n",
            "Label: 'seven' ---> Prediction: 'seven' \n",
            "Label: '\\n ' ---> Prediction: '\\n' \n",
            "Label: 'eight' ---> Prediction: 'eight' \n",
            "Label: 'thousand' ---> Prediction: 'thousand' \n",
            "Label: 'eight' ---> Prediction: 'eight' \n",
            "Label: '\\n ' ---> Prediction: '\\n' \n",
            "Label: 'eight' ---> Prediction: 'eight' \n",
            "Label: 'thousand' ---> Prediction: 'thousand' \n",
            "Label: 'nine' ---> Prediction: 'nine' \n",
            "Label: '\\n ' ---> Prediction: '\\n' \n",
            "Label: 'eight' ---> Prediction: 'eight' \n",
            "Label: 'thousand' ---> Prediction: '\\n' \n",
            "Label: 'ten' ---> Prediction: 'nine' \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "24632458-3bac-4db3-f136-b1fc6c83e7f8",
        "id": "apax64ForB9O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "show_text(valid_label[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n eight thousand one \\n eight thousand two \\n eight thousand three \\n eight thousand four \\n eight thousand five'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NE3_V8oVrB9Q"
      },
      "source": [
        "Wow, bidirectional is the solution for it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "7905d1af-8527-4193-dbb1-3b5ae2aac6f8",
        "id": "dDXpMarkugP0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "source": [
        "#### Let's try the stateful\n",
        "model = Sequential()\n",
        "model.add(Embedding(len(vocab.itos), 64, input_length=train_x.shape[1],batch_input_shape=(BATCH_SIZE,train_x.shape[1])))\n",
        "model.add(Bidirectional(GRU(150,stateful=True,return_sequences=True)))\n",
        "model.add(Dense(len(vocab.itos), activation='softmax'))\n",
        "\n",
        "### Compile the model\n",
        "adam = Adam(lr=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['categorical_accuracy'])\n",
        "\n",
        "#earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=0, mode='auto')\n",
        "#history = model.fit(train_x, train_y, epochs=10, batch_size=64, verbose=1,validation_data=(valid_x,valid_y))\n",
        "history = model.fit(train_batch, epochs=5, verbose=1,validation_data=val_batch)\n",
        "print (model.summary())\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "800/800 [==============================] - 28s 36ms/step - loss: 0.1874 - categorical_accuracy: 0.9526 - val_loss: 0.2898 - val_categorical_accuracy: 0.9261\n",
            "Epoch 2/5\n",
            "800/800 [==============================] - 28s 35ms/step - loss: 0.0574 - categorical_accuracy: 0.9822 - val_loss: 0.3142 - val_categorical_accuracy: 0.9130\n",
            "Epoch 3/5\n",
            "800/800 [==============================] - 28s 34ms/step - loss: 0.0541 - categorical_accuracy: 0.9833 - val_loss: 0.5533 - val_categorical_accuracy: 0.8627\n",
            "Epoch 4/5\n",
            "800/800 [==============================] - 25s 32ms/step - loss: 0.1043 - categorical_accuracy: 0.9742 - val_loss: 0.3916 - val_categorical_accuracy: 0.8973\n",
            "Epoch 5/5\n",
            "800/800 [==============================] - 25s 32ms/step - loss: 0.0978 - categorical_accuracy: 0.9740 - val_loss: 0.2155 - val_categorical_accuracy: 0.9442\n",
            "Model: \"sequential_22\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_26 (Embedding)     (64, 20, 64)              2176      \n",
            "_________________________________________________________________\n",
            "bidirectional_8 (Bidirection (64, 20, 300)             194400    \n",
            "_________________________________________________________________\n",
            "dense_24 (Dense)             (64, 20, 34)              10234     \n",
            "=================================================================\n",
            "Total params: 206,810\n",
            "Trainable params: 206,810\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zR9xN7PyW6I",
        "colab_type": "text"
      },
      "source": [
        "#### LSTM\n",
        "\n",
        "Let's do one more experiment. Try both uni directional and bi-directional network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "11a6b7e3-ef0c-47b1-aa46-389526a1f530",
        "id": "mruLse_dMdxP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(len(vocab.itos), output_dim=64, input_length=train_x.shape[1]))\n",
        "model.add(LSTM(units=64, return_sequences=True))\n",
        "model.add(Dense(len(vocab.itos), activation='softmax'))\n",
        "\n",
        "### Compile the model\n",
        "adam = Adam(lr=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['categorical_accuracy'])\n",
        "\n",
        "#earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=0, mode='auto')\n",
        "#history = model.fit(train_x, train_y, epochs=10, batch_size=64, verbose=1,validation_data=(valid_x,valid_y))\n",
        "history = model.fit(train_batch, epochs=10, verbose=1,validation_data=val_batch)\n",
        "print (model.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "800/800 [==============================] - 20s 25ms/step - loss: 1.2076 - categorical_accuracy: 0.5462 - val_loss: 1.9996 - val_categorical_accuracy: 0.5106\n",
            "Epoch 2/10\n",
            "800/800 [==============================] - 20s 25ms/step - loss: 0.4926 - categorical_accuracy: 0.8228 - val_loss: 1.9235 - val_categorical_accuracy: 0.5982\n",
            "Epoch 3/10\n",
            "800/800 [==============================] - 18s 22ms/step - loss: 0.4233 - categorical_accuracy: 0.8425 - val_loss: 1.9903 - val_categorical_accuracy: 0.6149\n",
            "Epoch 4/10\n",
            "800/800 [==============================] - 18s 23ms/step - loss: 0.4168 - categorical_accuracy: 0.8432 - val_loss: 2.0843 - val_categorical_accuracy: 0.6276\n",
            "Epoch 5/10\n",
            "800/800 [==============================] - 18s 23ms/step - loss: 0.4150 - categorical_accuracy: 0.8430 - val_loss: 2.1842 - val_categorical_accuracy: 0.6334\n",
            "Epoch 6/10\n",
            "800/800 [==============================] - 17s 21ms/step - loss: 0.4160 - categorical_accuracy: 0.8428 - val_loss: 2.3218 - val_categorical_accuracy: 0.6178\n",
            "Epoch 7/10\n",
            "800/800 [==============================] - 17s 21ms/step - loss: 0.4115 - categorical_accuracy: 0.8437 - val_loss: 2.3553 - val_categorical_accuracy: 0.6267\n",
            "Epoch 8/10\n",
            "800/800 [==============================] - 17s 21ms/step - loss: 0.4116 - categorical_accuracy: 0.8437 - val_loss: 2.4414 - val_categorical_accuracy: 0.6297\n",
            "Epoch 9/10\n",
            "800/800 [==============================] - 17s 21ms/step - loss: 0.4100 - categorical_accuracy: 0.8439 - val_loss: 2.4278 - val_categorical_accuracy: 0.6131\n",
            "Epoch 10/10\n",
            "800/800 [==============================] - 17s 21ms/step - loss: 0.4107 - categorical_accuracy: 0.8438 - val_loss: 2.5171 - val_categorical_accuracy: 0.6151\n",
            "Model: \"sequential_23\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_27 (Embedding)     (None, 20, 64)            2176      \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 20, 64)            33024     \n",
            "_________________________________________________________________\n",
            "dense_25 (Dense)             (None, 20, 34)            2210      \n",
            "=================================================================\n",
            "Total params: 37,410\n",
            "Trainable params: 37,410\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "94510a40-cabb-4b7b-ab8a-d1a8599d5f33",
        "id": "8dbNaJ2KMlyD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "source": [
        "#### Let's try the stateful\n",
        "model = Sequential()\n",
        "model.add(Embedding(len(vocab.itos), 64, input_length=train_x.shape[1],batch_input_shape=(BATCH_SIZE,train_x.shape[1])))\n",
        "model.add(Bidirectional( LSTM(units=64, return_sequences=True)))\n",
        "model.add(Dense(len(vocab.itos), activation='softmax'))\n",
        "\n",
        "### Compile the model\n",
        "adam = Adam(lr=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['categorical_accuracy'])\n",
        "\n",
        "#earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=0, mode='auto')\n",
        "#history = model.fit(train_x, train_y, epochs=10, batch_size=64, verbose=1,validation_data=(valid_x,valid_y))\n",
        "history = model.fit(train_batch, epochs=5, verbose=1,validation_data=val_batch)\n",
        "print (model.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "800/800 [==============================] - 17s 21ms/step - loss: 0.1636 - categorical_accuracy: 0.9531 - val_loss: 0.1349 - val_categorical_accuracy: 0.9657\n",
            "Epoch 2/5\n",
            "800/800 [==============================] - 17s 21ms/step - loss: 0.0128 - categorical_accuracy: 0.9963 - val_loss: 0.1241 - val_categorical_accuracy: 0.9744\n",
            "Epoch 3/5\n",
            "800/800 [==============================] - 17s 21ms/step - loss: 0.0049 - categorical_accuracy: 0.9988 - val_loss: 0.1029 - val_categorical_accuracy: 0.9801\n",
            "Epoch 4/5\n",
            "800/800 [==============================] - 17s 21ms/step - loss: 0.0033 - categorical_accuracy: 0.9992 - val_loss: 0.1164 - val_categorical_accuracy: 0.9762\n",
            "Epoch 5/5\n",
            "800/800 [==============================] - 17s 21ms/step - loss: 0.0032 - categorical_accuracy: 0.9992 - val_loss: 0.0973 - val_categorical_accuracy: 0.9801\n",
            "Model: \"sequential_24\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_28 (Embedding)     (64, 20, 64)              2176      \n",
            "_________________________________________________________________\n",
            "bidirectional_9 (Bidirection (64, 20, 128)             66048     \n",
            "_________________________________________________________________\n",
            "dense_26 (Dense)             (64, 20, 34)              4386      \n",
            "=================================================================\n",
            "Total params: 72,610\n",
            "Trainable params: 72,610\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-7d2FgsBstql"
      },
      "source": [
        "#### See the results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "I-sSsvaFstqm",
        "colab": {}
      },
      "source": [
        "validation_results = model.predict(val_batch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "cd757b31-35b2-4a4c-fd06-87e04b74268e",
        "id": "oTKKoV-Jstqo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "validation_results[0].shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20, 34)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "74289841-a781-4354-9895-de1a8a27aaee",
        "id": "xMImdW0Dstqq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "show_text(np.argmax(validation_results[20],axis=1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n eight thousand six \\n eight thousand seven \\n eight thousand eight \\n eight thousand nine \\n eight thousand nine'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "9b83a7ca-beb2-477a-a715-52711f651fd5",
        "id": "8lUdz-43stqs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "#### Comparing the label and predictions\n",
        "for i,word_idx in  enumerate(np.argmax(validation_results[20],axis=1)):\n",
        "  print (f'Label: {repr(tokenizer(show_text(valid_label[20]))[i])} ---> Prediction: {repr(vocab.itos[word_idx])} ')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label: '\\n ' ---> Prediction: '\\n' \n",
            "Label: 'eight' ---> Prediction: 'eight' \n",
            "Label: 'thousand' ---> Prediction: 'thousand' \n",
            "Label: 'six' ---> Prediction: 'six' \n",
            "Label: '\\n ' ---> Prediction: '\\n' \n",
            "Label: 'eight' ---> Prediction: 'eight' \n",
            "Label: 'thousand' ---> Prediction: 'thousand' \n",
            "Label: 'seven' ---> Prediction: 'seven' \n",
            "Label: '\\n ' ---> Prediction: '\\n' \n",
            "Label: 'eight' ---> Prediction: 'eight' \n",
            "Label: 'thousand' ---> Prediction: 'thousand' \n",
            "Label: 'eight' ---> Prediction: 'eight' \n",
            "Label: '\\n ' ---> Prediction: '\\n' \n",
            "Label: 'eight' ---> Prediction: 'eight' \n",
            "Label: 'thousand' ---> Prediction: 'thousand' \n",
            "Label: 'nine' ---> Prediction: 'nine' \n",
            "Label: '\\n ' ---> Prediction: '\\n' \n",
            "Label: 'eight' ---> Prediction: 'eight' \n",
            "Label: 'thousand' ---> Prediction: 'thousand' \n",
            "Label: 'ten' ---> Prediction: 'nine' \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "905558ff-09c6-40ff-9ef7-f3dd20df40a8",
        "id": "R0CzUkQestqu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "show_text(valid_label[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n eight thousand one \\n eight thousand two \\n eight thousand three \\n eight thousand four \\n eight thousand five'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OjVGQCxvstqy"
      },
      "source": [
        "Wow, bidirectional is the solution for it. Unidirectional is not optimum."
      ]
    }
  ]
}