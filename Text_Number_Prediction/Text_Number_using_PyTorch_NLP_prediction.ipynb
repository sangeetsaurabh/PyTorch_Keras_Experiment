{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "colab": {
      "name": "Text Number using PyTorch NLP prediction.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "J9pubLZDi6h4",
        "ykBs_0d7i6iQ",
        "CfShdqjKi6jM",
        "1nkjC28Ai6kj",
        "bY4gJclpi6lg",
        "ML3Kmou0AwMy",
        "g394ECsvi6nB",
        "pv4d2inKErAi",
        "VHAZLiedi6oi"
      ],
      "machine_shape": "hm"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfmjC5UV0qv2",
        "colab_type": "text"
      },
      "source": [
        "## Predict the next number in the sequence\n",
        "\n",
        "Given a set of numbers, goal of the model is to predict next number in the sequence. \n",
        "\n",
        "For example, model can be given input like - eight thousand one , eight thousand two , eight thousand three , eight thousand four , eight thousand five , eight thousand six , eight thousand seven , eight thousand eight , eight thousand nine , eight thousand ten , eight thousand eleven , eight thousand twelve....\n",
        "\n",
        "Model will predict next number given the one input. Model in this notebook predicts 21st word given 20 words like above (last step prediction).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ynTYO4FEDwJu",
        "colab_type": "text"
      },
      "source": [
        "### Prepare the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "149iYfEnjyLR",
        "colab_type": "code",
        "outputId": "300a7cb2-1834-444e-c1a0-e98a4e1e5932",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "source": [
        "#### Install the right version of PyTorch\n",
        "!pip install torchtext==0.6.0\n",
        "import torchtext\n",
        "print(torchtext.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torchtext==0.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f2/17/e7c588245aece7aa93f360894179374830daf60d7ed0bbb59332de3b3b61/torchtext-0.6.0-py3-none-any.whl (64kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 2.5MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3b/88/49e772d686088e1278766ad68a463513642a2a877487decbd691dec02955/sentencepiece-0.1.90-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 9.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6.0) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6.0) (1.18.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6.0) (4.41.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6.0) (1.12.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6.0) (1.5.0+cu101)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.6.0) (2020.4.5.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.6.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.6.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.6.0) (2.9)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->torchtext==0.6.0) (0.16.0)\n",
            "Installing collected packages: sentencepiece, torchtext\n",
            "  Found existing installation: torchtext 0.3.1\n",
            "    Uninstalling torchtext-0.3.1:\n",
            "      Successfully uninstalled torchtext-0.3.1\n",
            "Successfully installed sentencepiece-0.1.90 torchtext-0.6.0\n",
            "0.6.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RR4eRGbbjJHU",
        "colab_type": "code",
        "outputId": "b04f5cb6-4b26-4611-fe1b-3d0db5693332",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRJv3gWMi6g-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#### Setting up path to import important data preparation Python module\n",
        "import sys\n",
        "import os\n",
        "sys.path.append('/content/drive/My Drive/Colab Notebooks/torch_pipe/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItOt_tGZi6hJ",
        "colab_type": "code",
        "outputId": "b4e48858-bb50-4e01-e51d-4eaddb7f7ffd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "os.getcwd()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bt_V_qOIi6hR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#### Importing all the appropriate Torch Module\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from Util.human_language_modeling import *\n",
        "from torch.utils.data import DataLoader ### Custom dataloader to load the data\n",
        "import torch.nn.functional as F\n",
        "import time\n",
        "import logging"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7iRyHrqii6hY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import logging\n",
        "logger = logging.getLogger()\n",
        "fhandler = logging.FileHandler(filename='mylog.log', mode='a')\n",
        "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
        "fhandler.setFormatter(formatter)\n",
        "logger.addHandler(fhandler)\n",
        "logger.setLevel(logging.DEBUG)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4Gzgd_Ei6hf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 64 ## defining the batch size\n",
        "bptt = 20 ## back propogration through LSTM\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6ZYTThai6hl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NLP = spacy.load('en_core_web_sm')\n",
        "def tokenizer(comment):\n",
        "    comment = re.sub(\n",
        "        r\"[\\*\\\"“”\\n\\\\…\\+\\-\\/\\=\\(\\)‘•:\\[\\]\\|’\\!;\\.]\", \" \", \n",
        "        str(comment))\n",
        "    comment = re.sub(r\"[ ]+\", \" \", comment)\n",
        "    comment = re.sub(r\"\\!+\", \"!\", comment)\n",
        "    comment = re.sub(r\"\\,+\", \",\", comment)\n",
        "    comment = re.sub(r\"\\?+\", \"?\", comment)\n",
        "    cleanr = re.compile('<.*?>')\n",
        "    cleanr = re.compile('<>')\n",
        "    comment = re.sub(cleanr, '', comment)\n",
        "    #if (len(comment) > MAX_CHARS):\n",
        "    #   comment = comment[:MAX_CHARS]\n",
        "    return[x.text for x in NLP.tokenizer(comment) if x.text != \" \"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgAD2zDri6hr",
        "colab_type": "code",
        "outputId": "003e1226-d0aa-4c1e-86db-e7b4eb076b6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tokenizer(\"I am king \\n ,fdds  , king\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['I', 'am', 'king', ',', 'fdds', ',', 'king']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srAakqVfi6hy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### A simplie python function to show text given an array of vectors\n",
        "def show_text(input_vector):\n",
        "    separator = ' '\n",
        "    txt = separator.join([vocab.itos[i] for i in input_vector])\n",
        "    return txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9pubLZDi6h4",
        "colab_type": "text"
      },
      "source": [
        "#### Download the train and validation data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dv4ludI1i6h5",
        "colab_type": "code",
        "outputId": "f684fa65-e69a-49ad-9fa3-52dbad9fb282",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tokenizer = get_tokenizer(\"spacy\")\n",
        "train_dataset_old, valid_dataset_old = HumanNumbers(root='data',data_select=('train', 'valid'))\n",
        "vocab = train_dataset_old.get_vocab()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0lines [00:00, ?lines/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "<function tokenizer at 0x7f27757ae730>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8001lines [00:00, 20885.17lines/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-MF6hGBi6iB",
        "colab_type": "code",
        "outputId": "685ee8e8-2f70-420c-ab18-2b85e5e63c00",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tokenizer = get_tokenizer(\"spacy\")\n",
        "train_dataset, valid_dataset = HumanNumbers(root='data',bptt=bptt,batch_size=BATCH_SIZE,data_select=('train', 'valid'))\n",
        "vocab = train_dataset.get_vocab()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3606lines [00:00, 36055.31lines/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "<function tokenizer at 0x7f27757ae730>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8001lines [00:00, 35046.05lines/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "51200\n",
            "51200\n",
            "torch.Size([51200, 20])\n",
            "torch.Size([51200, 20])\n",
            "14080\n",
            "14080\n",
            "torch.Size([14080, 20])\n",
            "torch.Size([14080, 20])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bc6RJenJi6iJ",
        "colab_type": "code",
        "outputId": "c677e947-5a89-41de-f641-db46aad7bf5b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "13056/64"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "204.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykBs_0d7i6iQ",
        "colab_type": "text"
      },
      "source": [
        "#### Analyze the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAhlE_owi6iR",
        "colab_type": "code",
        "outputId": "d02e2e7e-58fd-48e2-b160-1d289e2941fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print (f\"Train size: {len(train_dataset)}\")\n",
        "print (f\"Validation size: {len(valid_dataset)}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train size: 51200\n",
            "Validation size: 14080\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zch5y88i6iY",
        "colab_type": "code",
        "outputId": "ec01dff5-24ee-492d-8438-e4be102a4091",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print (f\"The number of unique words in train dataset is {len(set(train_dataset_old.raw_data))}. \")\n",
        "print (f\"The number of unique words in Valid dataset is {len(set(valid_dataset_old.raw_data))}. \")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The number of unique words in train dataset is 32. \n",
            "The number of unique words in Valid dataset is 32. \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R3e8wqwvi6if",
        "colab_type": "text"
      },
      "source": [
        "##### Analysis on Vocab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOpmT4nPi6if",
        "colab_type": "code",
        "outputId": "3dc15aaa-e38e-4e6c-8533-818ab45093a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "### See the all the tokens in the vocab\n",
        "vocab.itos"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<unk>',\n",
              " '<pad>',\n",
              " '\\n',\n",
              " 'hundred',\n",
              " 'thousand',\n",
              " 'five',\n",
              " 'four',\n",
              " 'one',\n",
              " 'seven',\n",
              " 'six',\n",
              " 'three',\n",
              " 'two',\n",
              " 'eight',\n",
              " 'nine',\n",
              " 'eighty',\n",
              " 'fifty',\n",
              " 'forty',\n",
              " 'ninety',\n",
              " 'seventy',\n",
              " 'sixty',\n",
              " 'thirty',\n",
              " 'twenty',\n",
              " 'eighteen',\n",
              " 'eleven',\n",
              " 'fifteen',\n",
              " 'fourteen',\n",
              " 'nineteen',\n",
              " 'seventeen',\n",
              " 'sixteen',\n",
              " 'ten',\n",
              " 'thirteen',\n",
              " 'twelve',\n",
              " 'xxBOF',\n",
              " 'xxEOF']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKx_apMNi6il",
        "colab_type": "code",
        "outputId": "438e22cc-7066-4a12-b08c-34f6b00c9da1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(vocab.itos)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "34"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "z9iP_0a0i6ip",
        "colab_type": "code",
        "outputId": "01165d97-29c2-4c0f-dfaf-42564ff6511b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#### See the frequency of each of the tokens in the train\n",
        "vocab.freqs"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'\\n': 8000,\n",
              "         'eight': 1520,\n",
              "         'eighteen': 80,\n",
              "         'eighty': 800,\n",
              "         'eleven': 80,\n",
              "         'fifteen': 80,\n",
              "         'fifty': 800,\n",
              "         'five': 2520,\n",
              "         'forty': 800,\n",
              "         'four': 2520,\n",
              "         'fourteen': 80,\n",
              "         'hundred': 7200,\n",
              "         'nine': 1520,\n",
              "         'nineteen': 80,\n",
              "         'ninety': 800,\n",
              "         'one': 2520,\n",
              "         'seven': 2520,\n",
              "         'seventeen': 80,\n",
              "         'seventy': 800,\n",
              "         'six': 2520,\n",
              "         'sixteen': 80,\n",
              "         'sixty': 800,\n",
              "         'ten': 80,\n",
              "         'thirteen': 80,\n",
              "         'thirty': 800,\n",
              "         'thousand': 7000,\n",
              "         'three': 2520,\n",
              "         'twelve': 80,\n",
              "         'twenty': 800,\n",
              "         'two': 2520,\n",
              "         'xxBOF': 1,\n",
              "         'xxEOF': 1})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D94wHIfVi6iv",
        "colab_type": "text"
      },
      "source": [
        "#### See the texts in input and label data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYeAz21Ji6iw",
        "colab_type": "code",
        "outputId": "bbc8f7f5-2324-413a-ed69-6058c646754e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "train_dataset.input_data[1].numpy()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 2,  7,  2, 11,  2, 10,  2,  6,  2,  5,  2,  9,  2,  8,  2, 12,  2,\n",
              "       13,  2, 29])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgoB68VRi6i1",
        "colab_type": "code",
        "outputId": "16f54faa-d2aa-4021-8e19-5713b74b7ee8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "train_dataset.label_data[1].numpy()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 7,  2, 11,  2, 10,  2,  6,  2,  5,  2,  9,  2,  8,  2, 12,  2, 13,\n",
              "        2, 29,  2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iy_0rBsqi6i5",
        "colab_type": "code",
        "outputId": "1632e63d-b423-4e78-e67b-b8090f9b2938",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "show_text(train_dataset.input_data[1].numpy())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n one \\n two \\n three \\n four \\n five \\n six \\n seven \\n eight \\n nine \\n ten'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpVapQ80i6jA",
        "colab_type": "code",
        "outputId": "ddc1c97e-e7e4-4a84-d714-07b5924458d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "show_text(train_dataset.label_data[1].numpy())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'one \\n two \\n three \\n four \\n five \\n six \\n seven \\n eight \\n nine \\n ten \\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tX3Iiu8yi6jE",
        "colab_type": "code",
        "outputId": "35535de7-52fb-4ef8-97d8-a0ad95d34eee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "show_text(train_dataset.input_data[-2].numpy())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'two hundred eighty \\n two hundred eighty one \\n two hundred eighty two \\n two hundred eighty three \\n two'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18zaIg_Ti6jI",
        "colab_type": "code",
        "outputId": "e45436dd-46b7-4aa8-bb91-4b4f07a721da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "show_text(train_dataset.label_data[-2].numpy())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'hundred eighty \\n two hundred eighty one \\n two hundred eighty two \\n two hundred eighty three \\n two hundred'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfShdqjKi6jM",
        "colab_type": "text"
      },
      "source": [
        "### Implement a fully connected neural network (Model 10 & 11)\n",
        "\n",
        "Given 20 words, this model predicts 21st word."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwJkfLfPi6jN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#### A simple Linear network that processes the word in a sequence\n",
        "class Model0(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.i_h = nn.Embedding(nv,nh)  # green arrow\n",
        "        self.h_h = nn.Linear(nh,nh)     # brown arrow\n",
        "        self.h_o = nn.Linear(nh,nv)     # blue arrow\n",
        "        self.bn = nn.BatchNorm1d(nh)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        h = self.bn(F.relu(self.i_h(x[:,0])))\n",
        "        #print(x.shape[1])\n",
        "        if x.shape[1]>1:\n",
        "            h = h + self.i_h(x[:,1])\n",
        "            h = self.bn(F.relu(self.h_h(h)))\n",
        "        if x.shape[1]>2:\n",
        "            h = h + self.i_h(x[:,2])\n",
        "            h = self.bn(F.relu(self.h_h(h)))\n",
        "        #print(self.h_o(h))\n",
        "        #print(self.h_o(h).shape)\n",
        "        return self.h_o(h)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAKA-Njji6jR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#### A simple Linear network that processes the word in a sequence\n",
        "class Model1(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.i_h = nn.Embedding(nv,nh)  # green arrow\n",
        "        self.h_h = nn.Linear(nh,nh)     # brown arrow\n",
        "        self.h_o = nn.Linear(nh,nv)     # blue arrow\n",
        "        self.bn = nn.BatchNorm1d(nh)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        h = torch.zeros(x.shape[0], nh).to(device=x.device)\n",
        "        for i in range(x.shape[1]):\n",
        "            h = h + self.i_h(x[:,i])\n",
        "            h = self.bn(F.relu(self.h_h(h)))\n",
        "        return self.h_o(h)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Yn79b0Ki6jW",
        "colab_type": "code",
        "outputId": "6206fae0-c9dc-4ccf-c272-b6f4ce3c4714",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "nv = len(vocab.itos)\n",
        "nv"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "34"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwWdI26Ei6jc",
        "colab_type": "code",
        "outputId": "a8a54047-fb9c-49ec-9bb5-9afc95eb4e94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "nh = BATCH_SIZE\n",
        "nh"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZO3JafAi6jj",
        "colab_type": "code",
        "outputId": "a8794ead-fe58-4ee9-d4ae-f5b43e1680b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = Model1().to(device)\n",
        "model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model1(\n",
              "  (i_h): Embedding(34, 64)\n",
              "  (h_h): Linear(in_features=64, out_features=64, bias=True)\n",
              "  (h_o): Linear(in_features=64, out_features=34, bias=True)\n",
              "  (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDM_9sT_i6jn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#### Function to return a batch of data\n",
        "def generate_batch(batch):\n",
        "    #print(len(batch))\n",
        "    text = []\n",
        "    label = []\n",
        "    for entry in batch:\n",
        "        text.append(entry[0].numpy())\n",
        "        label.append(entry[1].numpy())\n",
        "    return torch.tensor(text), torch.tensor(label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v06ZlVgOi6jy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "### Function to train the model\n",
        "def train_func(sub_train_):\n",
        "\n",
        "    # Train the model\n",
        "    train_loss = 0\n",
        "    train_acc = 0\n",
        "    #print(len(sub_train_))\n",
        "    data = DataLoader(sub_train_, batch_size=BATCH_SIZE, shuffle=True,\n",
        "                      collate_fn=generate_batch)\n",
        "    for i, (text, cls) in enumerate(data):\n",
        "        optimizer.zero_grad()\n",
        "        text, cls = text.to(device), cls.to(device)\n",
        "        #print(text.shape)\n",
        "        #print(cls.shape)\n",
        "        output = model(text)\n",
        "        #print(output.shape)\n",
        "        loss = criterion(output, cls[:,-1])\n",
        "        train_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_acc += (output.argmax(1) == cls[:,-1]).sum().item()\n",
        "\n",
        "    # Adjust the learning rate\n",
        "    scheduler.step()\n",
        "\n",
        "    return train_loss / len(sub_train_), train_acc / len(sub_train_)\n",
        "\n",
        "### Function to test the model using validation data\n",
        "def test_func(data_):\n",
        "    loss = 0\n",
        "    acc = 0\n",
        "    data = DataLoader(data_, batch_size=BATCH_SIZE, collate_fn=generate_batch)\n",
        "    for text, cls in data:\n",
        "        text, cls = text.to(device), cls.to(device)\n",
        "        with torch.no_grad():\n",
        "            output = model(text)\n",
        "            loss = criterion(output, cls[:,-1])\n",
        "            loss += loss.item()\n",
        "            acc += (output.argmax(1) == cls[:,-1]).sum().item()\n",
        "\n",
        "    return loss / len(data_), acc / len(data_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "sH3LyEMGi6j3",
        "colab_type": "code",
        "outputId": "dbedc898-5149-4aec-8beb-d4f2f8f576f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#### Train the model\n",
        "from torch.utils.data.dataset import random_split\n",
        "N_EPOCHS = 10\n",
        "min_valid_loss = float('inf')\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1, gamma=0.9)\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "    train_loss, train_acc = train_func(train_dataset)\n",
        "    valid_loss, valid_acc = test_func(valid_dataset)\n",
        "\n",
        "    secs = int(time.time() - start_time)\n",
        "    mins = secs / 60\n",
        "    secs = secs % 60\n",
        "\n",
        "    print('Epoch: %d' %(epoch + 1), \" | time in %d minutes, %d seconds\" %(mins, secs))\n",
        "    print(f'\\tLoss: {train_loss:.4f}(train)\\t|\\tAcc: {train_acc * 100:.1f}%(train)')\n",
        "    print(f'\\tLoss: {valid_loss:.4f}(valid)\\t|\\tAcc: {valid_acc * 100:.1f}%(valid)')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1  | time in 0 minutes, 9 seconds\n",
            "\tLoss: 0.0396(train)\t|\tAcc: 35.8%(train)\n",
            "\tLoss: 0.0003(valid)\t|\tAcc: 46.5%(valid)\n",
            "Epoch: 2  | time in 0 minutes, 9 seconds\n",
            "\tLoss: 0.0261(train)\t|\tAcc: 47.5%(train)\n",
            "\tLoss: 0.0003(valid)\t|\tAcc: 47.3%(valid)\n",
            "Epoch: 3  | time in 0 minutes, 9 seconds\n",
            "\tLoss: 0.0229(train)\t|\tAcc: 51.3%(train)\n",
            "\tLoss: 0.0002(valid)\t|\tAcc: 48.8%(valid)\n",
            "Epoch: 4  | time in 0 minutes, 9 seconds\n",
            "\tLoss: 0.0213(train)\t|\tAcc: 54.2%(train)\n",
            "\tLoss: 0.0002(valid)\t|\tAcc: 49.9%(valid)\n",
            "Epoch: 5  | time in 0 minutes, 8 seconds\n",
            "\tLoss: 0.0202(train)\t|\tAcc: 56.6%(train)\n",
            "\tLoss: 0.0002(valid)\t|\tAcc: 50.5%(valid)\n",
            "Epoch: 6  | time in 0 minutes, 9 seconds\n",
            "\tLoss: 0.0193(train)\t|\tAcc: 58.3%(train)\n",
            "\tLoss: 0.0002(valid)\t|\tAcc: 51.1%(valid)\n",
            "Epoch: 7  | time in 0 minutes, 9 seconds\n",
            "\tLoss: 0.0186(train)\t|\tAcc: 59.8%(train)\n",
            "\tLoss: 0.0002(valid)\t|\tAcc: 51.8%(valid)\n",
            "Epoch: 8  | time in 0 minutes, 8 seconds\n",
            "\tLoss: 0.0180(train)\t|\tAcc: 61.2%(train)\n",
            "\tLoss: 0.0002(valid)\t|\tAcc: 52.6%(valid)\n",
            "Epoch: 9  | time in 0 minutes, 8 seconds\n",
            "\tLoss: 0.0175(train)\t|\tAcc: 62.0%(train)\n",
            "\tLoss: 0.0002(valid)\t|\tAcc: 52.5%(valid)\n",
            "Epoch: 10  | time in 0 minutes, 9 seconds\n",
            "\tLoss: 0.0171(train)\t|\tAcc: 63.2%(train)\n",
            "\tLoss: 0.0003(valid)\t|\tAcc: 52.7%(valid)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Hb9k-7u5Lep",
        "colab_type": "text"
      },
      "source": [
        "Results are not bad considering it's a simple custom sequential network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fx8xfq71i6kB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(model.state_dict(),f='model11.pt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ArftGvgri6kI",
        "colab_type": "text"
      },
      "source": [
        "#### Create the test data to test out models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQu55jyqi6kJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data = valid_dataset.input_data[0:64]\n",
        "test_label = valid_dataset.label_data[0:64]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2sDEuEtmi6kN",
        "colab_type": "code",
        "outputId": "4037a961-70ee-4338-8e73-a8c24d138299",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "test_data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[32,  2, 12,  ...,  2, 12,  4],\n",
              "        [ 2, 12,  4,  ..., 12,  4,  5],\n",
              "        [12,  4,  7,  ...,  4,  5,  2],\n",
              "        ...,\n",
              "        [ 2, 12,  4,  ..., 12,  4, 21],\n",
              "        [12,  4, 28,  ...,  4, 21,  2],\n",
              "        [ 4, 28,  2,  ..., 21,  2, 12]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NkNW8cpBi6kV",
        "colab_type": "code",
        "outputId": "9ead0963-13bc-4ed7-8ef7-ac54e9985d26",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "show_text(test_data[20])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'five \\n eight thousand six \\n eight thousand seven \\n eight thousand eight \\n eight thousand nine \\n eight thousand'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nkjC28Ai6kj",
        "colab_type": "text"
      },
      "source": [
        "#### Model 1 testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-2j7ze2i6kk",
        "colab_type": "code",
        "outputId": "905d52e3-6693-489c-a779-1969ebb5455a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = Model1().to(device)\n",
        "model.load_state_dict(torch.load('model11.pt'))\n",
        "model.eval()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model1(\n",
              "  (i_h): Embedding(34, 64)\n",
              "  (h_h): Linear(in_features=64, out_features=64, bias=True)\n",
              "  (h_o): Linear(in_features=64, out_features=34, bias=True)\n",
              "  (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSi6YGlni6kz",
        "colab_type": "code",
        "outputId": "8461983e-2750-4ae4-8ad9-42053eacc038",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "output = model(test_data.to(device))\n",
        "output.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 34])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k91-WjGmi6k4",
        "colab_type": "code",
        "outputId": "faa80e70-7a52-4c84-8db9-4e6c63108384",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import numpy as np\n",
        "test_predictions = np.argmax(output.cpu().detach().numpy(),axis=1)\n",
        "test_predictions"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([13,  2, 10,  4, 10,  3,  5,  4, 13,  2,  6,  3, 13,  2,  5,  4, 13,\n",
              "        2, 10,  3, 13,  2,  7,  4, 10,  2, 10,  4, 13,  2,  6,  4,  9,  2,\n",
              "       10,  4, 10,  3, 10,  4, 10,  2,  7,  3,  9,  2,  6,  4, 13,  2, 10,\n",
              "        4, 10,  2, 10,  3, 13,  2, 12,  3,  9,  7, 10,  3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KicJ3Qigi6k9",
        "colab_type": "code",
        "outputId": "752e38aa-71e6-4316-f709-72bbb579085c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print (f\"Prediction for 20th sentence is '{vocab.itos[test_predictions[20]]}'\")\n",
        "#print(repr(show_text(output.argmax(20))))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction for 20th sentence is 'nine'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76m2MtnRi6kt",
        "colab_type": "code",
        "outputId": "e9f83db5-61c7-4243-abad-2c68e3ded48a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "show_text(test_data[20])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'five \\n eight thousand six \\n eight thousand seven \\n eight thousand eight \\n eight thousand nine \\n eight thousand'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bY4gJclpi6lg",
        "colab_type": "text"
      },
      "source": [
        "### Multi fully connected model (Model 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Whc6S-F9i6lh",
        "colab_type": "text"
      },
      "source": [
        "Before, we were just predicting the last word in a line of text.  Given 20 tokens, what is token 21?  That approach was throwing away a lot of data.  Why not predict token 2 from token 1, then predict token 3, then predict token 4, and so on?  We will modify our model to do this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgZ7Ji3zi6lj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.i_h = nn.Embedding(nv,nh)\n",
        "        self.h_h = nn.Linear(nh,nh)\n",
        "        self.h_o = nn.Linear(nh,nv)\n",
        "        self.bn = nn.BatchNorm1d(nh)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        h = torch.zeros(x.shape[0], nh).to(device=x.device)\n",
        "        res = []\n",
        "        for i in range(x.shape[1]):\n",
        "            h = h + self.i_h(x[:,i])\n",
        "            h = F.relu(self.h_h(h))\n",
        "            res.append(self.h_o(self.bn(h)))\n",
        "        return torch.stack(res, dim=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0AJrzVr0i6lw",
        "colab_type": "code",
        "outputId": "0384bd59-bd81-4912-ae5a-a629aa7e2079",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "nv = len(vocab.itos)\n",
        "nv"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "34"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ltXbjdAi6l5",
        "colab_type": "code",
        "outputId": "32c2fce3-e9b6-42b1-b4e4-3986876635fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "nh = BATCH_SIZE\n",
        "nh"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FluBJ4wvi6mC",
        "colab_type": "code",
        "outputId": "6ead210b-5696-4079-b75a-83b513b216f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = Model2().to(device)\n",
        "model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model2(\n",
              "  (i_h): Embedding(34, 64)\n",
              "  (h_h): Linear(in_features=64, out_features=64, bias=True)\n",
              "  (h_o): Linear(in_features=64, out_features=34, bias=True)\n",
              "  (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTM86MGMi6mK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#### Function to generate batch\n",
        "def generate_batch(batch):\n",
        "    #print(len(batch))\n",
        "    text = []\n",
        "    label = []\n",
        "    for entry in batch:\n",
        "        text.append(entry[0].numpy())\n",
        "        label.append(entry[1].numpy())\n",
        "    return torch.tensor(text), torch.tensor(label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyMd9Inji6mN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "#### Train the model\n",
        "def train_func(sub_train_):\n",
        "\n",
        "    # Train the model\n",
        "    train_loss = 0\n",
        "    train_acc = 0\n",
        "    #print(len(sub_train_))\n",
        "    data = DataLoader(sub_train_, batch_size=BATCH_SIZE, shuffle=True,\n",
        "                      collate_fn=generate_batch)\n",
        "    for i, (text, cls) in enumerate(data):\n",
        "        optimizer.zero_grad()\n",
        "        text, cls = text.to(device), cls.to(device)\n",
        "        output = model(text)\n",
        "        #print(output.shape)\n",
        "        #print(cls.shape)\n",
        "        for i in range(output.shape[1]):\n",
        "            loss = criterion(output[:,i,:], cls[:,i])\n",
        "            train_loss += loss.item()\n",
        "            train_acc += (output[:,i,:].argmax(1) == cls[:,i]).sum().item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "\n",
        "    # Adjust the learning rate\n",
        "    scheduler.step()\n",
        "\n",
        "    return train_loss / (len(sub_train_)*bptt), train_acc / (len(sub_train_)*bptt)\n",
        "\n",
        "#### Test the model while training\n",
        "def test_func(data_):\n",
        "    loss = 0\n",
        "    acc = 0\n",
        "    data = DataLoader(data_, batch_size=BATCH_SIZE, collate_fn=generate_batch)\n",
        "    for text, cls in data:\n",
        "        text, cls = text.to(device), cls.to(device)\n",
        "        with torch.no_grad():\n",
        "            output = model(text)\n",
        "            #print(output.shape)\n",
        "            #print(cls.shape)\n",
        "            for i in range(output.shape[1]):\n",
        "                loss = criterion(output[:,i,:], cls[:,i])\n",
        "                loss += loss.item()\n",
        "                acc += (output[:,i,:].argmax(1) == cls[:,i]).sum().item()\n",
        "\n",
        "    return loss / (len(data_)*bptt), acc / (len(data_)*bptt)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "d3Al_URxi6mV",
        "colab_type": "code",
        "outputId": "c3792e56-0fe5-4709-e32c-c07a66830c67",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from torch.utils.data.dataset import random_split\n",
        "N_EPOCHS = 20\n",
        "min_valid_loss = float('inf')\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1, gamma=0.9)\n",
        "\n",
        "#### Break test sets into 2 data sets validations and test data set\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "    train_loss, train_acc = train_func(train_dataset)\n",
        "    valid_loss, valid_acc = test_func(valid_dataset)\n",
        "\n",
        "    secs = int(time.time() - start_time)\n",
        "    mins = secs / 60\n",
        "    secs = secs % 60\n",
        "\n",
        "    print('Epoch: %d' %(epoch + 1), \" | time in %d minutes, %d seconds\" %(mins, secs))\n",
        "    print(f'\\tLoss: {train_loss:.4f}(train)\\t|\\tAcc: {train_acc * 100:.1f}%(train)')\n",
        "    print(f'\\tLoss: {valid_loss:.4f}(valid)\\t|\\tAcc: {valid_acc * 100:.1f}%(valid)')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1  | time in 0 minutes, 15 seconds\n",
            "\tLoss: 0.0375(train)\t|\tAcc: 36.8%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 40.7%(valid)\n",
            "Epoch: 2  | time in 0 minutes, 15 seconds\n",
            "\tLoss: 0.0263(train)\t|\tAcc: 45.6%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 37.4%(valid)\n",
            "Epoch: 3  | time in 0 minutes, 15 seconds\n",
            "\tLoss: 0.0246(train)\t|\tAcc: 45.9%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 31.8%(valid)\n",
            "Epoch: 4  | time in 0 minutes, 15 seconds\n",
            "\tLoss: 0.0240(train)\t|\tAcc: 45.9%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 30.9%(valid)\n",
            "Epoch: 5  | time in 0 minutes, 15 seconds\n",
            "\tLoss: 0.0237(train)\t|\tAcc: 46.0%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 30.9%(valid)\n",
            "Epoch: 6  | time in 0 minutes, 15 seconds\n",
            "\tLoss: 0.0236(train)\t|\tAcc: 46.1%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 30.6%(valid)\n",
            "Epoch: 7  | time in 0 minutes, 15 seconds\n",
            "\tLoss: 0.0235(train)\t|\tAcc: 46.0%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 30.6%(valid)\n",
            "Epoch: 8  | time in 0 minutes, 15 seconds\n",
            "\tLoss: 0.0234(train)\t|\tAcc: 46.1%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 30.5%(valid)\n",
            "Epoch: 9  | time in 0 minutes, 15 seconds\n",
            "\tLoss: 0.0234(train)\t|\tAcc: 46.1%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 30.5%(valid)\n",
            "Epoch: 10  | time in 0 minutes, 15 seconds\n",
            "\tLoss: 0.0234(train)\t|\tAcc: 46.1%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 30.5%(valid)\n",
            "Epoch: 11  | time in 0 minutes, 15 seconds\n",
            "\tLoss: 0.0233(train)\t|\tAcc: 46.1%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 30.6%(valid)\n",
            "Epoch: 12  | time in 0 minutes, 15 seconds\n",
            "\tLoss: 0.0233(train)\t|\tAcc: 46.0%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 30.9%(valid)\n",
            "Epoch: 13  | time in 0 minutes, 15 seconds\n",
            "\tLoss: 0.0233(train)\t|\tAcc: 46.1%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 30.6%(valid)\n",
            "Epoch: 14  | time in 0 minutes, 15 seconds\n",
            "\tLoss: 0.0233(train)\t|\tAcc: 46.0%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 30.9%(valid)\n",
            "Epoch: 15  | time in 0 minutes, 15 seconds\n",
            "\tLoss: 0.0233(train)\t|\tAcc: 46.1%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 31.0%(valid)\n",
            "Epoch: 16  | time in 0 minutes, 15 seconds\n",
            "\tLoss: 0.0233(train)\t|\tAcc: 46.1%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 31.0%(valid)\n",
            "Epoch: 17  | time in 0 minutes, 15 seconds\n",
            "\tLoss: 0.0232(train)\t|\tAcc: 46.1%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 30.9%(valid)\n",
            "Epoch: 18  | time in 0 minutes, 14 seconds\n",
            "\tLoss: 0.0232(train)\t|\tAcc: 46.1%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 30.9%(valid)\n",
            "Epoch: 19  | time in 0 minutes, 15 seconds\n",
            "\tLoss: 0.0232(train)\t|\tAcc: 46.1%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 31.1%(valid)\n",
            "Epoch: 20  | time in 0 minutes, 15 seconds\n",
            "\tLoss: 0.0232(train)\t|\tAcc: 46.1%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 31.0%(valid)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "Tnw6BmSFi6ma",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(model.state_dict(),\"./model2.pt\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ML3Kmou0AwMy"
      },
      "source": [
        "#### Model 2 testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "0ba1c9de-b0e8-4917-f381-721bd8cfad0d",
        "id": "WV2Q525FAwM3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = Model2().to(device)\n",
        "model.load_state_dict(torch.load('model2.pt'))\n",
        "model.eval()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model2(\n",
              "  (i_h): Embedding(34, 64)\n",
              "  (h_h): Linear(in_features=64, out_features=64, bias=True)\n",
              "  (h_o): Linear(in_features=64, out_features=34, bias=True)\n",
              "  (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "59902764-392f-45c6-892a-68d03ea54af9",
        "id": "nK85_fk9AwM8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "output = model(test_data.to(device))\n",
        "output.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 20, 34])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "bb59bcd8-be59-4c07-a33e-af4d89f81b0d",
        "id": "rzU89JjrAwM-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import numpy as np\n",
        "test_predictions = np.argmax(output.cpu().detach().numpy(),axis=2)\n",
        "test_predictions"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 4, 10,  3, ..., 11,  3, 10],\n",
              "       [10,  3,  8, ...,  3, 10,  3],\n",
              "       [ 2, 10,  3, ..., 10,  3,  6],\n",
              "       ...,\n",
              "       [10,  3,  8, ...,  3, 10,  8],\n",
              "       [ 2, 10,  2, ..., 10,  8,  6],\n",
              "       [10,  2,  6, ...,  8,  6,  3]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWzv0PIvBpAO",
        "colab_type": "code",
        "outputId": "79d28076-d25c-423c-fd11-0aff98a2defd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "test_predictions[20]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 4, 10,  3, 10,  3,  6,  3, 10,  3,  5,  3, 10,  3,  6,  3,  8,  3,\n",
              "        5,  3, 10])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "87071752-cff2-45ef-a710-bf220756275b",
        "id": "oen_h-EMAwM_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#### Comparing the label and predictions\n",
        "for i,word_idx in  enumerate(test_predictions[20]):\n",
        "  print (f'Label: {repr(tokenizer(show_text(test_label[20]))[i])} ---> Prediction: {repr(vocab.itos[word_idx])} ')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label: '\\n ' ---> Prediction: 'thousand' \n",
            "Label: 'eight' ---> Prediction: 'three' \n",
            "Label: 'thousand' ---> Prediction: 'hundred' \n",
            "Label: 'six' ---> Prediction: 'three' \n",
            "Label: '\\n ' ---> Prediction: 'hundred' \n",
            "Label: 'eight' ---> Prediction: 'four' \n",
            "Label: 'thousand' ---> Prediction: 'hundred' \n",
            "Label: 'seven' ---> Prediction: 'three' \n",
            "Label: '\\n ' ---> Prediction: 'hundred' \n",
            "Label: 'eight' ---> Prediction: 'five' \n",
            "Label: 'thousand' ---> Prediction: 'hundred' \n",
            "Label: 'eight' ---> Prediction: 'three' \n",
            "Label: '\\n ' ---> Prediction: 'hundred' \n",
            "Label: 'eight' ---> Prediction: 'four' \n",
            "Label: 'thousand' ---> Prediction: 'hundred' \n",
            "Label: 'nine' ---> Prediction: 'seven' \n",
            "Label: '\\n ' ---> Prediction: 'hundred' \n",
            "Label: 'eight' ---> Prediction: 'five' \n",
            "Label: 'thousand' ---> Prediction: 'hundred' \n",
            "Label: 'ten' ---> Prediction: 'three' \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LM6alxgvi6nA",
        "colab_type": "text"
      },
      "source": [
        "Note that our accuracy is worse now, because we are doing a harder task.  When we predict word k (k<20), we have less history to help us then when we were only predicting word 71."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g394ECsvi6nB",
        "colab_type": "text"
      },
      "source": [
        "### Multi fully connected model that maintains State (Model 3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9qKBK5yi6nC",
        "colab_type": "text"
      },
      "source": [
        "To address this issue, let's keep the hidden state from the previous line of text, so we are not starting over again on each new line of text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ctLqdAXi6nD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model3(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.i_h = nn.Embedding(nv,nh)\n",
        "        self.h_h = nn.Linear(nh,nh)\n",
        "        self.h_o = nn.Linear(nh,nv)\n",
        "        self.bn = nn.BatchNorm1d(nh)\n",
        "        self.h = torch.zeros(BATCH_SIZE, nh).to(device)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        res = []\n",
        "        h = self.h\n",
        "        for i in range(x.shape[1]):\n",
        "            h = h + self.i_h(x[:,i])\n",
        "            h = F.relu(self.h_h(h))\n",
        "            res.append(self.bn(h))\n",
        "        self.h = h.detach()\n",
        "        res = torch.stack(res, dim=1)\n",
        "        res = self.h_o(res)\n",
        "        return res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pikHt0AYi6nL",
        "colab_type": "code",
        "outputId": "d2a89058-b3f1-45d4-8720-337adc08c9a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "nv = len(vocab.itos)\n",
        "nv"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "34"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnXTWsgei6nO",
        "colab_type": "code",
        "outputId": "d2785343-b764-42f4-8fd2-72e51a71917b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "nh = BATCH_SIZE\n",
        "nh"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSy3iAJai6nW",
        "colab_type": "code",
        "outputId": "4e5b9ad7-d5f3-4abc-c8c9-17a121dd6250",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = Model3().to(device)\n",
        "model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model3(\n",
              "  (i_h): Embedding(34, 64)\n",
              "  (h_h): Linear(in_features=64, out_features=64, bias=True)\n",
              "  (h_o): Linear(in_features=64, out_features=34, bias=True)\n",
              "  (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uXesJN6i6nZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Function to generate the batch dataset\n",
        "def generate_batch(batch):\n",
        "    #print(len(batch))\n",
        "    text = []\n",
        "    label = []\n",
        "    for entry in batch:\n",
        "        text.append(entry[0].numpy())\n",
        "        label.append(entry[1].numpy())\n",
        "    return torch.tensor(text), torch.tensor(label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12ugkFzZi6nc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def train_func(sub_train_):\n",
        "\n",
        "    # Train the model\n",
        "    train_loss = 0\n",
        "    train_acc = 0\n",
        "    #print(len(sub_train_))\n",
        "    data = DataLoader(sub_train_, batch_size=BATCH_SIZE, shuffle=True,\n",
        "                      collate_fn=generate_batch,drop_last=True)\n",
        "    for i, (text, cls) in enumerate(data):\n",
        "        optimizer.zero_grad()\n",
        "        text, cls = text.to(device), cls.to(device)\n",
        "        #print(text.shape)\n",
        "        output = model(text)\n",
        "        #print(output.shape)\n",
        "        #print(cls.shape)\n",
        "        for i in range(output.shape[1]):\n",
        "            loss = criterion(output[:,i,:], cls[:,i])\n",
        "            train_loss += loss.item()\n",
        "            train_acc += (output[:,i,:].argmax(1) == cls[:,i]).sum().item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "\n",
        "    # Adjust the learning rate\n",
        "    #scheduler.step()\n",
        "\n",
        "    return train_loss / (len(sub_train_)*bptt), train_acc / (len(sub_train_)*bptt)\n",
        "\n",
        "def test_func(data_):\n",
        "    loss = 0\n",
        "    acc = 0\n",
        "    data = DataLoader(data_, batch_size=BATCH_SIZE, collate_fn=generate_batch,drop_last=True)\n",
        "    for text, cls in data:\n",
        "        text, cls = text.to(device), cls.to(device)\n",
        "        with torch.no_grad():\n",
        "            output = model(text)\n",
        "            #print(output.shape)\n",
        "            #print(cls.shape)\n",
        "            for i in range(output.shape[1]):\n",
        "                loss = criterion(output[:,i,:], cls[:,i])\n",
        "                loss += loss.item()\n",
        "                acc += (output[:,i,:].argmax(1) == cls[:,i]).sum().item()\n",
        "\n",
        "    return loss / (len(data_)*bptt), acc / (len(data_)*bptt)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "cuyPWiExi6ng",
        "colab_type": "code",
        "outputId": "290da5c4-4cbf-450a-ebc9-4c88066cce62",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from torch.utils.data.dataset import random_split\n",
        "N_EPOCHS = 20\n",
        "min_valid_loss = float('inf')\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=3e-3)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1, gamma=0.9)\n",
        "\n",
        "#### Break test sets into 2 data sets validations and test data set\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "    train_loss, train_acc = train_func(train_dataset)\n",
        "    valid_loss, valid_acc = test_func(valid_dataset)\n",
        "\n",
        "    secs = int(time.time() - start_time)\n",
        "    mins = secs / 60\n",
        "    secs = secs % 60\n",
        "\n",
        "    print('Epoch: %d' %(epoch + 1), \" | time in %d minutes, %d seconds\" %(mins, secs))\n",
        "    print(f'\\tLoss: {train_loss:.4f}(train)\\t|\\tAcc: {train_acc * 100:.1f}%(train)')\n",
        "    print(f'\\tLoss: {valid_loss:.4f}(valid)\\t|\\tAcc: {valid_acc * 100:.1f}%(valid)')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1  | time in 0 minutes, 13 seconds\n",
            "\tLoss: 0.0256(train)\t|\tAcc: 46.9%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 44.2%(valid)\n",
            "Epoch: 2  | time in 0 minutes, 13 seconds\n",
            "\tLoss: 0.0305(train)\t|\tAcc: 52.3%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 45.6%(valid)\n",
            "Epoch: 3  | time in 0 minutes, 13 seconds\n",
            "\tLoss: 0.0368(train)\t|\tAcc: 56.0%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 48.4%(valid)\n",
            "Epoch: 4  | time in 0 minutes, 13 seconds\n",
            "\tLoss: 0.0424(train)\t|\tAcc: 58.8%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 49.4%(valid)\n",
            "Epoch: 5  | time in 0 minutes, 13 seconds\n",
            "\tLoss: 0.0473(train)\t|\tAcc: 60.6%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 49.1%(valid)\n",
            "Epoch: 6  | time in 0 minutes, 13 seconds\n",
            "\tLoss: 0.0512(train)\t|\tAcc: 62.0%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 49.7%(valid)\n",
            "Epoch: 7  | time in 0 minutes, 13 seconds\n",
            "\tLoss: 0.0536(train)\t|\tAcc: 62.7%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 51.5%(valid)\n",
            "Epoch: 8  | time in 0 minutes, 13 seconds\n",
            "\tLoss: 0.0569(train)\t|\tAcc: 63.6%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 49.6%(valid)\n",
            "Epoch: 9  | time in 0 minutes, 13 seconds\n",
            "\tLoss: 0.0596(train)\t|\tAcc: 64.0%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 52.9%(valid)\n",
            "Epoch: 10  | time in 0 minutes, 13 seconds\n",
            "\tLoss: 0.0629(train)\t|\tAcc: 64.5%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 52.0%(valid)\n",
            "Epoch: 11  | time in 0 minutes, 13 seconds\n",
            "\tLoss: 0.0650(train)\t|\tAcc: 64.3%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 51.9%(valid)\n",
            "Epoch: 12  | time in 0 minutes, 13 seconds\n",
            "\tLoss: 0.0653(train)\t|\tAcc: 65.0%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 53.2%(valid)\n",
            "Epoch: 13  | time in 0 minutes, 13 seconds\n",
            "\tLoss: 0.0677(train)\t|\tAcc: 65.4%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 51.9%(valid)\n",
            "Epoch: 14  | time in 0 minutes, 13 seconds\n",
            "\tLoss: 0.0684(train)\t|\tAcc: 65.7%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 52.3%(valid)\n",
            "Epoch: 15  | time in 0 minutes, 13 seconds\n",
            "\tLoss: 0.0692(train)\t|\tAcc: 65.6%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 52.8%(valid)\n",
            "Epoch: 16  | time in 0 minutes, 13 seconds\n",
            "\tLoss: 0.0706(train)\t|\tAcc: 66.1%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 53.0%(valid)\n",
            "Epoch: 17  | time in 0 minutes, 13 seconds\n",
            "\tLoss: 0.0726(train)\t|\tAcc: 65.9%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 52.7%(valid)\n",
            "Epoch: 18  | time in 0 minutes, 13 seconds\n",
            "\tLoss: 0.0716(train)\t|\tAcc: 65.8%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 53.9%(valid)\n",
            "Epoch: 19  | time in 0 minutes, 13 seconds\n",
            "\tLoss: 0.0729(train)\t|\tAcc: 66.4%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 52.8%(valid)\n",
            "Epoch: 20  | time in 0 minutes, 13 seconds\n",
            "\tLoss: 0.0735(train)\t|\tAcc: 66.5%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 53.9%(valid)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "tmSOUPpsi6nk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(model.state_dict(),\"./model3.pt\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pv4d2inKErAi"
      },
      "source": [
        "#### Model 3 testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "4bf5a21a-1ce9-47a3-91dc-db62b63cdaa4",
        "id": "IzSSKFQ1ErAk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = Model3().to(device)\n",
        "model.load_state_dict(torch.load('model3.pt'))\n",
        "model.eval()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model3(\n",
              "  (i_h): Embedding(34, 64)\n",
              "  (h_h): Linear(in_features=64, out_features=64, bias=True)\n",
              "  (h_o): Linear(in_features=64, out_features=34, bias=True)\n",
              "  (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "bcf04d76-beba-4ac0-b037-201dfc3d2100",
        "id": "RCjXGujCErAo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "output = model(test_data.to(device))\n",
        "output.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 20, 34])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "09d730e6-acd2-420a-9372-c5ae172fce5f",
        "id": "_uXEDbZ2ErAq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import numpy as np\n",
        "test_predictions = np.argmax(output.cpu().detach().numpy(),axis=2)\n",
        "test_predictions"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 2,  8,  4, ...,  9,  4,  9],\n",
              "       [ 9,  4,  8, ...,  4,  9,  2],\n",
              "       [ 1,  6,  3, ...,  9,  2,  9],\n",
              "       ...,\n",
              "       [ 9,  4,  8, ...,  4, 21,  2],\n",
              "       [ 1,  6,  2, ..., 21,  2,  9],\n",
              "       [32,  3, 16, ...,  2,  9,  4]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "4b1d8d56-6f4e-4582-dcab-a50a4e3a7672",
        "id": "7bfl_g4CErAs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "test_predictions[20]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 2,  9,  4,  8,  3, 16,  4, 16,  3,  9,  4, 18,  2,  9,  4, 12,  2,\n",
              "        5,  4, 29])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "d6cc1a6c-65cf-45e6-e119-367cb619168a",
        "id": "esTEGxLUErAu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#### Comparing the label and predictions\n",
        "for i,word_idx in  enumerate(test_predictions[20]):\n",
        "  print (f'Label: {repr(tokenizer(show_text(test_label[20]))[i])} ---> Prediction: {repr(vocab.itos[word_idx])} ')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label: '\\n ' ---> Prediction: '\\n' \n",
            "Label: 'eight' ---> Prediction: 'six' \n",
            "Label: 'thousand' ---> Prediction: 'thousand' \n",
            "Label: 'six' ---> Prediction: 'seven' \n",
            "Label: '\\n ' ---> Prediction: 'hundred' \n",
            "Label: 'eight' ---> Prediction: 'forty' \n",
            "Label: 'thousand' ---> Prediction: 'thousand' \n",
            "Label: 'seven' ---> Prediction: 'forty' \n",
            "Label: '\\n ' ---> Prediction: 'hundred' \n",
            "Label: 'eight' ---> Prediction: 'six' \n",
            "Label: 'thousand' ---> Prediction: 'thousand' \n",
            "Label: 'eight' ---> Prediction: 'seventy' \n",
            "Label: '\\n ' ---> Prediction: '\\n' \n",
            "Label: 'eight' ---> Prediction: 'six' \n",
            "Label: 'thousand' ---> Prediction: 'thousand' \n",
            "Label: 'nine' ---> Prediction: 'eight' \n",
            "Label: '\\n ' ---> Prediction: '\\n' \n",
            "Label: 'eight' ---> Prediction: 'five' \n",
            "Label: 'thousand' ---> Prediction: 'thousand' \n",
            "Label: 'ten' ---> Prediction: 'ten' \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DbKoZUvSErAv"
      },
      "source": [
        "Accuracy is still not good. Let's try RNN."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHAZLiedi6oi",
        "colab_type": "text"
      },
      "source": [
        "### RNN (Model 4)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THFUjjFai6oj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BatchNorm1dFlat(nn.BatchNorm1d):\n",
        "    \"`nn.BatchNorm1d`, but first flattens leading dimensions\"\n",
        "    def forward(self, x):\n",
        "        if x.dim()==2: return super().forward(x)\n",
        "        *f,l = x.shape\n",
        "        x = x.contiguous().view(-1,l)\n",
        "        return super().forward(x).view(*f,l)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PEkty_Vi6oo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model4(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.i_h = nn.Embedding(nv,nh)\n",
        "        self.rnn = nn.RNN(nh,nh, batch_first=True)\n",
        "        self.h_o = nn.Linear(nh,nv)\n",
        "        self.bn = BatchNorm1dFlat(nh)\n",
        "        self.h = torch.zeros(1, BATCH_SIZE, nh).to(device)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        res,h = self.rnn(self.i_h(x), self.h)\n",
        "        self.h = h.detach()\n",
        "        return self.h_o(self.bn(res))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLniIM4vi6ow",
        "colab_type": "code",
        "outputId": "d072ea26-2747-4f05-8cfc-c7e0bde9a095",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "nv = len(vocab.itos)\n",
        "nv"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "34"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZ3VRJbni6oz",
        "colab_type": "code",
        "outputId": "71a61f97-0629-4f53-8e7a-5703d08cf3b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "nh = BATCH_SIZE\n",
        "nh"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cm2z-La5i6o2",
        "colab_type": "code",
        "outputId": "4b089d96-e649-4141-dbeb-1ce53342fdfd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = Model4().to(device)\n",
        "model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model4(\n",
              "  (i_h): Embedding(34, 64)\n",
              "  (rnn): RNN(64, 64, batch_first=True)\n",
              "  (h_o): Linear(in_features=64, out_features=34, bias=True)\n",
              "  (bn): BatchNorm1dFlat(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQ2IrGuYi6o5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_batch(batch):\n",
        "    #print(len(batch))\n",
        "    text = []\n",
        "    label = []\n",
        "    for entry in batch:\n",
        "        text.append(entry[0].numpy())\n",
        "        label.append(entry[1].numpy())\n",
        "    return torch.tensor(text), torch.tensor(label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YllfE9u2i6pB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def train_func(sub_train_):\n",
        "\n",
        "    # Train the model\n",
        "    train_loss = 0\n",
        "    train_acc = 0\n",
        "    #print(len(sub_train_))\n",
        "    data = DataLoader(sub_train_, batch_size=BATCH_SIZE, shuffle=False,\n",
        "                      collate_fn=generate_batch,drop_last=True)\n",
        "    for i, (text, cls) in enumerate(data):\n",
        "        optimizer.zero_grad()\n",
        "        text, cls = text.to(device), cls.to(device)\n",
        "        #print(text.shape)\n",
        "        output = model(text)\n",
        "        #print(output.shape)\n",
        "        #print(cls.shape)\n",
        "        for i in range(output.shape[1]):\n",
        "            loss = criterion(output[:,i,:], cls[:,i])\n",
        "            train_loss += loss.item()\n",
        "            train_acc += (output[:,i,:].argmax(1) == cls[:,i]).sum().item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "\n",
        "    # Adjust the learning rate\n",
        "    scheduler.step()\n",
        "\n",
        "    return train_loss / (len(sub_train_)*bptt), train_acc / (len(sub_train_)*bptt)\n",
        "\n",
        "def test_func(data_):\n",
        "    loss = 0\n",
        "    acc = 0\n",
        "    data = DataLoader(data_, batch_size=BATCH_SIZE, collate_fn=generate_batch,drop_last=True)\n",
        "    for text, cls in data:\n",
        "        text, cls = text.to(device), cls.to(device)\n",
        "        with torch.no_grad():\n",
        "            output = model(text)\n",
        "            #print(output.shape)\n",
        "            #print(cls.shape)\n",
        "            for i in range(output.shape[1]):\n",
        "                loss = criterion(output[:,i,:], cls[:,i])\n",
        "                loss += loss.item()\n",
        "                acc += (output[:,i,:].argmax(1) == cls[:,i]).sum().item()\n",
        "\n",
        "    return loss / (len(data_)*bptt), acc / (len(data_)*bptt)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "tNNwznTRi6pE",
        "colab_type": "code",
        "outputId": "e6dcac47-3c3b-4d5d-f9be-020fb52e4269",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from torch.utils.data.dataset import random_split\n",
        "N_EPOCHS = 20\n",
        "min_valid_loss = float('inf')\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=3e-3)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1, gamma=0.9)\n",
        "\n",
        "#### Break test sets into 2 data sets validations and test data set\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "    train_loss, train_acc = train_func(train_dataset)\n",
        "    valid_loss, valid_acc = test_func(valid_dataset)\n",
        "\n",
        "    secs = int(time.time() - start_time)\n",
        "    mins = secs / 60\n",
        "    secs = secs % 60\n",
        "\n",
        "    print('Epoch: %d' %(epoch + 1), \" | time in %d minutes, %d seconds\" %(mins, secs))\n",
        "    print(f'\\tLoss: {train_loss:.4f}(train)\\t|\\tAcc: {train_acc * 100:.1f}%(train)')\n",
        "    print(f'\\tLoss: {valid_loss:.4f}(valid)\\t|\\tAcc: {valid_acc * 100:.1f}%(valid)')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1  | time in 0 minutes, 7 seconds\n",
            "\tLoss: 0.0224(train)\t|\tAcc: 57.8%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 45.5%(valid)\n",
            "Epoch: 2  | time in 0 minutes, 7 seconds\n",
            "\tLoss: 0.0187(train)\t|\tAcc: 61.8%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 41.1%(valid)\n",
            "Epoch: 3  | time in 0 minutes, 7 seconds\n",
            "\tLoss: 0.0175(train)\t|\tAcc: 63.6%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 39.5%(valid)\n",
            "Epoch: 4  | time in 0 minutes, 7 seconds\n",
            "\tLoss: 0.0171(train)\t|\tAcc: 66.2%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 43.2%(valid)\n",
            "Epoch: 5  | time in 0 minutes, 7 seconds\n",
            "\tLoss: 0.0160(train)\t|\tAcc: 70.9%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 46.1%(valid)\n",
            "Epoch: 6  | time in 0 minutes, 7 seconds\n",
            "\tLoss: 0.0155(train)\t|\tAcc: 73.4%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 46.8%(valid)\n",
            "Epoch: 7  | time in 0 minutes, 7 seconds\n",
            "\tLoss: 0.0149(train)\t|\tAcc: 76.1%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 44.6%(valid)\n",
            "Epoch: 8  | time in 0 minutes, 7 seconds\n",
            "\tLoss: 0.0144(train)\t|\tAcc: 76.9%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 51.8%(valid)\n",
            "Epoch: 9  | time in 0 minutes, 7 seconds\n",
            "\tLoss: 0.0140(train)\t|\tAcc: 77.5%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 52.0%(valid)\n",
            "Epoch: 10  | time in 0 minutes, 7 seconds\n",
            "\tLoss: 0.0139(train)\t|\tAcc: 78.1%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 56.1%(valid)\n",
            "Epoch: 11  | time in 0 minutes, 7 seconds\n",
            "\tLoss: 0.0141(train)\t|\tAcc: 78.1%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 56.6%(valid)\n",
            "Epoch: 12  | time in 0 minutes, 7 seconds\n",
            "\tLoss: 0.0140(train)\t|\tAcc: 78.6%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 56.8%(valid)\n",
            "Epoch: 13  | time in 0 minutes, 7 seconds\n",
            "\tLoss: 0.0142(train)\t|\tAcc: 78.9%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 58.5%(valid)\n",
            "Epoch: 14  | time in 0 minutes, 7 seconds\n",
            "\tLoss: 0.0139(train)\t|\tAcc: 79.8%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 58.2%(valid)\n",
            "Epoch: 15  | time in 0 minutes, 7 seconds\n",
            "\tLoss: 0.0140(train)\t|\tAcc: 80.6%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 58.5%(valid)\n",
            "Epoch: 16  | time in 0 minutes, 7 seconds\n",
            "\tLoss: 0.0143(train)\t|\tAcc: 81.3%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 56.6%(valid)\n",
            "Epoch: 17  | time in 0 minutes, 7 seconds\n",
            "\tLoss: 0.0146(train)\t|\tAcc: 82.1%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 57.3%(valid)\n",
            "Epoch: 18  | time in 0 minutes, 7 seconds\n",
            "\tLoss: 0.0151(train)\t|\tAcc: 82.5%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 58.0%(valid)\n",
            "Epoch: 19  | time in 0 minutes, 7 seconds\n",
            "\tLoss: 0.0155(train)\t|\tAcc: 82.8%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 58.3%(valid)\n",
            "Epoch: 20  | time in 0 minutes, 7 seconds\n",
            "\tLoss: 0.0159(train)\t|\tAcc: 83.1%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 59.1%(valid)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "JO8damuzi6pG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(model.state_dict(),\"./model4.pt\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ALkHepNHhLt",
        "colab_type": "text"
      },
      "source": [
        "Performance is better, but still not good enough. Let's try GRU."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_QLu19u_i6pJ",
        "colab_type": "text"
      },
      "source": [
        "### GRU (Model 5)\n",
        "\n",
        "This is testing GRU for multiple steps predictions. So given the 20 words, it makes 20 predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cb5yoeA3i6pK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BatchNorm1dFlat(nn.BatchNorm1d):\n",
        "    \"`nn.BatchNorm1d`, but first flattens leading dimensions\"\n",
        "    def forward(self, x):\n",
        "        if x.dim()==2: return super().forward(x)\n",
        "        *f,l = x.shape\n",
        "        x = x.contiguous().view(-1,l)\n",
        "        return super().forward(x).view(*f,l)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZM0GpvXhi6pN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model5(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.i_h = nn.Embedding(nv,nh)\n",
        "        self.rnn = nn.GRU(nh, nh, 2, batch_first=True)\n",
        "        self.h_o = nn.Linear(nh,nv)\n",
        "        self.bn = BatchNorm1dFlat(nh)\n",
        "        self.h = torch.zeros(2, BATCH_SIZE, nh)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        res,h = self.rnn(self.i_h(x), self.h)\n",
        "        self.h = h.detach()\n",
        "        return self.h_o(self.bn(res))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFIA9Dzni6pW",
        "colab_type": "code",
        "outputId": "20a7002d-be13-4d4d-a1d6-a50bea70d673",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "nv = len(vocab.itos)\n",
        "nv"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "34"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nL4a1Bv9i6pY",
        "colab_type": "code",
        "outputId": "7b770413-9763-48c5-c16f-4c70adb8fc37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "nh = BATCH_SIZE\n",
        "nh"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZsbiFgjri6pb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model5().to(device)\n",
        "model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPb-rn4Ri6pd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_batch(batch):\n",
        "    #print(len(batch))\n",
        "    text = []\n",
        "    label = []\n",
        "    for entry in batch:\n",
        "        text.append(entry[0].numpy())\n",
        "        label.append(entry[1].numpy())\n",
        "    return torch.tensor(text), torch.tensor(label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-LQaUszi6pg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def train_func(sub_train_):\n",
        "\n",
        "    # Train the model\n",
        "    train_loss = 0\n",
        "    train_acc = 0\n",
        "    #print(len(sub_train_))\n",
        "    data = DataLoader(sub_train_, batch_size=BATCH_SIZE, shuffle=True,\n",
        "                      collate_fn=generate_batch,drop_last=True)\n",
        "    for i, (text, cls) in enumerate(data):\n",
        "        optimizer.zero_grad()\n",
        "        text, cls = text.to(device), cls.to(device)\n",
        "        #print(text.shape)\n",
        "        output = model(text)\n",
        "        #print(output.shape)\n",
        "        #print(cls.shape)\n",
        "        for i in range(output.shape[1]):\n",
        "            loss = criterion(output[:,i,:], cls[:,i])\n",
        "            train_loss += loss.item()\n",
        "            train_acc += (output[:,i,:].argmax(1) == cls[:,i]).sum().item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "\n",
        "    # Adjust the learning rate\n",
        "    scheduler.step()\n",
        "\n",
        "    return train_loss / (len(sub_train_)*bptt), train_acc / (len(sub_train_)*bptt)\n",
        "\n",
        "def test_func(data_):\n",
        "    loss = 0\n",
        "    acc = 0\n",
        "    data = DataLoader(data_, batch_size=BATCH_SIZE, collate_fn=generate_batch,drop_last=True)\n",
        "    for text, cls in data:\n",
        "        text, cls = text.to(device), cls.to(device)\n",
        "        with torch.no_grad():\n",
        "            output = model(text)\n",
        "            #print(output.shape)\n",
        "            #print(cls.shape)\n",
        "            for i in range(output.shape[1]):\n",
        "                loss = criterion(output[:,i,:], cls[:,i])\n",
        "                loss += loss.item()\n",
        "                acc += (output[:,i,:].argmax(1) == cls[:,i]).sum().item()\n",
        "\n",
        "    return loss / (len(data_)*bptt), acc / (len(data_)*bptt)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "HVPV1I6ei6pj",
        "colab_type": "code",
        "outputId": "50d394a5-b3af-42cb-eb51-2ccd2fd4721d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "N_EPOCHS = 20\n",
        "min_valid_loss = float('inf')\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1, gamma=0.9)\n",
        "\n",
        "#### Break test sets into 2 data sets validations and test data set\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "    train_loss, train_acc = train_func(train_dataset)\n",
        "    valid_loss, valid_acc = test_func(valid_dataset)\n",
        "\n",
        "    secs = int(time.time() - start_time)\n",
        "    mins = secs / 60\n",
        "    secs = secs % 60\n",
        "\n",
        "    print('Epoch: %d' %(epoch + 1), \" | time in %d minutes, %d seconds\" %(mins, secs))\n",
        "    print(f'\\tLoss: {train_loss:.4f}(train)\\t|\\tAcc: {train_acc * 100:.1f}%(train)')\n",
        "    print(f'\\tLoss: {valid_loss:.4f}(valid)\\t|\\tAcc: {valid_acc * 100:.1f}%(valid)')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1  | time in 0 minutes, 32 seconds\n",
            "\tLoss: 0.0280(train)\t|\tAcc: 68.7%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 56.2%(valid)\n",
            "Epoch: 2  | time in 0 minutes, 33 seconds\n",
            "\tLoss: 0.0391(train)\t|\tAcc: 76.7%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 54.9%(valid)\n",
            "Epoch: 3  | time in 0 minutes, 32 seconds\n",
            "\tLoss: 0.0444(train)\t|\tAcc: 77.3%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 58.3%(valid)\n",
            "Epoch: 4  | time in 0 minutes, 31 seconds\n",
            "\tLoss: 0.0483(train)\t|\tAcc: 76.8%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 56.6%(valid)\n",
            "Epoch: 5  | time in 0 minutes, 31 seconds\n",
            "\tLoss: 0.0479(train)\t|\tAcc: 77.2%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 57.5%(valid)\n",
            "Epoch: 6  | time in 0 minutes, 31 seconds\n",
            "\tLoss: 0.0492(train)\t|\tAcc: 77.4%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 57.5%(valid)\n",
            "Epoch: 7  | time in 0 minutes, 31 seconds\n",
            "\tLoss: 0.0507(train)\t|\tAcc: 77.4%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 56.7%(valid)\n",
            "Epoch: 8  | time in 0 minutes, 31 seconds\n",
            "\tLoss: 0.0502(train)\t|\tAcc: 78.0%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 56.3%(valid)\n",
            "Epoch: 9  | time in 0 minutes, 31 seconds\n",
            "\tLoss: 0.0519(train)\t|\tAcc: 77.9%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 56.4%(valid)\n",
            "Epoch: 10  | time in 0 minutes, 31 seconds\n",
            "\tLoss: 0.0536(train)\t|\tAcc: 77.9%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 55.9%(valid)\n",
            "Epoch: 11  | time in 0 minutes, 31 seconds\n",
            "\tLoss: 0.0550(train)\t|\tAcc: 77.9%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 55.0%(valid)\n",
            "Epoch: 12  | time in 0 minutes, 31 seconds\n",
            "\tLoss: 0.0562(train)\t|\tAcc: 77.9%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 56.8%(valid)\n",
            "Epoch: 13  | time in 0 minutes, 31 seconds\n",
            "\tLoss: 0.0568(train)\t|\tAcc: 77.9%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 57.5%(valid)\n",
            "Epoch: 14  | time in 0 minutes, 31 seconds\n",
            "\tLoss: 0.0572(train)\t|\tAcc: 77.8%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 57.3%(valid)\n",
            "Epoch: 15  | time in 0 minutes, 31 seconds\n",
            "\tLoss: 0.0577(train)\t|\tAcc: 77.9%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 57.8%(valid)\n",
            "Epoch: 16  | time in 0 minutes, 31 seconds\n",
            "\tLoss: 0.0588(train)\t|\tAcc: 77.8%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 58.6%(valid)\n",
            "Epoch: 17  | time in 0 minutes, 31 seconds\n",
            "\tLoss: 0.0598(train)\t|\tAcc: 77.9%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 58.1%(valid)\n",
            "Epoch: 18  | time in 0 minutes, 31 seconds\n",
            "\tLoss: 0.0605(train)\t|\tAcc: 77.8%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 58.0%(valid)\n",
            "Epoch: 19  | time in 0 minutes, 31 seconds\n",
            "\tLoss: 0.0614(train)\t|\tAcc: 77.8%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 58.7%(valid)\n",
            "Epoch: 20  | time in 0 minutes, 31 seconds\n",
            "\tLoss: 0.0621(train)\t|\tAcc: 77.8%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 59.3%(valid)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "IM74A_CJi6pp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(model.state_dict(),\"./model5.pt\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1zqKA1rKshj3"
      },
      "source": [
        "### GRU (Model 6)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wRz-p4P4shj6",
        "colab": {}
      },
      "source": [
        "class BatchNorm1dFlat(nn.BatchNorm1d):\n",
        "    \"`nn.BatchNorm1d`, but first flattens leading dimensions\"\n",
        "    def forward(self, x):\n",
        "        if x.dim()==2: return super().forward(x)\n",
        "        *f,l = x.shape\n",
        "        x = x.contiguous().view(-1,l)\n",
        "        return super().forward(x).view(*f,l)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "m0vpArBmshkC",
        "colab": {}
      },
      "source": [
        "class Model6(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.i_h = nn.Embedding(nv,nh)\n",
        "        self.rnn = nn.GRU(nh, nh, 2, batch_first=True)\n",
        "        self.h_o = nn.Linear(nh,nv)\n",
        "        self.bn = BatchNorm1dFlat(nh)\n",
        "        self.h = torch.zeros(2, BATCH_SIZE, nh)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        res,h = self.rnn(self.i_h(x), self.h)\n",
        "        #self.h = h.detach()\n",
        "        return self.h_o(self.bn(res))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "j2oZuszCshkF",
        "outputId": "b2348f5e-68ef-43e7-cef0-ab3808ef1690",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "bptt=20\n",
        "tokenizer = get_tokenizer(\"spacy\")\n",
        "train_dataset, valid_dataset = HumanNumbers(root='data',bptt=bptt,data_select=('train', 'valid'))\n",
        "vocab = train_dataset.get_vocab()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3790lines [00:00, 37890.73lines/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "<function tokenizer at 0x7f1d0bd07268>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8001lines [00:00, 36544.06lines/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "51840\n",
            "51840\n",
            "torch.Size([51840, 30])\n",
            "torch.Size([51840, 30])\n",
            "13440\n",
            "13440\n",
            "torch.Size([13440, 30])\n",
            "torch.Size([13440, 30])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "o2hNvAkGshkK",
        "outputId": "9c92cb2f-a7a7-44af-e412-3dc5685d4b8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "nv = len(vocab.itos)\n",
        "nv"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "34"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_b6iONyLshkO",
        "outputId": "91532fdd-0b4e-47f6-aaf4-b9d7b0d08db0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "nh = BATCH_SIZE\n",
        "nh"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QBu2SSLeshkR",
        "outputId": "6f2c6983-cfd9-4414-8b45-8ba5f5e8b0ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "model = Model6().to(device)\n",
        "model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model6(\n",
              "  (i_h): Embedding(34, 64)\n",
              "  (rnn): GRU(64, 64, num_layers=2, batch_first=True)\n",
              "  (h_o): Linear(in_features=64, out_features=34, bias=True)\n",
              "  (bn): BatchNorm1dFlat(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9pBaTaxmshkU",
        "colab": {}
      },
      "source": [
        "def generate_batch(batch):\n",
        "    #print(len(batch))\n",
        "    text = []\n",
        "    label = []\n",
        "    for entry in batch:\n",
        "        text.append(entry[0].numpy())\n",
        "        label.append(entry[1].numpy())\n",
        "    return torch.tensor(text), torch.tensor(label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TQ04XGl4shkX",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def train_func(sub_train_):\n",
        "\n",
        "    # Train the model\n",
        "    train_loss = 0\n",
        "    train_acc = 0\n",
        "    #print(len(sub_train_))\n",
        "    data = DataLoader(sub_train_, batch_size=BATCH_SIZE, shuffle=True,\n",
        "                      collate_fn=generate_batch,drop_last=True)\n",
        "    for i, (text, cls) in enumerate(data):\n",
        "        optimizer.zero_grad()\n",
        "        text, cls = text.to(device), cls.to(device)\n",
        "        #print(text.shape)\n",
        "        output = model(text)\n",
        "        #print(output.shape)\n",
        "        #print(cls.shape)\n",
        "        #for i in range(output.shape[1]):\n",
        "        loss = criterion(output[:,-1,:], cls[:,-1])\n",
        "        train_loss += loss.item()\n",
        "        train_acc += (output[:,-1,:].argmax(1) == cls[:,-1]).sum().item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "\n",
        "    # Adjust the learning rate\n",
        "    scheduler.step()\n",
        "\n",
        "    return train_loss / len(sub_train_), train_acc / len(sub_train_)\n",
        "\n",
        "def test_func(data_):\n",
        "    loss = 0\n",
        "    acc = 0\n",
        "    data = DataLoader(data_, batch_size=BATCH_SIZE, collate_fn=generate_batch,drop_last=True)\n",
        "    for text, cls in data:\n",
        "        text, cls = text.to(device), cls.to(device)\n",
        "        with torch.no_grad():\n",
        "            output = model(text)\n",
        "            #print(output.shape)\n",
        "            #print(cls.shape)\n",
        "            #for i in range(output.shape[1]):\n",
        "            loss = criterion(output[:,-1,:], cls[:,-1])\n",
        "            loss += loss.item()\n",
        "            acc += (output[:,-1,:].argmax(1) == cls[:,-1]).sum().item()\n",
        "\n",
        "    return loss / len(data_), acc / len(data_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab_type": "code",
        "id": "QkyVCXt9shkc",
        "outputId": "b3996761-df00-40d6-de39-95d5af84497f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from torch.utils.data.dataset import random_split\n",
        "N_EPOCHS = 20\n",
        "min_valid_loss = float('inf')\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1, gamma=0.9)\n",
        "\n",
        "#### Break test sets into 2 data sets validations and test data set\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "    train_loss, train_acc = train_func(train_dataset)\n",
        "    valid_loss, valid_acc = test_func(valid_dataset)\n",
        "\n",
        "    secs = int(time.time() - start_time)\n",
        "    mins = secs / 60\n",
        "    secs = secs % 60\n",
        "\n",
        "    print('Epoch: %d' %(epoch + 1), \" | time in %d minutes, %d seconds\" %(mins, secs))\n",
        "    print(f'\\tLoss: {train_loss:.4f}(train)\\t|\\tAcc: {train_acc * 100:.1f}%(train)')\n",
        "    print(f'\\tLoss: {valid_loss:.4f}(valid)\\t|\\tAcc: {valid_acc * 100:.1f}%(valid)')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1  | time in 0 minutes, 42 seconds\n",
            "\tLoss: 0.0048(train)\t|\tAcc: 90.8%(train)\n",
            "\tLoss: 0.0003(valid)\t|\tAcc: 76.7%(valid)\n",
            "Epoch: 2  | time in 0 minutes, 41 seconds\n",
            "\tLoss: 0.0012(train)\t|\tAcc: 97.8%(train)\n",
            "\tLoss: 0.0004(valid)\t|\tAcc: 75.8%(valid)\n",
            "Epoch: 3  | time in 0 minutes, 41 seconds\n",
            "\tLoss: 0.0008(train)\t|\tAcc: 98.7%(train)\n",
            "\tLoss: 0.0003(valid)\t|\tAcc: 78.3%(valid)\n",
            "Epoch: 4  | time in 0 minutes, 40 seconds\n",
            "\tLoss: 0.0006(train)\t|\tAcc: 99.0%(train)\n",
            "\tLoss: 0.0005(valid)\t|\tAcc: 74.2%(valid)\n",
            "Epoch: 5  | time in 0 minutes, 41 seconds\n",
            "\tLoss: 0.0004(train)\t|\tAcc: 99.3%(train)\n",
            "\tLoss: 0.0004(valid)\t|\tAcc: 78.2%(valid)\n",
            "Epoch: 6  | time in 0 minutes, 40 seconds\n",
            "\tLoss: 0.0004(train)\t|\tAcc: 99.4%(train)\n",
            "\tLoss: 0.0003(valid)\t|\tAcc: 76.4%(valid)\n",
            "Epoch: 7  | time in 0 minutes, 41 seconds\n",
            "\tLoss: 0.0004(train)\t|\tAcc: 99.4%(train)\n",
            "\tLoss: 0.0004(valid)\t|\tAcc: 77.7%(valid)\n",
            "Epoch: 8  | time in 0 minutes, 40 seconds\n",
            "\tLoss: 0.0003(train)\t|\tAcc: 99.5%(train)\n",
            "\tLoss: 0.0005(valid)\t|\tAcc: 74.0%(valid)\n",
            "Epoch: 9  | time in 0 minutes, 40 seconds\n",
            "\tLoss: 0.0003(train)\t|\tAcc: 99.5%(train)\n",
            "\tLoss: 0.0005(valid)\t|\tAcc: 76.2%(valid)\n",
            "Epoch: 10  | time in 0 minutes, 40 seconds\n",
            "\tLoss: 0.0001(train)\t|\tAcc: 99.8%(train)\n",
            "\tLoss: 0.0005(valid)\t|\tAcc: 77.0%(valid)\n",
            "Epoch: 11  | time in 0 minutes, 41 seconds\n",
            "\tLoss: 0.0001(train)\t|\tAcc: 99.8%(train)\n",
            "\tLoss: 0.0005(valid)\t|\tAcc: 78.7%(valid)\n",
            "Epoch: 12  | time in 0 minutes, 42 seconds\n",
            "\tLoss: 0.0001(train)\t|\tAcc: 99.9%(train)\n",
            "\tLoss: 0.0005(valid)\t|\tAcc: 79.0%(valid)\n",
            "Epoch: 13  | time in 0 minutes, 41 seconds\n",
            "\tLoss: 0.0001(train)\t|\tAcc: 99.8%(train)\n",
            "\tLoss: 0.0005(valid)\t|\tAcc: 78.7%(valid)\n",
            "Epoch: 14  | time in 0 minutes, 40 seconds\n",
            "\tLoss: 0.0001(train)\t|\tAcc: 99.9%(train)\n",
            "\tLoss: 0.0005(valid)\t|\tAcc: 78.0%(valid)\n",
            "Epoch: 15  | time in 0 minutes, 40 seconds\n",
            "\tLoss: 0.0001(train)\t|\tAcc: 99.9%(train)\n",
            "\tLoss: 0.0005(valid)\t|\tAcc: 77.7%(valid)\n",
            "Epoch: 16  | time in 0 minutes, 40 seconds\n",
            "\tLoss: 0.0000(train)\t|\tAcc: 99.9%(train)\n",
            "\tLoss: 0.0006(valid)\t|\tAcc: 79.1%(valid)\n",
            "Epoch: 17  | time in 0 minutes, 41 seconds\n",
            "\tLoss: 0.0000(train)\t|\tAcc: 100.0%(train)\n",
            "\tLoss: 0.0005(valid)\t|\tAcc: 78.8%(valid)\n",
            "Epoch: 18  | time in 0 minutes, 40 seconds\n",
            "\tLoss: 0.0000(train)\t|\tAcc: 100.0%(train)\n",
            "\tLoss: 0.0005(valid)\t|\tAcc: 79.1%(valid)\n",
            "Epoch: 19  | time in 0 minutes, 40 seconds\n",
            "\tLoss: 0.0000(train)\t|\tAcc: 100.0%(train)\n",
            "\tLoss: 0.0005(valid)\t|\tAcc: 79.2%(valid)\n",
            "Epoch: 20  | time in 0 minutes, 40 seconds\n",
            "\tLoss: 0.0000(train)\t|\tAcc: 100.0%(train)\n",
            "\tLoss: 0.0005(valid)\t|\tAcc: 78.8%(valid)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "colab_type": "code",
        "id": "zCv_CoMjshkf",
        "colab": {}
      },
      "source": [
        "torch.save(model.state_dict(),\"./model6.pt\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TLfEon1-0S_P"
      },
      "source": [
        "### LSTM (Model 7)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8tnry3VO0S_R",
        "colab": {}
      },
      "source": [
        "class BatchNorm1dFlat(nn.BatchNorm1d):\n",
        "    \"`nn.BatchNorm1d`, but first flattens leading dimensions\"\n",
        "    def forward(self, x):\n",
        "        if x.dim()==2: return super().forward(x)\n",
        "        *f,l = x.shape\n",
        "        x = x.contiguous().view(-1,l)\n",
        "        return super().forward(x).view(*f,l)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HnDWHsub0S_U",
        "colab": {}
      },
      "source": [
        "class Model7(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.i_h = nn.Embedding(nv,nh)\n",
        "        self.rnn = nn.LSTM(nh, nh, 2, batch_first=True)\n",
        "        self.h_o = nn.Linear(nh,nv)\n",
        "        self.bn = BatchNorm1dFlat(nh)\n",
        "        self.h = torch.zeros(2, BATCH_SIZE, nh)\n",
        "        self.c = torch.zeros(2, BATCH_SIZE, nh)\n",
        "        \n",
        "        \n",
        "    def forward(self, x):\n",
        "        res,(h,c) = self.rnn(self.i_h(x), (self.h,self.c))\n",
        "        #self.h = h.detach()\n",
        "        return self.h_o(self.bn(res))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9ixzmUnV0S_Z",
        "outputId": "b3a1d205-11ec-4f91-89b2-30cc767df4d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "nv = len(vocab.itos)\n",
        "nv"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "34"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Uv-r_L7N0S_d",
        "outputId": "6774fdda-0e33-49ee-c273-b368b60792ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "nh = BATCH_SIZE\n",
        "nh"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PIqlsF3z0S_g",
        "outputId": "cd2e29bb-35c1-4ecf-b779-99d30b209769",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "model = Model7().to(device)\n",
        "model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model7(\n",
              "  (i_h): Embedding(34, 64)\n",
              "  (rnn): LSTM(64, 64, num_layers=2, batch_first=True)\n",
              "  (h_o): Linear(in_features=64, out_features=34, bias=True)\n",
              "  (bn): BatchNorm1dFlat(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IzcxYuQ20S_j",
        "colab": {}
      },
      "source": [
        "def generate_batch(batch):\n",
        "    #print(len(batch))\n",
        "    text = []\n",
        "    label = []\n",
        "    for entry in batch:\n",
        "        text.append(entry[0].numpy())\n",
        "        label.append(entry[1].numpy())\n",
        "    return torch.tensor(text), torch.tensor(label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oK4sF9QV0S_l",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def train_func(sub_train_):\n",
        "\n",
        "    # Train the model\n",
        "    train_loss = 0\n",
        "    train_acc = 0\n",
        "    #print(len(sub_train_))\n",
        "    data = DataLoader(sub_train_, batch_size=BATCH_SIZE, shuffle=True,\n",
        "                      collate_fn=generate_batch,drop_last=True)\n",
        "    for i, (text, cls) in enumerate(data):\n",
        "        optimizer.zero_grad()\n",
        "        text, cls = text.to(device), cls.to(device)\n",
        "        #print(text.shape)\n",
        "        output = model(text)\n",
        "        #print(output.shape)\n",
        "        #print(cls.shape)\n",
        "        #for i in range(output.shape[1]):\n",
        "        loss = criterion(output[:,-1,:], cls[:,-1])\n",
        "        train_loss += loss.item()\n",
        "        train_acc += (output[:,-1,:].argmax(1) == cls[:,-1]).sum().item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "\n",
        "    # Adjust the learning rate\n",
        "    scheduler.step()\n",
        "\n",
        "    return train_loss / len(sub_train_), train_acc / len(sub_train_)\n",
        "\n",
        "def test_func(data_):\n",
        "    loss = 0\n",
        "    acc = 0\n",
        "    data = DataLoader(data_, batch_size=BATCH_SIZE, collate_fn=generate_batch,drop_last=True)\n",
        "    for text, cls in data:\n",
        "        text, cls = text.to(device), cls.to(device)\n",
        "        with torch.no_grad():\n",
        "            output = model(text)\n",
        "            #print(output.shape)\n",
        "            #print(cls.shape)\n",
        "            #for i in range(output.shape[1]):\n",
        "            loss = criterion(output[:,-1,:], cls[:,-1])\n",
        "            loss += loss.item()\n",
        "            acc += (output[:,-1,:].argmax(1) == cls[:,-1]).sum().item()\n",
        "\n",
        "    return loss / len(data_), acc / len(data_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab_type": "code",
        "id": "zfPry8-D0S_n",
        "outputId": "3c525867-2d21-4c80-e539-fbdd7e8af2e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 936
        }
      },
      "source": [
        "from torch.utils.data.dataset import random_split\n",
        "N_EPOCHS = 20\n",
        "min_valid_loss = float('inf')\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1, gamma=0.9)\n",
        "\n",
        "#### Break test sets into 2 data sets validations and test data set\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "    train_loss, train_acc = train_func(train_dataset)\n",
        "    valid_loss, valid_acc = test_func(valid_dataset)\n",
        "\n",
        "    secs = int(time.time() - start_time)\n",
        "    mins = secs / 60\n",
        "    secs = secs % 60\n",
        "\n",
        "    print('Epoch: %d' %(epoch + 1), \" | time in %d minutes, %d seconds\" %(mins, secs))\n",
        "    print(f'\\tLoss: {train_loss:.4f}(train)\\t|\\tAcc: {train_acc * 100:.1f}%(train)')\n",
        "    print(f'\\tLoss: {valid_loss:.4f}(valid)\\t|\\tAcc: {valid_acc * 100:.1f}%(valid)')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1  | time in 0 minutes, 40 seconds\n",
            "\tLoss: 0.0046(train)\t|\tAcc: 90.8%(train)\n",
            "\tLoss: 0.0004(valid)\t|\tAcc: 78.4%(valid)\n",
            "Epoch: 2  | time in 0 minutes, 40 seconds\n",
            "\tLoss: 0.0002(train)\t|\tAcc: 99.6%(train)\n",
            "\tLoss: 0.0004(valid)\t|\tAcc: 83.8%(valid)\n",
            "Epoch: 3  | time in 0 minutes, 40 seconds\n",
            "\tLoss: 0.0001(train)\t|\tAcc: 99.8%(train)\n",
            "\tLoss: 0.0004(valid)\t|\tAcc: 82.4%(valid)\n",
            "Epoch: 4  | time in 0 minutes, 40 seconds\n",
            "\tLoss: 0.0001(train)\t|\tAcc: 99.8%(train)\n",
            "\tLoss: 0.0005(valid)\t|\tAcc: 82.1%(valid)\n",
            "Epoch: 5  | time in 0 minutes, 40 seconds\n",
            "\tLoss: 0.0001(train)\t|\tAcc: 99.8%(train)\n",
            "\tLoss: 0.0005(valid)\t|\tAcc: 83.5%(valid)\n",
            "Epoch: 6  | time in 0 minutes, 41 seconds\n",
            "\tLoss: 0.0000(train)\t|\tAcc: 99.9%(train)\n",
            "\tLoss: 0.0005(valid)\t|\tAcc: 83.9%(valid)\n",
            "Epoch: 7  | time in 0 minutes, 40 seconds\n",
            "\tLoss: 0.0000(train)\t|\tAcc: 100.0%(train)\n",
            "\tLoss: 0.0005(valid)\t|\tAcc: 83.7%(valid)\n",
            "Epoch: 8  | time in 0 minutes, 39 seconds\n",
            "\tLoss: 0.0000(train)\t|\tAcc: 100.0%(train)\n",
            "\tLoss: 0.0004(valid)\t|\tAcc: 83.6%(valid)\n",
            "Epoch: 9  | time in 0 minutes, 40 seconds\n",
            "\tLoss: 0.0000(train)\t|\tAcc: 100.0%(train)\n",
            "\tLoss: 0.0005(valid)\t|\tAcc: 84.0%(valid)\n",
            "Epoch: 10  | time in 0 minutes, 40 seconds\n",
            "\tLoss: 0.0000(train)\t|\tAcc: 100.0%(train)\n",
            "\tLoss: 0.0005(valid)\t|\tAcc: 84.0%(valid)\n",
            "Epoch: 11  | time in 0 minutes, 39 seconds\n",
            "\tLoss: 0.0000(train)\t|\tAcc: 100.0%(train)\n",
            "\tLoss: 0.0006(valid)\t|\tAcc: 83.6%(valid)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-97-2f85b24d458a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-96-9a1634d5d032>\u001b[0m in \u001b[0;36mtrain_func\u001b[0;34m(sub_train_)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m#print(text.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;31m#print(output.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m#print(cls.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-91-41bef72dd391>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mi_h\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0;31m#self.h = h.detach()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh_o\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    568\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0;32m--> 570\u001b[0;31m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    571\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "colab_type": "code",
        "id": "J1quUNQP0S_o",
        "colab": {}
      },
      "source": [
        "torch.save(model.state_dict(),\"./model7.pt\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5JibVtj7r18",
        "colab_type": "code",
        "outputId": "d9c958d8-d831-4720-e03f-9aff11bd36a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "for i in model.parameters():\n",
        "    print(i.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([34, 64])\n",
            "torch.Size([256, 64])\n",
            "torch.Size([256, 64])\n",
            "torch.Size([256])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 64])\n",
            "torch.Size([256, 64])\n",
            "torch.Size([256])\n",
            "torch.Size([256])\n",
            "torch.Size([34, 64])\n",
            "torch.Size([34])\n",
            "torch.Size([64])\n",
            "torch.Size([64])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vAGysPoCdEbl",
        "colab_type": "text"
      },
      "source": [
        "## Try Bidrectional GRU and LSTM\n",
        "\n",
        "Given the pattern of the numbers, bidirectional LSTM and GRU may work best for this situation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "37e79e47-17b5-4002-b577-5ca6a4ffc3bc",
        "id": "ahv6RZE8d3L4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "#### Download the data\n",
        "bptt=20\n",
        "tokenizer = get_tokenizer(\"spacy\")\n",
        "train_dataset, valid_dataset = HumanNumbers(root='data',bptt=bptt,data_select=('train', 'valid'))\n",
        "vocab = train_dataset.get_vocab()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3642lines [00:00, 36417.26lines/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "<function tokenizer at 0x7f27757ae730>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8001lines [00:00, 35494.12lines/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "51200\n",
            "51200\n",
            "torch.Size([51200, 20])\n",
            "torch.Size([51200, 20])\n",
            "14080\n",
            "14080\n",
            "torch.Size([14080, 20])\n",
            "torch.Size([14080, 20])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "my_0K711dZdO"
      },
      "source": [
        "### Bidirectional GRU (Model 8)\n",
        "\n",
        "This is testing GRU for multiple steps predictions. So given the 20 words, it makes 20 predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "7d695b56-25fe-4765-df3d-2426fa67ece8",
        "id": "g7gIk6HjdZdU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "nv = len(vocab.itos)\n",
        "nv"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "34"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "f8affda7-eb62-4a27-dcfd-9a18e8437bb7",
        "id": "z03d6TWCdZdX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "nh = 64\n",
        "nh"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fFeHCuJUdZdQ",
        "colab": {}
      },
      "source": [
        "class BatchNorm1dFlat(nn.BatchNorm1d):\n",
        "    \"`nn.BatchNorm1d`, but first flattens leading dimensions\"\n",
        "    def forward(self, x):\n",
        "        if x.dim()==2: return super().forward(x)\n",
        "        *f,l = x.shape\n",
        "        x = x.contiguous().view(-1,l)\n",
        "        return super().forward(x).view(*f,l)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1wtlZtUVdZdT",
        "colab": {}
      },
      "source": [
        "class Model8(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.i_h = nn.Embedding(num_embeddings=nv,embedding_dim = nh)\n",
        "        self.rnn = nn.GRU(nh, nh, 2, batch_first=True,bidirectional=True)\n",
        "        self.h_o = nn.Linear(2*nh,nv)\n",
        "        self.bn = BatchNorm1dFlat(2*nh)\n",
        "        self.h = torch.zeros(2*2, BATCH_SIZE, nh)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        res,h = self.rnn(self.i_h(x), self.h)\n",
        "        return self.h_o(self.bn(res))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ERrCFNgWdZdZ",
        "outputId": "c1dec7ab-6daf-4d89-e430-bb99a3b49251",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "model = Model8().to(device)\n",
        "model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model8(\n",
              "  (i_h): Embedding(34, 64)\n",
              "  (rnn): GRU(64, 64, num_layers=2, batch_first=True, bidirectional=True)\n",
              "  (h_o): Linear(in_features=128, out_features=34, bias=True)\n",
              "  (bn): BatchNorm1dFlat(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2GG3wvhZdZda",
        "colab": {}
      },
      "source": [
        "def generate_batch(batch):\n",
        "    #print(len(batch))\n",
        "    text = []\n",
        "    label = []\n",
        "    for entry in batch:\n",
        "        text.append(entry[0].numpy())\n",
        "        label.append(entry[1].numpy())\n",
        "    return torch.tensor(text), torch.tensor(label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ScF2nXLcdZdc",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def train_func(sub_train_):\n",
        "\n",
        "    # Train the model\n",
        "    train_loss = 0\n",
        "    train_acc = 0\n",
        "    #print(len(sub_train_))\n",
        "    data = DataLoader(sub_train_, batch_size=BATCH_SIZE, shuffle=True,\n",
        "                      collate_fn=generate_batch,drop_last=True)\n",
        "    for i, (text, cls) in enumerate(data):\n",
        "        optimizer.zero_grad()\n",
        "        text, cls = text.to(device), cls.to(device)\n",
        "        #print(text.shape)\n",
        "        output = model(text)\n",
        "        #print(output.shape)\n",
        "        #print(cls.shape)\n",
        "        for i in range(output.shape[1]):\n",
        "            loss = criterion(output[:,i,:], cls[:,i])\n",
        "            train_loss += loss.item()\n",
        "            train_acc += (output[:,i,:].argmax(1) == cls[:,i]).sum().item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "\n",
        "    # Adjust the learning rate\n",
        "    scheduler.step()\n",
        "\n",
        "    return train_loss / (len(sub_train_)*bptt), train_acc / (len(sub_train_)*bptt)\n",
        "\n",
        "def test_func(data_):\n",
        "    loss = 0\n",
        "    acc = 0\n",
        "    data = DataLoader(data_, batch_size=BATCH_SIZE, collate_fn=generate_batch,drop_last=True)\n",
        "    for text, cls in data:\n",
        "        text, cls = text.to(device), cls.to(device)\n",
        "        with torch.no_grad():\n",
        "            output = model(text)\n",
        "            #print(output.shape)\n",
        "            #print(cls.shape)\n",
        "            for i in range(output.shape[1]):\n",
        "                loss = criterion(output[:,i,:], cls[:,i])\n",
        "                loss += loss.item()\n",
        "                acc += (output[:,i,:].argmax(1) == cls[:,i]).sum().item()\n",
        "\n",
        "    return loss / (len(data_)*bptt), acc / (len(data_)*bptt)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab_type": "code",
        "outputId": "50abfc4b-a9c9-4206-8197-db0a651fec17",
        "id": "NTb-DfgidZde",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "N_EPOCHS = 10\n",
        "min_valid_loss = float('inf')\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1, gamma=0.9)\n",
        "\n",
        "#### Break test sets into 2 data sets validations and test data set\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "    train_loss, train_acc = train_func(train_dataset)\n",
        "    valid_loss, valid_acc = test_func(valid_dataset)\n",
        "\n",
        "    secs = int(time.time() - start_time)\n",
        "    mins = secs / 60\n",
        "    secs = secs % 60\n",
        "\n",
        "    print('Epoch: %d' %(epoch + 1), \" | time in %d minutes, %d seconds\" %(mins, secs))\n",
        "    print(f'\\tLoss: {train_loss:.4f}(train)\\t|\\tAcc: {train_acc * 100:.1f}%(train)')\n",
        "    print(f'\\tLoss: {valid_loss:.4f}(valid)\\t|\\tAcc: {valid_acc * 100:.1f}%(valid)')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1  | time in 1 minutes, 0 seconds\n",
            "\tLoss: 0.0499(train)\t|\tAcc: 38.9%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 25.7%(valid)\n",
            "Epoch: 2  | time in 1 minutes, 0 seconds\n",
            "\tLoss: 0.0697(train)\t|\tAcc: 34.6%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 26.8%(valid)\n",
            "Epoch: 3  | time in 1 minutes, 1 seconds\n",
            "\tLoss: 0.0818(train)\t|\tAcc: 33.4%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 27.6%(valid)\n",
            "Epoch: 4  | time in 1 minutes, 0 seconds\n",
            "\tLoss: 0.0877(train)\t|\tAcc: 33.3%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 27.3%(valid)\n",
            "Epoch: 5  | time in 1 minutes, 1 seconds\n",
            "\tLoss: 0.0959(train)\t|\tAcc: 32.1%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 26.3%(valid)\n",
            "Epoch: 6  | time in 0 minutes, 59 seconds\n",
            "\tLoss: 0.1034(train)\t|\tAcc: 31.2%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 26.1%(valid)\n",
            "Epoch: 7  | time in 0 minutes, 59 seconds\n",
            "\tLoss: 0.1049(train)\t|\tAcc: 31.0%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 24.4%(valid)\n",
            "Epoch: 8  | time in 0 minutes, 57 seconds\n",
            "\tLoss: 0.1124(train)\t|\tAcc: 30.0%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 24.1%(valid)\n",
            "Epoch: 9  | time in 1 minutes, 1 seconds\n",
            "\tLoss: 0.1170(train)\t|\tAcc: 29.9%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 25.2%(valid)\n",
            "Epoch: 10  | time in 0 minutes, 59 seconds\n",
            "\tLoss: 0.1207(train)\t|\tAcc: 29.4%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 25.3%(valid)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "colab_type": "code",
        "id": "lmZE3DnSdZdg",
        "colab": {}
      },
      "source": [
        "torch.save(model.state_dict(),\"./model8.pt\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uoSXUfmTeUeg"
      },
      "source": [
        "### Bidirectional LSTM (Model 9)\n",
        "\n",
        "This is testing LSTM for multiple steps predictions. So given the 20 words, it makes 20 predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "677f9288-beb7-4b90-c4a3-af03b2aea374",
        "id": "--h1c1eaeUei",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "nv = len(vocab.itos)\n",
        "nv"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "34"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "cda79bd8-6c44-4b6e-870b-b7d5530feba2",
        "id": "4y3kM-0UeUel",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "nh = 64\n",
        "nh"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "76ftnozseUen",
        "colab": {}
      },
      "source": [
        "class BatchNorm1dFlat(nn.BatchNorm1d):\n",
        "    \"`nn.BatchNorm1d`, but first flattens leading dimensions\"\n",
        "    def forward(self, x):\n",
        "        if x.dim()==2: return super().forward(x)\n",
        "        *f,l = x.shape\n",
        "        x = x.contiguous().view(-1,l)\n",
        "        return super().forward(x).view(*f,l)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "87kE6J1aeUep",
        "colab": {}
      },
      "source": [
        "class Model9(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.i_h = nn.Embedding(num_embeddings=nv,embedding_dim = nh)\n",
        "        self.rnn = nn.LSTM(nh, nh, 2, batch_first=True,bidirectional=True)\n",
        "        self.h_o = nn.Linear(2*nh,nv)\n",
        "        self.bn = BatchNorm1dFlat(2*nh)\n",
        "        self.h = torch.zeros(2*2, BATCH_SIZE, nh)\n",
        "        self.c = torch.zeros(2*2, BATCH_SIZE, nh)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        res,(h,c) = self.rnn(self.i_h(x), (self.h,self.c))\n",
        "        return self.h_o(self.bn(res))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "1f2d5b04-ecb5-461f-e335-4ebacc93050b",
        "id": "mop1GwyCeUer",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "model = Model9().to(device)\n",
        "model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model9(\n",
              "  (i_h): Embedding(34, 64)\n",
              "  (rnn): LSTM(64, 64, num_layers=2, batch_first=True, bidirectional=True)\n",
              "  (h_o): Linear(in_features=128, out_features=34, bias=True)\n",
              "  (bn): BatchNorm1dFlat(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-OKtk5XpeUes",
        "colab": {}
      },
      "source": [
        "def generate_batch(batch):\n",
        "    #print(len(batch))\n",
        "    text = []\n",
        "    label = []\n",
        "    for entry in batch:\n",
        "        text.append(entry[0].numpy())\n",
        "        label.append(entry[1].numpy())\n",
        "    return torch.tensor(text), torch.tensor(label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wy6E1GgFeUeu",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def train_func(sub_train_):\n",
        "\n",
        "    # Train the model\n",
        "    train_loss = 0\n",
        "    train_acc = 0\n",
        "    #print(len(sub_train_))\n",
        "    data = DataLoader(sub_train_, batch_size=BATCH_SIZE, shuffle=True,\n",
        "                      collate_fn=generate_batch,drop_last=True)\n",
        "    for i, (text, cls) in enumerate(data):\n",
        "        optimizer.zero_grad()\n",
        "        text, cls = text.to(device), cls.to(device)\n",
        "        #print(text.shape)\n",
        "        output = model(text)\n",
        "        #print(output.shape)\n",
        "        #print(cls.shape)\n",
        "        for i in range(output.shape[1]):\n",
        "            loss = criterion(output[:,i,:], cls[:,i])\n",
        "            train_loss += loss.item()\n",
        "            train_acc += (output[:,i,:].argmax(1) == cls[:,i]).sum().item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "\n",
        "    # Adjust the learning rate\n",
        "    scheduler.step()\n",
        "\n",
        "    return train_loss / (len(sub_train_)*bptt), train_acc / (len(sub_train_)*bptt)\n",
        "\n",
        "def test_func(data_):\n",
        "    loss = 0\n",
        "    acc = 0\n",
        "    data = DataLoader(data_, batch_size=BATCH_SIZE, collate_fn=generate_batch,drop_last=True)\n",
        "    for text, cls in data:\n",
        "        text, cls = text.to(device), cls.to(device)\n",
        "        with torch.no_grad():\n",
        "            output = model(text)\n",
        "            #print(output.shape)\n",
        "            #print(cls.shape)\n",
        "            for i in range(output.shape[1]):\n",
        "                loss = criterion(output[:,i,:], cls[:,i])\n",
        "                loss += loss.item()\n",
        "                acc += (output[:,i,:].argmax(1) == cls[:,i]).sum().item()\n",
        "\n",
        "    return loss / (len(data_)*bptt), acc / (len(data_)*bptt)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab_type": "code",
        "id": "x5YJiVsbeUew",
        "outputId": "07804caf-6957-4028-e7fb-19576bc69f40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "N_EPOCHS = 10\n",
        "min_valid_loss = float('inf')\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1, gamma=0.9)\n",
        "\n",
        "#### Break test sets into 2 data sets validations and test data set\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "    train_loss, train_acc = train_func(train_dataset)\n",
        "    valid_loss, valid_acc = test_func(valid_dataset)\n",
        "\n",
        "    secs = int(time.time() - start_time)\n",
        "    mins = secs / 60\n",
        "    secs = secs % 60\n",
        "\n",
        "    print('Epoch: %d' %(epoch + 1), \" | time in %d minutes, %d seconds\" %(mins, secs))\n",
        "    print(f'\\tLoss: {train_loss:.4f}(train)\\t|\\tAcc: {train_acc * 100:.1f}%(train)')\n",
        "    print(f'\\tLoss: {valid_loss:.4f}(valid)\\t|\\tAcc: {valid_acc * 100:.1f}%(valid)')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1  | time in 1 minutes, 2 seconds\n",
            "\tLoss: 0.0233(train)\t|\tAcc: 65.7%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 58.3%(valid)\n",
            "Epoch: 2  | time in 1 minutes, 0 seconds\n",
            "\tLoss: 0.0208(train)\t|\tAcc: 74.7%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 56.1%(valid)\n",
            "Epoch: 3  | time in 1 minutes, 0 seconds\n",
            "\tLoss: 0.0212(train)\t|\tAcc: 76.5%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 61.5%(valid)\n",
            "Epoch: 4  | time in 1 minutes, 1 seconds\n",
            "\tLoss: 0.0208(train)\t|\tAcc: 77.5%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 63.2%(valid)\n",
            "Epoch: 5  | time in 1 minutes, 2 seconds\n",
            "\tLoss: 0.0209(train)\t|\tAcc: 75.8%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 57.1%(valid)\n",
            "Epoch: 6  | time in 1 minutes, 1 seconds\n",
            "\tLoss: 0.0221(train)\t|\tAcc: 74.7%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 57.7%(valid)\n",
            "Epoch: 7  | time in 1 minutes, 3 seconds\n",
            "\tLoss: 0.0242(train)\t|\tAcc: 75.4%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 61.3%(valid)\n",
            "Epoch: 8  | time in 1 minutes, 2 seconds\n",
            "\tLoss: 0.0220(train)\t|\tAcc: 78.0%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 62.0%(valid)\n",
            "Epoch: 9  | time in 1 minutes, 4 seconds\n",
            "\tLoss: 0.0234(train)\t|\tAcc: 77.8%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 61.6%(valid)\n",
            "Epoch: 10  | time in 1 minutes, 3 seconds\n",
            "\tLoss: 0.0238(train)\t|\tAcc: 77.7%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 61.3%(valid)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "colab_type": "code",
        "id": "q7Q-fCrEeUey",
        "colab": {}
      },
      "source": [
        "torch.save(model.state_dict(),\"./model9.pt\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}