{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text_Number_Prediction_single_step_PyTorch_Keras",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMRIY6iv+s+ymkCj7iFBB6r",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sangeetsaurabh/PyTorch_Keras_Experiment/blob/master/Text_Number_Prediction/Text_Number_Prediction_single_step_PyTorch_Keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDbpkkgIzGIK",
        "colab_type": "text"
      },
      "source": [
        "### Predict the next number in the sequence\n",
        "\n",
        "Given a set of numbers, goal of the model is to predict next number in the sequence. \n",
        "\n",
        "For example, model can be given input like - eight thousand one , eight thousand two , eight thousand three , eight thousand four , eight thousand five , eight thousand six , eight thousand seven , eight thousand eight , eight thousand nine , eight thousand ten , eight thousand eleven , eight thousand twelve....\n",
        "\n",
        "Model will predict next number given the one input. Model in this notebook predicts 21st word given 20 words like above (last step prediction).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "149iYfEnjyLR",
        "colab_type": "code",
        "outputId": "63b8ace2-6104-4a48-f7d8-1dc1c7a69583",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "#### Make sure that the right version of Torch is there\n",
        "!pip install torchtext==0.6.0\n",
        "import torchtext\n",
        "print(torchtext.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchtext==0.6.0 in /usr/local/lib/python3.6/dist-packages (0.6.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6.0) (1.5.0+cu101)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6.0) (1.12.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6.0) (1.18.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6.0) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6.0) (4.41.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6.0) (0.1.90)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->torchtext==0.6.0) (0.16.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.6.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.6.0) (2020.4.5.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.6.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.6.0) (2.9)\n",
            "0.6.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RR4eRGbbjJHU",
        "colab_type": "code",
        "outputId": "2a978c25-d99d-4872-fe89-aa7fa40b6d37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYx3rbtw0NBL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#drive.flush_and_unmount"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBaVXPQZuWLV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#### Setting up the right seed to make Keras result more consistent\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import random as python_random\n",
        "\n",
        "# The below is necessary for starting Numpy generated random numbers\n",
        "# in a well-defined initial state.\n",
        "np.random.seed(123)\n",
        "\n",
        "# The below is necessary for starting core Python generated random numbers\n",
        "# in a well-defined state.\n",
        "python_random.seed(123)\n",
        "\n",
        "# The below set_seed() will make random number generation\n",
        "# in the TensorFlow backend have a well-defined initial state.\n",
        "# For further details, see:\n",
        "# https://www.tensorflow.org/api_docs/python/tf/random/set_seed\n",
        "tf.random.set_seed(1234)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRJv3gWMi6g-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#### Setting up path to import important data preparation Python module\n",
        "import sys\n",
        "import os\n",
        "sys.path.append('/content/drive/My Drive/Colab Notebooks/torch_pipe/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItOt_tGZi6hJ",
        "colab_type": "code",
        "outputId": "a8793d69-854e-4a07-8856-4a3561dac79d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "os.getcwd()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXNSZjr1nkIY",
        "colab_type": "code",
        "outputId": "f1969cde-dacd-4fda-a37b-b0f4485564e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        }
      },
      "source": [
        "####Loading up TPU\n",
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
        "tf.config.experimental_connect_to_cluster(resolver)\n",
        "# This is the TPU initialization code that has to be at the beginning.\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "strategy = tf.distribute.experimental.TPUStrategy(resolver)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.63.181.178:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.63.181.178:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bt_V_qOIi6hR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#### Using torch utilities to prepare the features. Importing all the important files\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from Util.human_language_modeling import *\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "import time\n",
        "import logging"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7iRyHrqii6hY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#### Enabling logging\n",
        "import logging\n",
        "logger = logging.getLogger()\n",
        "fhandler = logging.FileHandler(filename='mylog.log', mode='a')\n",
        "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
        "fhandler.setFormatter(formatter)\n",
        "logger.addHandler(fhandler)\n",
        "logger.setLevel(logging.DEBUG)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4Gzgd_Ei6hf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#### Setting up the batch size and length of the sequence\n",
        "BATCH_SIZE = 64 ## defining the batch size\n",
        "bptt = 20 ## back propogration through LSTM\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srAakqVfi6hy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### A simplie python function to show text given an array of vectors\n",
        "def show_text(input_vector):\n",
        "    separator = ' '\n",
        "    txt = separator.join([vocab.itos[i] for i in input_vector])\n",
        "    return txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9pubLZDi6h4",
        "colab_type": "text"
      },
      "source": [
        "#### Download the train and validation data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-MF6hGBi6iB",
        "colab_type": "code",
        "outputId": "15783f80-dfc9-4137-8c7a-ee35b1f3ca54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "tokenizer = get_tokenizer(\"spacy\")\n",
        "train_dataset, valid_dataset = HumanNumbers(root='data',bptt=bptt,batch_size=BATCH_SIZE,data_select=('train', 'valid'))\n",
        "vocab = train_dataset.get_vocab()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:root:Building Vocab based on /content/drive/My Drive/Colab Notebooks/torch_pipe/Human_Numberlearning/Data/train.txt\n",
            "3641lines [00:00, 36396.41lines/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "<function tokenizer at 0x7f34df5ad950>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8001lines [00:00, 35296.82lines/s]\n",
            "INFO:root:Vocab has 34 entries\n",
            "INFO:root:Creating train data\n",
            "INFO:root:Creating valid data\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "51200\n",
            "51200\n",
            "torch.Size([51200, 20])\n",
            "torch.Size([51200, 20])\n",
            "14080\n",
            "14080\n",
            "torch.Size([14080, 20])\n",
            "torch.Size([14080, 20])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4iNmEGzoEFN",
        "colab_type": "text"
      },
      "source": [
        "#### Extract the features for Keras/Tensor Flow implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9I5fFdykqMqd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional, GRU, SimpleRNN\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import initializers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRAfySwzmVl1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#### Building input features and lables for machine learning models\n",
        "train_x = train_dataset.input_data.numpy()\n",
        "train_label = train_dataset.label_data[:,-1].numpy().astype(int)\n",
        "train_y = tf.keras.utils.to_categorical(train_label, num_classes=len(vocab.itos))\n",
        "\n",
        "valid_x = valid_dataset.input_data.numpy()\n",
        "valid_label = valid_dataset.label_data[:,-1].numpy()\n",
        "valid_y = tf.keras.utils.to_categorical(valid_label, num_classes=len(vocab.itos))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "342a1nWPni1X",
        "colab_type": "code",
        "outputId": "07ce005c-5f8d-4ab3-ccc3-50d3cd70cdbc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print(train_x.shape)\n",
        "print (train_y.shape)\n",
        "print(valid_x.shape)\n",
        "print(valid_y.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(51200, 20)\n",
            "(51200, 34)\n",
            "(14080, 20)\n",
            "(14080, 34)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMkXv7X6fiYs",
        "colab_type": "text"
      },
      "source": [
        "##### Create the batch data for Train and Validation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLX-gWBXft86",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#### Setting up Keras dataset to feed into machine learning models\n",
        "BUFFER_SIZE = train_x.shape[0] ## Shuffling the data across entire dataset before building the batch\n",
        "\n",
        "train_batch = tf.data.Dataset.from_tensor_slices((train_x, train_y))\n",
        "train_batch = train_batch.shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "\n",
        "val_batch = tf.data.Dataset.from_tensor_slices((valid_x, valid_y))\n",
        "val_batch = val_batch.batch(BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Lp26TcaYZ8U",
        "colab_type": "text"
      },
      "source": [
        "#### Simple DNN to do the prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ha0bqpSRvbuR",
        "colab_type": "code",
        "outputId": "856f4854-e37a-4867-8f26-561f43763a76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "model = keras.Sequential(\n",
        "    [\n",
        "        keras.layers.Embedding(len(vocab.itos), 100, input_length=train_x.shape[1]),\n",
        "        keras.layers.Dense(64, activation=\"relu\"),\n",
        "        keras.layers.BatchNormalization(),\n",
        "        keras.layers.Dense(len(vocab.itos), activation=\"softmax\"),\n",
        "        keras.layers.Lambda(lambda x: x[:,-1])\n",
        "    ]\n",
        ")\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, 20, 100)           3400      \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 20, 64)            6464      \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 20, 64)            256       \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 20, 34)            2210      \n",
            "_________________________________________________________________\n",
            "lambda_1 (Lambda)            (None, 34)                0         \n",
            "=================================================================\n",
            "Total params: 12,330\n",
            "Trainable params: 12,202\n",
            "Non-trainable params: 128\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sQO8QaIcYxmY",
        "colab": {}
      },
      "source": [
        "adam = Adam(lr=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['categorical_accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "b3b99275-99a7-42d6-9a61-29439d6955f3",
        "id": "GWTf-V8aYxmc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "#history = model.fit(train_x, train_y, epochs=10, batch_size=64, verbose=1,validation_data=(valid_x,valid_y))\n",
        "history = model.fit(train_batch, epochs=10, verbose=1,validation_data=val_batch)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "800/800 [==============================] - 9s 11ms/step - loss: 1.8777 - categorical_accuracy: 0.2337 - val_loss: 3.1220 - val_categorical_accuracy: 0.0844\n",
            "Epoch 2/10\n",
            "800/800 [==============================] - 9s 12ms/step - loss: 1.8393 - categorical_accuracy: 0.2380 - val_loss: 3.0730 - val_categorical_accuracy: 0.1884\n",
            "Epoch 3/10\n",
            "800/800 [==============================] - 8s 10ms/step - loss: 1.8364 - categorical_accuracy: 0.2397 - val_loss: 3.0727 - val_categorical_accuracy: 0.0844\n",
            "Epoch 4/10\n",
            "800/800 [==============================] - 9s 12ms/step - loss: 1.8329 - categorical_accuracy: 0.2371 - val_loss: 3.1444 - val_categorical_accuracy: 0.0909\n",
            "Epoch 5/10\n",
            "800/800 [==============================] - 8s 10ms/step - loss: 1.8303 - categorical_accuracy: 0.2397 - val_loss: 3.1492 - val_categorical_accuracy: 0.0839\n",
            "Epoch 6/10\n",
            "800/800 [==============================] - 9s 12ms/step - loss: 1.8287 - categorical_accuracy: 0.2405 - val_loss: 3.1893 - val_categorical_accuracy: 0.0839\n",
            "Epoch 7/10\n",
            "800/800 [==============================] - 8s 11ms/step - loss: 1.8289 - categorical_accuracy: 0.2389 - val_loss: 3.2284 - val_categorical_accuracy: 0.1817\n",
            "Epoch 8/10\n",
            "800/800 [==============================] - 10s 12ms/step - loss: 1.8281 - categorical_accuracy: 0.2400 - val_loss: 3.0919 - val_categorical_accuracy: 0.1762\n",
            "Epoch 9/10\n",
            "800/800 [==============================] - 8s 11ms/step - loss: 1.8277 - categorical_accuracy: 0.2395 - val_loss: 3.0899 - val_categorical_accuracy: 0.1903\n",
            "Epoch 10/10\n",
            "800/800 [==============================] - 9s 12ms/step - loss: 1.8263 - categorical_accuracy: 0.2413 - val_loss: 3.0684 - val_categorical_accuracy: 0.0840\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xj6pkWZUY8Oz",
        "colab_type": "text"
      },
      "source": [
        "This sequential layer network didn't produce the best results. This was expected as simple DNN is not the right way to predict 21st word given 20 words. Let's customize DNN to take the sequence of 20 words."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxbR7WxpQqIE",
        "colab_type": "text"
      },
      "source": [
        "#### DNN to do the prediction\n",
        "\n",
        "Customizing DNN to process one word at a time in a sequence. This is more like a custom RNN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0dAiDoZvRwI",
        "colab_type": "code",
        "outputId": "1d01ed49-8b05-4f94-de6d-979e247c5370",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow import keras\n",
        "\n",
        "nh = BATCH_SIZE\n",
        "\n",
        "# Define a Functional model to do a softmax on final dense layer\n",
        "inputs = keras.Input((nh))\n",
        "outputs = layers.Dense(len(vocab.itos), activation=\"softmax\")(inputs)\n",
        "model = keras.Model(inputs, outputs)\n",
        "\n",
        "class CustomRNN(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(CustomRNN, self).__init__()\n",
        "        self.embedding1 = layers.Embedding(len(vocab.itos), nh, input_length=train_x.shape[1])\n",
        "        self.projection_1 = layers.Dense(units=64, activation=\"relu\")\n",
        "        self.batchnormal = layers.BatchNormalization()\n",
        "        # Our previously-defined Functional model\n",
        "        self.classifier = model\n",
        "\n",
        "    def call(self, inputs):\n",
        "        ### Initialize the weights\n",
        "        if inputs.shape[0] == None:\n",
        "          bs = BATCH_SIZE\n",
        "        else:\n",
        "          bs = inputs.shape[0]\n",
        "        h = tf.zeros(shape=(bs, nh))\n",
        "        ### going in the loop to pick one word at a time\n",
        "        for t in range(inputs.shape[1]):\n",
        "            x = inputs[:, t]\n",
        "            h = h + self.embedding1(x)\n",
        "            h = self.batchnormal(self.projection_1(h))\n",
        "        return self.classifier(h)\n",
        "\n",
        "rnn_model = CustomRNN()\n",
        "rnn_model.predict(valid_x).shape\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14080, 34)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b42I7AM5vyjq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "adam = Adam(lr=0.01)\n",
        "rnn_model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['categorical_accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6hnaBBjv33c",
        "colab_type": "code",
        "outputId": "3e318657-14e1-4f82-8466-ebbbd47309b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        }
      },
      "source": [
        "#### Train the model\n",
        "#history = rnn_model.fit(train_x, train_y, epochs=20, batch_size=64, verbose=1,validation_data=(valid_x,valid_y))\n",
        "history = rnn_model.fit(train_batch, epochs=20, verbose=1,validation_data=val_batch)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "800/800 [==============================] - 9s 11ms/step - loss: 1.6653 - categorical_accuracy: 0.4821 - val_loss: 1.9949 - val_categorical_accuracy: 0.4697\n",
            "Epoch 2/20\n",
            "800/800 [==============================] - 8s 10ms/step - loss: 1.0610 - categorical_accuracy: 0.6389 - val_loss: 2.1035 - val_categorical_accuracy: 0.4915\n",
            "Epoch 3/20\n",
            "800/800 [==============================] - 8s 10ms/step - loss: 0.8751 - categorical_accuracy: 0.7025 - val_loss: 2.0762 - val_categorical_accuracy: 0.5068\n",
            "Epoch 4/20\n",
            "800/800 [==============================] - 8s 10ms/step - loss: 0.7418 - categorical_accuracy: 0.7523 - val_loss: 2.2044 - val_categorical_accuracy: 0.5436\n",
            "Epoch 5/20\n",
            "800/800 [==============================] - 8s 10ms/step - loss: 0.6657 - categorical_accuracy: 0.7792 - val_loss: 2.1817 - val_categorical_accuracy: 0.5724\n",
            "Epoch 6/20\n",
            "800/800 [==============================] - 8s 10ms/step - loss: 0.5939 - categorical_accuracy: 0.8024 - val_loss: 2.3753 - val_categorical_accuracy: 0.5554\n",
            "Epoch 7/20\n",
            "800/800 [==============================] - 8s 10ms/step - loss: 0.5266 - categorical_accuracy: 0.8238 - val_loss: 2.3830 - val_categorical_accuracy: 0.5522\n",
            "Epoch 8/20\n",
            "800/800 [==============================] - 8s 10ms/step - loss: 0.4947 - categorical_accuracy: 0.8348 - val_loss: 2.3541 - val_categorical_accuracy: 0.5881\n",
            "Epoch 9/20\n",
            "800/800 [==============================] - 8s 10ms/step - loss: 0.4428 - categorical_accuracy: 0.8536 - val_loss: 2.3244 - val_categorical_accuracy: 0.5898\n",
            "Epoch 10/20\n",
            "800/800 [==============================] - 8s 10ms/step - loss: 0.4089 - categorical_accuracy: 0.8647 - val_loss: 2.2515 - val_categorical_accuracy: 0.5914\n",
            "Epoch 11/20\n",
            "800/800 [==============================] - 8s 10ms/step - loss: 0.3968 - categorical_accuracy: 0.8698 - val_loss: 2.3476 - val_categorical_accuracy: 0.5786\n",
            "Epoch 12/20\n",
            "800/800 [==============================] - 8s 10ms/step - loss: 0.3746 - categorical_accuracy: 0.8764 - val_loss: 2.5250 - val_categorical_accuracy: 0.5825\n",
            "Epoch 13/20\n",
            "800/800 [==============================] - 8s 10ms/step - loss: 0.3337 - categorical_accuracy: 0.8919 - val_loss: 2.8949 - val_categorical_accuracy: 0.5879\n",
            "Epoch 14/20\n",
            "800/800 [==============================] - 8s 10ms/step - loss: 0.3233 - categorical_accuracy: 0.8947 - val_loss: 3.1808 - val_categorical_accuracy: 0.5695\n",
            "Epoch 15/20\n",
            "800/800 [==============================] - 8s 10ms/step - loss: 0.3047 - categorical_accuracy: 0.9012 - val_loss: 3.3667 - val_categorical_accuracy: 0.5810\n",
            "Epoch 16/20\n",
            "800/800 [==============================] - 8s 10ms/step - loss: 0.2956 - categorical_accuracy: 0.9043 - val_loss: 3.0210 - val_categorical_accuracy: 0.5884\n",
            "Epoch 17/20\n",
            "800/800 [==============================] - 8s 10ms/step - loss: 0.2835 - categorical_accuracy: 0.9075 - val_loss: 3.0472 - val_categorical_accuracy: 0.5975\n",
            "Epoch 18/20\n",
            "800/800 [==============================] - 8s 10ms/step - loss: 0.2728 - categorical_accuracy: 0.9119 - val_loss: 2.6306 - val_categorical_accuracy: 0.6153\n",
            "Epoch 19/20\n",
            "800/800 [==============================] - 8s 10ms/step - loss: 0.2602 - categorical_accuracy: 0.9172 - val_loss: 3.2256 - val_categorical_accuracy: 0.6018\n",
            "Epoch 20/20\n",
            "800/800 [==============================] - 8s 10ms/step - loss: 0.2459 - categorical_accuracy: 0.9206 - val_loss: 3.4205 - val_categorical_accuracy: 0.5880\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1hJcZd4TbprQ",
        "colab_type": "text"
      },
      "source": [
        "As can be seen, performance improved quite a bit with the implmentation of SQL model. Let's try RNN, GRU and LSTM models to see what happens."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHsguJfA0IDL",
        "colab_type": "text"
      },
      "source": [
        "#### Simple RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Thwq-UlMeSJi",
        "colab_type": "code",
        "outputId": "ce55d6c1-2d00-4059-ce3c-682a858bf83a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(len(vocab.itos), 64, input_length=train_x.shape[1]))\n",
        "model.add(SimpleRNN(150))\n",
        "model.add(Dense(len(vocab.itos), activation='softmax'))\n",
        "\n",
        "### Compile the model\n",
        "adam = Adam(lr=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['categorical_accuracy'])\n",
        "\n",
        "#earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=0, mode='auto')\n",
        "history = model.fit(train_x, train_y, epochs=10, batch_size=64, verbose=1,validation_data=(valid_x,valid_y))\n",
        "#history = model.fit(train_batch, epochs=10, verbose=1,validation_data=val_batch)\n",
        "#print model.summary()\n",
        "print(model)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "800/800 [==============================] - 14s 17ms/step - loss: 1.4330 - categorical_accuracy: 0.5035 - val_loss: 2.0118 - val_categorical_accuracy: 0.5027\n",
            "Epoch 2/10\n",
            "800/800 [==============================] - 12s 15ms/step - loss: 1.3739 - categorical_accuracy: 0.5139 - val_loss: 1.8240 - val_categorical_accuracy: 0.4976\n",
            "Epoch 3/10\n",
            "800/800 [==============================] - 11s 14ms/step - loss: 1.5678 - categorical_accuracy: 0.4784 - val_loss: 2.2471 - val_categorical_accuracy: 0.4240\n",
            "Epoch 4/10\n",
            "800/800 [==============================] - 11s 14ms/step - loss: 1.5353 - categorical_accuracy: 0.4814 - val_loss: 2.2322 - val_categorical_accuracy: 0.4533\n",
            "Epoch 5/10\n",
            "800/800 [==============================] - 13s 16ms/step - loss: 1.4467 - categorical_accuracy: 0.4915 - val_loss: 2.0925 - val_categorical_accuracy: 0.4751\n",
            "Epoch 6/10\n",
            "800/800 [==============================] - 10s 13ms/step - loss: 1.3916 - categorical_accuracy: 0.5005 - val_loss: 2.4835 - val_categorical_accuracy: 0.4795\n",
            "Epoch 7/10\n",
            "800/800 [==============================] - 11s 13ms/step - loss: 1.3917 - categorical_accuracy: 0.4981 - val_loss: 2.4411 - val_categorical_accuracy: 0.4732\n",
            "Epoch 8/10\n",
            "800/800 [==============================] - 11s 13ms/step - loss: 1.5047 - categorical_accuracy: 0.4822 - val_loss: 2.2287 - val_categorical_accuracy: 0.4453\n",
            "Epoch 9/10\n",
            "800/800 [==============================] - 11s 14ms/step - loss: 1.4552 - categorical_accuracy: 0.4857 - val_loss: 2.2754 - val_categorical_accuracy: 0.4501\n",
            "Epoch 10/10\n",
            "800/800 [==============================] - 11s 14ms/step - loss: 1.6478 - categorical_accuracy: 0.4629 - val_loss: 2.2532 - val_categorical_accuracy: 0.3849\n",
            "<tensorflow.python.keras.engine.sequential.Sequential object at 0x7f34db34c550>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfIZI6mQt3qo",
        "colab_type": "text"
      },
      "source": [
        "#### GRU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "b45f0482-1dd9-4b58-c8f5-9e53d55608de",
        "id": "1kR0HdWSt-fX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(len(vocab.itos), output_dim=64, input_length=train_x.shape[1]))\n",
        "model.add(GRU(units=150))\n",
        "model.add(Dense(len(vocab.itos), activation='softmax'))\n",
        "\n",
        "### Compile the model\n",
        "adam = Adam(lr=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['categorical_accuracy'])\n",
        "\n",
        "#earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=0, mode='auto')\n",
        "#history = model.fit(train_x, train_y, epochs=10, batch_size=64, verbose=1,validation_data=(valid_x,valid_y))\n",
        "history = model.fit(train_batch, epochs=10, verbose=1,validation_data=val_batch)\n",
        "print (model.summary())\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "800/800 [==============================] - 22s 27ms/step - loss: 0.4697 - categorical_accuracy: 0.8517 - val_loss: 1.2467 - val_categorical_accuracy: 0.7963\n",
            "Epoch 2/10\n",
            "800/800 [==============================] - 21s 26ms/step - loss: 0.9145 - categorical_accuracy: 0.7364 - val_loss: 1.5323 - val_categorical_accuracy: 0.6738\n",
            "Epoch 3/10\n",
            "800/800 [==============================] - 22s 28ms/step - loss: 0.4715 - categorical_accuracy: 0.8524 - val_loss: 1.4716 - val_categorical_accuracy: 0.7714\n",
            "Epoch 4/10\n",
            "800/800 [==============================] - 21s 26ms/step - loss: 0.2146 - categorical_accuracy: 0.9395 - val_loss: 1.5443 - val_categorical_accuracy: 0.8058\n",
            "Epoch 5/10\n",
            "800/800 [==============================] - 21s 26ms/step - loss: 0.1236 - categorical_accuracy: 0.9682 - val_loss: 1.9054 - val_categorical_accuracy: 0.7994\n",
            "Epoch 6/10\n",
            "800/800 [==============================] - 21s 26ms/step - loss: 0.1129 - categorical_accuracy: 0.9688 - val_loss: 1.8607 - val_categorical_accuracy: 0.8050\n",
            "Epoch 7/10\n",
            "800/800 [==============================] - 21s 26ms/step - loss: 0.1160 - categorical_accuracy: 0.9686 - val_loss: 2.0241 - val_categorical_accuracy: 0.8136\n",
            "Epoch 8/10\n",
            "800/800 [==============================] - 21s 26ms/step - loss: 0.0779 - categorical_accuracy: 0.9800 - val_loss: 2.5085 - val_categorical_accuracy: 0.7556\n",
            "Epoch 9/10\n",
            "800/800 [==============================] - 21s 27ms/step - loss: 0.0684 - categorical_accuracy: 0.9814 - val_loss: 2.2238 - val_categorical_accuracy: 0.7826\n",
            "Epoch 10/10\n",
            "800/800 [==============================] - 21s 26ms/step - loss: 0.0972 - categorical_accuracy: 0.9727 - val_loss: 1.9162 - val_categorical_accuracy: 0.8170\n",
            "Model: \"sequential_27\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_32 (Embedding)     (None, 20, 64)            2176      \n",
            "_________________________________________________________________\n",
            "gru_10 (GRU)                 (None, 150)               97200     \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 34)                5134      \n",
            "=================================================================\n",
            "Total params: 104,510\n",
            "Trainable params: 104,510\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "c928b03e-c9de-4458-d3d6-2f693031f35e",
        "id": "dDXpMarkugP0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        }
      },
      "source": [
        "#### Let's try the stateful\n",
        "model = Sequential()\n",
        "model.add(Embedding(len(vocab.itos), 64, input_length=train_x.shape[1],batch_input_shape=(BATCH_SIZE,train_x.shape[1])))\n",
        "model.add(GRU(150,stateful=True))\n",
        "model.add(Dense(len(vocab.itos), activation='softmax'))\n",
        "\n",
        "### Compile the model\n",
        "adam = Adam(lr=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['categorical_accuracy'])\n",
        "\n",
        "#earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=0, mode='auto')\n",
        "#history = model.fit(train_x, train_y, epochs=10, batch_size=64, verbose=1,validation_data=(valid_x,valid_y))\n",
        "history = model.fit(train_batch, epochs=10, verbose=1,validation_data=val_batch)\n",
        "print (model.summary())\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "800/800 [==============================] - 19s 24ms/step - loss: 0.4722 - categorical_accuracy: 0.8473 - val_loss: 1.6509 - val_categorical_accuracy: 0.8248\n",
            "Epoch 2/10\n",
            "800/800 [==============================] - 19s 23ms/step - loss: 0.8802 - categorical_accuracy: 0.7494 - val_loss: 1.3874 - val_categorical_accuracy: 0.6442\n",
            "Epoch 3/10\n",
            "800/800 [==============================] - 19s 24ms/step - loss: 0.4198 - categorical_accuracy: 0.8596 - val_loss: 1.6147 - val_categorical_accuracy: 0.7674\n",
            "Epoch 4/10\n",
            "800/800 [==============================] - 19s 23ms/step - loss: 0.1937 - categorical_accuracy: 0.9420 - val_loss: 1.6947 - val_categorical_accuracy: 0.7907\n",
            "Epoch 5/10\n",
            "800/800 [==============================] - 19s 23ms/step - loss: 0.1356 - categorical_accuracy: 0.9626 - val_loss: 2.4478 - val_categorical_accuracy: 0.7494\n",
            "Epoch 6/10\n",
            "800/800 [==============================] - 19s 23ms/step - loss: 0.0761 - categorical_accuracy: 0.9826 - val_loss: 2.0892 - val_categorical_accuracy: 0.8006\n",
            "Epoch 7/10\n",
            "800/800 [==============================] - 19s 23ms/step - loss: 0.0575 - categorical_accuracy: 0.9886 - val_loss: 2.3233 - val_categorical_accuracy: 0.8218\n",
            "Epoch 8/10\n",
            "800/800 [==============================] - 19s 24ms/step - loss: 0.0910 - categorical_accuracy: 0.9776 - val_loss: 2.3094 - val_categorical_accuracy: 0.7820\n",
            "Epoch 9/10\n",
            "800/800 [==============================] - 19s 24ms/step - loss: 0.1232 - categorical_accuracy: 0.9687 - val_loss: 2.2319 - val_categorical_accuracy: 0.8056\n",
            "Epoch 10/10\n",
            "800/800 [==============================] - 19s 23ms/step - loss: 0.0730 - categorical_accuracy: 0.9843 - val_loss: 2.5630 - val_categorical_accuracy: 0.8108\n",
            "Model: \"sequential_28\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_33 (Embedding)     (64, 20, 64)              2176      \n",
            "_________________________________________________________________\n",
            "gru_11 (GRU)                 (64, 150)                 97200     \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (64, 34)                  5134      \n",
            "=================================================================\n",
            "Total params: 104,510\n",
            "Trainable params: 104,510\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zR9xN7PyW6I",
        "colab_type": "text"
      },
      "source": [
        "#### LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "9d5b789b-c215-4406-a880-feb3820e0d9a",
        "id": "mruLse_dMdxP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(len(vocab.itos), output_dim=64, input_length=train_x.shape[1]))\n",
        "model.add(LSTM(units=150))\n",
        "model.add(Dense(len(vocab.itos), activation='softmax'))\n",
        "\n",
        "### Compile the model\n",
        "adam = Adam(lr=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['categorical_accuracy'])\n",
        "\n",
        "#earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=0, mode='auto')\n",
        "#history = model.fit(train_x, train_y, epochs=10, batch_size=64, verbose=1,validation_data=(valid_x,valid_y))\n",
        "history = model.fit(train_batch, epochs=10, verbose=1,validation_data=val_batch)\n",
        "print (model.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "800/800 [==============================] - 26s 33ms/step - loss: 1.0249 - categorical_accuracy: 0.6214 - val_loss: 1.5408 - val_categorical_accuracy: 0.7087\n",
            "Epoch 2/10\n",
            "800/800 [==============================] - 25s 31ms/step - loss: 0.1175 - categorical_accuracy: 0.9661 - val_loss: 1.2967 - val_categorical_accuracy: 0.7843\n",
            "Epoch 3/10\n",
            "800/800 [==============================] - 25s 31ms/step - loss: 0.0498 - categorical_accuracy: 0.9891 - val_loss: 1.2797 - val_categorical_accuracy: 0.7437\n",
            "Epoch 4/10\n",
            "800/800 [==============================] - 24s 30ms/step - loss: 0.0207 - categorical_accuracy: 0.9958 - val_loss: 1.1748 - val_categorical_accuracy: 0.7935\n",
            "Epoch 5/10\n",
            "800/800 [==============================] - 24s 30ms/step - loss: 0.0359 - categorical_accuracy: 0.9909 - val_loss: 1.2044 - val_categorical_accuracy: 0.7550\n",
            "Epoch 6/10\n",
            "800/800 [==============================] - 25s 31ms/step - loss: 0.0190 - categorical_accuracy: 0.9959 - val_loss: 1.3432 - val_categorical_accuracy: 0.7411\n",
            "Epoch 7/10\n",
            "800/800 [==============================] - 25s 31ms/step - loss: 0.0335 - categorical_accuracy: 0.9918 - val_loss: 1.5175 - val_categorical_accuracy: 0.7797\n",
            "Epoch 8/10\n",
            "800/800 [==============================] - 24s 31ms/step - loss: 0.0337 - categorical_accuracy: 0.9911 - val_loss: 1.4665 - val_categorical_accuracy: 0.6966\n",
            "Epoch 9/10\n",
            "800/800 [==============================] - 25s 31ms/step - loss: 0.0206 - categorical_accuracy: 0.9949 - val_loss: 1.4120 - val_categorical_accuracy: 0.7175\n",
            "Epoch 10/10\n",
            "800/800 [==============================] - 24s 31ms/step - loss: 0.0158 - categorical_accuracy: 0.9963 - val_loss: 1.4413 - val_categorical_accuracy: 0.7398\n",
            "Model: \"sequential_31\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_36 (Embedding)     (None, 20, 64)            2176      \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 150)               129000    \n",
            "_________________________________________________________________\n",
            "dense_24 (Dense)             (None, 34)                5134      \n",
            "=================================================================\n",
            "Total params: 136,310\n",
            "Trainable params: 136,310\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxTn-rsp24pw",
        "colab_type": "code",
        "outputId": "f2c7150c-4a92-4e07-ed01-7055d2cc0086",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#### Above is the best model. So saving this model for future testing.\n",
        "model.save('best_lstm')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: best_lstm/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: best_lstm/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "a568c0b6-1c00-4889-8401-728760916c20",
        "id": "8dbNaJ2KMlyD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        }
      },
      "source": [
        "#### Let's try the stateful\n",
        "model = Sequential()\n",
        "model.add(Embedding(len(vocab.itos), 64, input_length=train_x.shape[1],batch_input_shape=(BATCH_SIZE,train_x.shape[1])))\n",
        "model.add(LSTM(150,stateful=True))\n",
        "model.add(Dense(len(vocab.itos), activation='softmax'))\n",
        "\n",
        "### Compile the model\n",
        "adam = Adam(lr=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['categorical_accuracy'])\n",
        "\n",
        "#earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=0, mode='auto')\n",
        "#history = model.fit(train_x, train_y, epochs=10, batch_size=64, verbose=1,validation_data=(valid_x,valid_y))\n",
        "history = model.fit(train_batch, epochs=10, verbose=1,validation_data=val_batch)\n",
        "print (model.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "800/800 [==============================] - 23s 29ms/step - loss: 1.1438 - categorical_accuracy: 0.5646 - val_loss: 2.0719 - val_categorical_accuracy: 0.5531\n",
            "Epoch 2/10\n",
            "800/800 [==============================] - 23s 29ms/step - loss: 0.2572 - categorical_accuracy: 0.9006 - val_loss: 1.5539 - val_categorical_accuracy: 0.7589\n",
            "Epoch 3/10\n",
            "800/800 [==============================] - 23s 29ms/step - loss: 0.0206 - categorical_accuracy: 0.9964 - val_loss: 1.7346 - val_categorical_accuracy: 0.7104\n",
            "Epoch 4/10\n",
            "800/800 [==============================] - 23s 29ms/step - loss: 0.0379 - categorical_accuracy: 0.9903 - val_loss: 1.1986 - val_categorical_accuracy: 0.7124\n",
            "Epoch 5/10\n",
            "800/800 [==============================] - 23s 29ms/step - loss: 0.0125 - categorical_accuracy: 0.9973 - val_loss: 1.3515 - val_categorical_accuracy: 0.7268\n",
            "Epoch 6/10\n",
            "800/800 [==============================] - 23s 29ms/step - loss: 0.0152 - categorical_accuracy: 0.9964 - val_loss: 1.1302 - val_categorical_accuracy: 0.7259\n",
            "Epoch 7/10\n",
            "800/800 [==============================] - 23s 29ms/step - loss: 0.0150 - categorical_accuracy: 0.9958 - val_loss: 1.4476 - val_categorical_accuracy: 0.7036\n",
            "Epoch 8/10\n",
            "800/800 [==============================] - 23s 29ms/step - loss: 0.0412 - categorical_accuracy: 0.9886 - val_loss: 1.0229 - val_categorical_accuracy: 0.7560\n",
            "Epoch 9/10\n",
            "800/800 [==============================] - 23s 29ms/step - loss: 0.0070 - categorical_accuracy: 0.9985 - val_loss: 1.0406 - val_categorical_accuracy: 0.7507\n",
            "Epoch 10/10\n",
            "800/800 [==============================] - 23s 29ms/step - loss: 0.0063 - categorical_accuracy: 0.9986 - val_loss: 1.4553 - val_categorical_accuracy: 0.7290\n",
            "Model: \"sequential_29\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_34 (Embedding)     (64, 20, 64)              2176      \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (64, 150)                 129000    \n",
            "_________________________________________________________________\n",
            "dense_22 (Dense)             (64, 34)                  5134      \n",
            "=================================================================\n",
            "Total params: 136,310\n",
            "Trainable params: 136,310\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpCbBnG1uUBI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jgyy6XlsKTqC",
        "colab_type": "text"
      },
      "source": [
        "#### See the results with best performing model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBUlrPS73ISW",
        "colab_type": "code",
        "outputId": "fa7f19aa-9904-48b2-deb5-9df0747d01e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        }
      },
      "source": [
        "from tensorflow import keras\n",
        "model = keras.models.load_model('lstm')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/py_checkpoint_reader.py\u001b[0m in \u001b[0;36mNewCheckpointReader\u001b[0;34m(filepattern)\u001b[0m\n\u001b[1;32m     94\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mCheckpointReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m   \u001b[0;31m# TODO(b/143319754): Remove the RuntimeError casting logic once we resolve the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for lstm/variables/variables",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-102-71d12977ad98>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'lstm'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m       \u001b[0mloader_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msaved_model_load\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m   raise IOError(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/load.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path, compile)\u001b[0m\n\u001b[1;32m    114\u001b[0m   \u001b[0;31m# TODO(kathywu): Add saving/loading of optimizer, compiled losses and metrics.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m   \u001b[0;31m# TODO(kathywu): Add code to load from objects that contain all endpoints\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m   \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_load\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mKerasObjectLoader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/load.py\u001b[0m in \u001b[0;36mload_internal\u001b[0;34m(export_dir, tags, loader_cls)\u001b[0m\n\u001b[1;32m    602\u001b[0m       loader = loader_cls(object_graph_proto,\n\u001b[1;32m    603\u001b[0m                           \u001b[0msaved_model_proto\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 604\u001b[0;31m                           export_dir)\n\u001b[0m\u001b[1;32m    605\u001b[0m       \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLoader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/load.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_models_to_reconstruct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKerasObjectLoader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[0;31m# Now that the node object has been fully loaded, and the checkpoint has\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/load.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, object_graph_proto, saved_model_proto, export_dir)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_restore_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/load.py\u001b[0m in \u001b[0;36m_restore_checkpoint\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    306\u001b[0m       \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file_prefix_placeholder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariables_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_expect_partial_checkpoint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m       \u001b[0mload_status\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariables_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpect_partial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m       \u001b[0mload_status\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariables_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/util.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, save_path)\u001b[0m\n\u001b[1;32m   1258\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msave_path\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mInitializationOnlyStatus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_view\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1260\u001b[0;31m     \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpy_checkpoint_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNewCheckpointReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1261\u001b[0m     \u001b[0mgraph_building\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mgraph_building\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/py_checkpoint_reader.py\u001b[0m in \u001b[0;36mNewCheckpointReader\u001b[0;34m(filepattern)\u001b[0m\n\u001b[1;32m     97\u001b[0m   \u001b[0;31m# issue with throwing python exceptions from C++.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m     \u001b[0merror_translator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/py_checkpoint_reader.py\u001b[0m in \u001b[0;36merror_translator\u001b[0;34m(e)\u001b[0m\n\u001b[1;32m     33\u001b[0m       \u001b[0;34m'Failed to find any '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m       'matching files for') in error_message:\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0merrors_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m   elif 'Sliced checkpoints are not supported' in error_message or (\n\u001b[1;32m     37\u001b[0m       \u001b[0;34m'Data type '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotFoundError\u001b[0m: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for lstm/variables/variables"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hG_lgFKDGnE2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "validation_results = model.predict(val_batch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9A2LJBgK1PR",
        "colab_type": "code",
        "outputId": "0bf958d1-133f-4f7a-e942-24bf16865dba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "validation_results[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.6416882e-06, 1.4358236e-06, 2.5674004e-07, 2.9088228e-06,\n",
              "       1.1634426e-05, 8.8351721e-01, 8.0385362e-08, 6.3598834e-02,\n",
              "       1.7600998e-05, 1.9651961e-02, 5.8387586e-06, 2.1095249e-07,\n",
              "       1.5345472e-08, 2.2925610e-04, 5.8484642e-05, 8.7771984e-03,\n",
              "       7.8436422e-08, 7.0348750e-07, 6.4347776e-05, 2.2038482e-07,\n",
              "       1.8173643e-07, 1.3117283e-04, 5.6981326e-06, 1.2573301e-05,\n",
              "       8.3909426e-06, 2.5287045e-08, 9.2871618e-03, 5.2801005e-07,\n",
              "       1.3819874e-02, 2.6627617e-06, 4.6225134e-04, 3.2909756e-04,\n",
              "       5.4047217e-07, 7.8967517e-08], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUJnx2IKLLwg",
        "colab_type": "code",
        "outputId": "f5c034d5-dcd2-4417-c75f-00654ee0dc07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "vocab.itos[np.argmax(validation_results[0])]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'five'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GL9KGFmXLaIO",
        "colab_type": "code",
        "outputId": "0fd70322-b48c-4897-a4f9-1838c9d7f3bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "show_text(valid_x[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'xxBOF \\n eight thousand one \\n eight thousand two \\n eight thousand three \\n eight thousand four \\n eight thousand'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    }
  ]
}